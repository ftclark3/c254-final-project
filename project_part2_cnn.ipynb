{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"project_part2_cnn.ipynb","provenance":[],"authorship_tag":"ABX9TyNDBa2gNDeIGIKjspX0HPlF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"knvEncaD0vAM","executionInfo":{"status":"ok","timestamp":1652192327024,"user_tz":240,"elapsed":3724,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}}},"outputs":[],"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","# import libraries\n","%matplotlib inline\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.models import Sequential \n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","# Helper libraries\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from google.colab import files\n","import io"]},{"cell_type":"code","source":["# load mostly preprocessed data (preprocessing accomplished before 3/25 proposal)\n","\n","# would use regular numpy syntax to load locally:\n","#X = np.load('<path>/X_cleaned_attempt_new.npy',allow_pickle=True)\n","#Y = np.load('<path>/Y_cleaned_attempt_new.npy',allow_pickle=True)\n","#X = np.asarray(X).astype('float32')\n","#Y = np.asarray(Y).astype('float32')\n","\n","# i'm using colab, so it's slightly more complicated\n","ytrainval_byteseq = files.upload() # choose 'Y_cleaned_attempt_new.npy' from local system\n","ytrainval_filelike = io.BytesIO(ytrainval_byteseq['Y_cleaned_attempt_new.npy']) # create file-like object\n","ytrainval = np.load(ytrainval_filelike,allow_pickle=True) # create regular numpy array\n","xtrainval_byteseq = files.upload() # choose 'X_cleaned_attempt_new.npy' from local system\n","xtrainval_filelike = io.BytesIO(xtrainval_byteseq['X_cleaned_attempt_new.npy']) # create file-like object\n","xtrainval = np.load(xtrainval_filelike,allow_pickle=True) # create regular numpy array\n","ytest_byteseq = files.upload() # choose 'Y_test.npy' from local system\n","ytest_filelike = io.BytesIO(ytest_byteseq['Y_test.npy']) # create file-like object\n","ytest = np.load(ytest_filelike,allow_pickle=True) # create regular numpy array\n","xtest_byteseq = files.upload() # choose 'X_test.npy' from local system\n","xtest_filelike = io.BytesIO(xtest_byteseq['X_test.npy']) # create file-like object\n","xtest = np.load(xtest_filelike,allow_pickle=True) # create regular numpy array"],"metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":240},"id":"80aUyMEu1Buy","executionInfo":{"status":"ok","timestamp":1652195433078,"user_tz":240,"elapsed":3103226,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"d78dd86f-b1e9-4ce4-de52-10f8dcb0959b"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-2ad7508f-4f75-4666-a724-3dab4f0918c4\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-2ad7508f-4f75-4666-a724-3dab4f0918c4\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Y_cleaned_attempt_new.npy to Y_cleaned_attempt_new.npy\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-5325a4dd-5bcc-479d-840f-66f7a30a0331\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-5325a4dd-5bcc-479d-840f-66f7a30a0331\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving X_cleaned_attempt_new.npy to X_cleaned_attempt_new.npy\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-b6e7c6a8-ff5a-401e-b967-d17a02f56a7c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b6e7c6a8-ff5a-401e-b967-d17a02f56a7c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Y_test.npy to Y_test.npy\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-066a1b42-0ae8-48ee-b07f-7b81877d1532\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-066a1b42-0ae8-48ee-b07f-7b81877d1532\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving X_test.npy to X_test.npy\n"]}]},{"cell_type":"code","source":["#check shapes\n","print(xtrainval.shape)\n","print(ytrainval.shape)\n","print(xtest.shape)\n","print(ytest.shape)\n","\n","#ytrainval needs to be converted to number representation of labels\n","feature_map = {'Rock':0,'Electronic':1,'Experimental':2,'Hip-Hop':3,'Folk':4,'Instrumental':5,'Pop':6,\n","              'International':7,'Classical':8,'Old-Time / Historic':9, 'Jazz':10,'Country':11,'Soul-RnB':12,\n","              'Spoken':13,'Blues':14,'Easy Listening':15}\n","for i in range(ytrainval.shape[0]):\n","    ytrainval[i] = float(feature_map[ytrainval[i]])\n","ytrainval[i] = np.asarray(ytrainval[i]).astype('float32')\n","\n","print(ytrainval)\n","print(ytest)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J2IiwY933jYv","executionInfo":{"status":"ok","timestamp":1652195620747,"user_tz":240,"elapsed":368,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"64522075-63ea-443e-db4e-ac4d8e53da8f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(9349, 520)\n","(9349,)\n","(40249, 520)\n","(40249,)\n","[3.0 3.0 3.0 ... 4.0 0.0 array(0., dtype=float32)]\n","[3.0 6.0 0.0 ... 0.0 0.0 array(0., dtype=float32)]\n"]}]},{"cell_type":"code","source":["# for the preliminary report, i did a roughly 80-20 split, but used the 20% as the training set to improve speed\n","# so will recombine and do a 90-10 split, using the 90% as training/validation\n","xfull = np.concatenate((xtrainval,xtest),axis=0)\n","yfull = np.concatenate((ytrainval,ytest),axis=0)\n","print(xfull.shape)\n","print(yfull.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2-RYTAI3bwX","executionInfo":{"status":"ok","timestamp":1652195628013,"user_tz":240,"elapsed":308,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"c8fb3b3a-0a10-4ba7-c01b-4c6522c8616d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(49598, 520)\n","(49598,)\n"]}]},{"cell_type":"code","source":["# finish preprocessing\n","\n","# ~50000 instances in full set, so could get away with 90-10 split probably\n","xtrainval, xtest, ytrainval, ytest = train_test_split(xfull,yfull,train_size=int(0.9*(xtest.shape[0]+xtrainval.shape[0])))\n","\n","# split into training and validation\n","xtrain, xval, ytrain, yval = train_test_split(xtrainval,ytrainval,train_size=int(0.9*xtrainval.shape[0]))\n","\n","# one-hot encoding\n","ytrain_1hot = to_categorical(ytrain)\n","yval_1hot = to_categorical(yval)\n","ytest_1hot = to_categorical(ytest)\n","\n","print(ytrain_1hot.shape)\n","print(yval_1hot.shape)\n","print(ytest_1hot.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xoAHVODb3noY","executionInfo":{"status":"ok","timestamp":1652197664823,"user_tz":240,"elapsed":345,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"b58ae91c-935d-42cd-ee6a-18c2fd48bf51"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["(40174, 16)\n","(4464, 16)\n","(4960, 16)\n"]}]},{"cell_type":"code","source":["'''\n","print(xtrain.shape)\n","print(xtrain[0,:])\n","print(xval[0,:])\n","print(xtest[0,:])\n","# starting with MLP; will need to un-flatten features into time-series signal for cnn implementation\n","# looks like data isn't normalized\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTI9AGRd3xpe","executionInfo":{"status":"ok","timestamp":1652195644534,"user_tz":240,"elapsed":489,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"bdfee22f-e1ba-4254-ba16-1b8241b8ef49"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(40174, 520)\n","[-1.67627648e-01 -3.20516735e-01 -5.47658861e-01 -9.71182227e-01\n"," -1.76922217e-01 -4.82989877e-01  1.08642364e+00 -1.11493632e-01\n"," -4.72926460e-02 -3.23914438e-01 -1.07533276e-01 -3.57802957e-01\n","  6.31417334e-01  6.77803636e-01  6.32379293e-01  6.52357936e-01\n","  6.62765980e-01  5.71075618e-01  6.72195315e-01  6.65100396e-01\n","  6.97125554e-01  6.43173218e-01  6.86596274e-01  6.44778252e-01\n","  2.21735671e-01  2.48877287e-01  2.60894954e-01  2.69073159e-01\n","  2.11407930e-01  1.64966047e-01  1.69164568e-01  2.44937539e-01\n","  2.98581898e-01  2.98516273e-01  3.07941079e-01  2.41853774e-01\n","  2.25851804e-01  2.44530037e-01  2.65893698e-01  2.39126056e-01\n","  2.05803096e-01  1.64028451e-01  1.37677804e-01  2.32101724e-01\n","  2.78784692e-01  2.94118732e-01  2.93991119e-01  2.32563943e-01\n","  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","  1.59775287e-01  3.10287654e-01 -1.41039625e-01  3.56385738e-01\n","  6.43402278e-01  3.52689236e-01  1.13752544e+00  5.07188439e-01\n","  4.54013437e-01  3.54457684e-02  3.63563508e-01  3.84998858e-01\n","  1.22510426e-01  1.51392847e-01  1.39391378e-01  1.80959299e-01\n","  1.60233617e-01  1.10426284e-01  1.46566719e-01  1.45143107e-01\n","  1.52484253e-01  1.40981048e-01  1.44867793e-01  1.47271559e-01\n"," -9.02930737e-01 -1.28108692e+00 -9.58665431e-01 -1.45385587e+00\n"," -1.00839019e+00 -1.75135985e-01 -4.63310361e-01 -8.93087387e-01\n"," -1.27406192e+00 -9.44912732e-01 -1.38952684e+00 -1.01855159e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  4.45898294e-01  5.08179367e-01  4.99347538e-01  5.33553541e-01\n","  4.48205143e-01  3.75716895e-01  3.96847069e-01  4.77361798e-01\n","  5.61757982e-01  5.39769650e-01  5.75716078e-01  4.81639504e-01\n","  4.16620433e-01  4.55621302e-01  5.01650035e-01  4.84806925e-01\n","  4.12478894e-01  3.35831583e-01  3.14533025e-01  4.51958150e-01\n","  5.23262322e-01  5.57538748e-01  5.52615106e-01  4.68131989e-01\n","  1.03950398e-02  1.16404798e-02  1.46987401e-02  1.19489422e-02\n","  1.57694872e-02  7.51221692e-03  1.05714677e-02  1.37288449e-02\n","  2.60859001e-02  3.33698802e-02  1.97299998e-02  1.11652343e-02\n","  3.83428365e-01  2.83189297e-01  9.62955281e-02  1.92783788e-01\n","  4.22087014e-01  7.21288323e-01  7.89073586e-01  3.35632712e-01\n","  1.34024665e-01 -3.40509787e-02  6.15274943e-02  2.74002671e-01\n","  2.63690442e-01  3.14649194e-01  2.60615528e-01  3.29812795e-01\n","  2.84427643e-01  2.31511518e-01  2.75516748e-01  2.66062796e-01\n","  3.01188558e-01  2.50173956e-01  3.04627568e-01  2.79157966e-01\n"," -5.20088911e-01 -1.34820807e+00 -7.97931254e-01 -5.87880671e-01\n"," -1.90091908e-01  3.82508337e-02 -2.00355828e-01 -7.56165504e-01\n"," -1.33353853e+00 -9.49868858e-01 -1.40632236e+00 -8.86214852e-01\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  4.36126977e-01  5.13081253e-01  4.43539113e-01  4.16093081e-01\n","  3.48083526e-01  3.53892148e-01  3.70474488e-01  4.40244317e-01\n","  5.71875989e-01  5.17664969e-01  5.77882946e-01  4.73470360e-01\n","  4.05000150e-01  4.38644916e-01  4.26217914e-01  3.33359510e-01\n","  2.82348245e-01  2.79609054e-01  3.09674531e-01  3.99208486e-01\n","  5.43935120e-01  5.09993136e-01  5.33629954e-01  4.38481301e-01\n","  1.04821648e-03  2.73930398e-03  4.50943783e-03  2.58126715e-03\n","  1.00620976e-03  8.56060127e-04  1.07520435e-03  3.75374802e-03\n","  1.46557465e-02  5.12357196e-03  1.06713576e-02  5.34385629e-03\n","  5.26268840e-01  3.15263897e-01  3.54253948e-01  7.50276089e-01\n","  8.34676266e-01  9.60020006e-01  8.28983188e-01  4.79639471e-01\n","  7.90902972e-02  1.05974481e-01  7.89743289e-02  3.49534273e-01\n","  2.52752900e-01  3.27770561e-01  2.57639676e-01  2.88403869e-01\n","  2.51732051e-01  2.58961052e-01  2.66751647e-01  2.70331085e-01\n","  3.08196098e-01  2.62407154e-01  3.15120935e-01  2.64216661e-01\n","  2.75347638e+00 -5.83305836e-01  1.69917017e-01  1.86964050e-01\n"," -3.99920195e-01  2.10943073e-01  3.49366277e-01  4.18283343e-02\n","  6.73638821e-01  3.02324206e-01  5.15340175e-03 -1.15888886e-01\n"," -2.77526677e-01  5.84896542e-02 -1.73621967e-01  1.97879955e-01\n","  1.38425222e-02  3.08299989e-01 -4.70227674e-02  2.20713288e-01\n","  4.02517548e+01  2.57809357e+02  9.67616119e+01  1.21053047e+02\n","  7.31764526e+01  7.07442627e+01  5.24997101e+01  5.40239182e+01\n","  5.89924431e+01  4.73175087e+01  3.92379150e+01  3.41971931e+01\n","  1.77308674e+01  2.54169006e+01  3.01668377e+01  3.01472988e+01\n","  1.92022343e+01  2.72218227e+01  2.52592468e+01  2.60159893e+01\n"," -1.12768051e+02  1.39984009e+02 -1.47872667e+01  3.97191162e+01\n","  1.87708390e+00  1.57694874e+01 -6.69107246e+00  8.53943920e+00\n"," -2.96282649e+00  3.08478332e+00 -4.03060341e+00  1.77715719e+00\n"," -1.09300470e+01 -1.95383477e+00 -5.24872017e+00 -1.60251886e-01\n"," -8.30957794e+00 -1.29844606e+00 -2.38114119e+00 -1.95183024e-01\n"," -1.01593414e+02  1.35372269e+02 -1.28806992e+01  4.07776718e+01\n","  2.80786562e+00  1.59364605e+01 -7.27076674e+00  8.73145580e+00\n"," -3.43871713e+00  3.17612195e+00 -4.21904182e+00  1.98239136e+00\n"," -1.11073799e+01 -1.49231017e+00 -5.18164539e+00 -1.27293598e-02\n"," -8.25551224e+00 -1.09691548e+00 -2.22459602e+00  1.20230719e-01\n"," -4.93112762e+02 -3.13535061e+01 -9.94586029e+01 -5.61367226e+01\n"," -8.39722977e+01 -4.26220856e+01 -4.76289101e+01 -4.37143974e+01\n"," -3.75838242e+01 -4.32929039e+01 -4.08118973e+01 -3.11847496e+01\n"," -4.12526245e+01 -3.33597069e+01 -3.23546181e+01 -2.74385662e+01\n"," -3.49186172e+01 -3.03301411e+01 -2.80258656e+01 -2.79223156e+01\n"," -1.13122821e+00  1.08488999e-01 -3.23896438e-01 -2.46017039e-01\n"," -1.26524083e-02 -4.47492376e-02  3.15788507e-01 -8.89111385e-02\n","  3.73438537e-01  2.97203194e-02  1.19816296e-01 -5.54992370e-02\n","  4.17787675e-03 -2.58697540e-01  8.94657150e-02 -2.88776737e-02\n"," -6.01291917e-02 -1.31304801e-01 -7.81936646e-02 -2.25605473e-01\n","  7.29036713e+01  4.58345146e+01  2.48220444e+01  2.24696999e+01\n","  2.31767178e+01  1.42780895e+01  1.15311241e+01  1.06435966e+01\n","  1.05167294e+01  9.67380428e+00  9.96084881e+00  7.93431282e+00\n","  8.13784885e+00  7.26405287e+00  8.62212086e+00  6.85564041e+00\n","  6.91016436e+00  6.92175245e+00  7.01325512e+00  6.73213148e+00\n","  4.79975700e-01  1.56629972e+01  6.05403376e+00  5.91829634e+00\n","  9.15978744e-05  3.49882543e-01  2.46361804e+00 -1.01596189e+00\n","  3.41214819e+03  1.73385547e+03  1.84603064e+03  6.04737732e+02\n"," -1.73219725e-01  5.53114136e+02 -4.70219553e-02  5.50520264e+03\n","  1.45248413e+03  1.34042029e+03  2.00917572e+02  6.00261629e-01\n","  7.41790771e+02  1.04763114e+00  3.87316525e-01  3.60802680e-01\n","  4.11249727e-01 -2.36990526e-01  7.81322300e-01 -1.05641317e+00\n","  6.56033325e+01  3.65493431e+01  4.17659798e+01  3.38989487e+01\n","  3.53567390e+01  2.99997616e+01  5.30500565e+01  2.05011749e+01\n","  1.43319235e+01  1.68067780e+01  1.65959721e+01  1.83112774e+01\n","  1.74746151e+01  3.81993561e+01  1.99813614e+01  1.39486589e+01\n","  1.64424553e+01  1.63396244e+01  1.77727966e+01  1.71506634e+01\n","  3.95558319e+01  3.20645237e+00  8.12685490e-01  1.74567628e+00\n","  4.16370678e+00  4.53669930e+00  8.72136879e+00  1.43067398e+01\n","  6.72322452e-01  5.12786567e-01  5.04532814e-01  3.99446905e-01\n","  4.64143068e-01  7.56131709e-01 -2.81908005e-01  6.36623716e+00\n","  4.31043673e+00  4.30331373e+00  3.59720373e+00  4.15933847e+00\n","  2.75168896e+00  5.85549641e+00 -8.17780197e-01  9.17314453e+03\n","  3.03098267e+03  2.92851562e+03  9.68994141e+01  2.41789460e-01\n","  1.59662732e+03  7.84266591e-01  7.40396738e-01  1.29944003e+00\n","  8.21180344e-01  5.57419918e-02  4.43694741e-01  1.03491701e-01\n","  1.39286876e-01  3.26773018e-01  3.48427027e-01  7.55004957e-02\n","  5.71926981e-02 -1.66181605e-02  5.18605951e-03  1.48040783e-02\n"," -9.71708330e-04  6.80663576e-03 -5.53299207e-03 -1.59188434e-02\n","  4.07043844e-03  1.94471274e-02  1.43643655e-03  6.24469435e-03\n"," -5.16038248e-03 -1.20012827e-01 -1.31319985e-01 -3.18191230e-01\n"," -3.65394324e-01 -5.02879955e-02 -6.69571906e-02  1.34854391e-01\n","  2.06845865e-01 -2.29107723e-01 -9.23636705e-02  1.78615898e-01\n"," -2.58617491e-01  2.85797212e-02  3.17912959e-02  9.24239382e-02\n","  9.74440649e-02  1.84984040e-02  1.59909558e-02  5.34885836e+00\n","  3.83300781e-01  5.92078194e-02  4.54101562e-02  2.44140625e-03\n","  2.01952386e+00  4.90518622e-02  2.01200000e+03  4.48000000e+02]\n","[-2.07685992e-01  1.65112227e-01  5.13997972e-01  3.29406522e-02\n","  4.24507231e-01 -3.30799795e-03  4.44840729e-01  1.23625660e+00\n","  1.87465692e+00  1.59207773e+00 -5.62496364e-01  1.06266312e-01\n","  4.73101467e-01  5.30212045e-01  5.91756403e-01  5.17430842e-01\n","  6.91808701e-01  6.01991296e-01  5.51085889e-01  7.00525820e-01\n","  6.21661007e-01  7.17859626e-01  5.95717788e-01  4.69982922e-01\n","  1.28985822e-01  1.38083443e-01  1.44625247e-01  2.22984463e-01\n","  3.36646616e-01  2.42022604e-01  1.39308959e-01  1.69440776e-01\n","  3.98846269e-01  4.96441394e-01  3.31545323e-01  1.47886872e-01\n","  1.31507173e-01  1.39205441e-01  1.30309299e-01  2.17603713e-01\n","  3.32900822e-01  2.29554042e-01  1.31704792e-01  1.54948130e-01\n","  4.29610133e-01  5.05949378e-01  3.52856129e-01  1.41946018e-01\n","  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","  2.08158288e-02  0.00000000e+00  5.73564284e-05  0.00000000e+00\n","  2.69028962e-01  4.36161995e-01  8.67342889e-01  1.94111228e-01\n"," -1.86676793e-02  1.48747385e-01  7.38213241e-01  1.00255978e+00\n"," -1.39542508e+00 -1.17151523e+00 -5.20609856e-01  5.61313152e-01\n","  8.00231695e-02  9.05858725e-02  1.17793962e-01  9.95866582e-02\n","  1.19479254e-01  1.00605860e-01  1.02249056e-01  1.26081705e-01\n","  8.48053694e-02  1.44009888e-01  1.00480601e-01  9.55558047e-02\n","  1.40081418e+00  1.57864356e+00  1.31071556e+00 -4.09545988e-01\n"," -1.15032434e+00 -4.86719877e-01  3.85488510e-01  4.15469825e-01\n","  5.11835217e-01  2.10058665e+00  9.06470835e-01  1.16627336e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  3.09748560e-01  3.15807194e-01  3.36714178e-01  4.07329559e-01\n","  5.79099357e-01  4.31843817e-01  3.24839741e-01  3.75288188e-01\n","  6.44342840e-01  8.71640503e-01  5.24179280e-01  3.33245695e-01\n","  2.74367124e-01  2.78982013e-01  2.80037075e-01  3.78980130e-01\n","  5.28326750e-01  3.97935539e-01  2.76758462e-01  2.96939790e-01\n","  6.38726413e-01  1.00000000e+00  5.29649019e-01  2.92206377e-01\n","  2.54768617e-02  2.54009776e-02  1.88733153e-02  3.83966565e-02\n","  1.81169137e-02  1.85965560e-02  1.55960405e-02  1.69976372e-02\n","  5.90595007e-02  4.40305285e-02  3.85982506e-02  1.52473552e-02\n","  1.11916041e+00  1.16168547e+00  1.27583957e+00  5.00485003e-01\n","  2.66978264e-01  4.90331918e-01  9.21234787e-01  1.15214431e+00\n"," -2.48489708e-01 -1.78322542e+00 -1.13516703e-01  1.12068343e+00\n","  1.70730144e-01  1.71763182e-01  2.17971355e-01  1.94208071e-01\n","  2.73390889e-01  2.07182661e-01  1.99131235e-01  2.60869145e-01\n","  1.68068796e-01  2.30715379e-01  1.44936472e-01  1.92072883e-01\n","  1.55382061e+00  8.71166646e-01  1.18569851e+00  3.47564906e-01\n"," -1.02388692e+00 -1.28303304e-01  6.89716458e-01  1.24636662e+00\n"," -8.33520114e-01 -1.00651932e+00 -1.32250547e-01 -3.59835595e-01\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  3.06830466e-01  3.38247120e-01  3.13274294e-01  3.39520007e-01\n","  4.87292558e-01  3.89460534e-01  3.21773618e-01  3.46358061e-01\n","  6.04798615e-01  7.22155571e-01  4.63046789e-01  4.24620599e-01\n","  2.50861883e-01  2.82324702e-01  2.36348107e-01  2.99714804e-01\n","  4.21563685e-01  3.24106455e-01  2.49050781e-01  2.99968511e-01\n","  5.90460896e-01  8.72749150e-01  4.55986679e-01  3.56105953e-01\n","  1.25343271e-03  8.85971298e-04  1.42329209e-03  2.98194122e-03\n","  5.51972119e-03  4.62302892e-03  1.71949377e-03  1.87247910e-03\n","  1.91827863e-03  2.35368661e-03  1.81613106e-03  2.03938736e-03\n","  1.30551136e+00  1.13555181e+00  1.35557306e+00  8.42274904e-01\n","  4.60399836e-01  8.46857250e-01  1.15459645e+00  1.19840741e+00\n"," -9.33347046e-02 -6.84738636e-01  2.24730849e-01  7.76960373e-01\n","  2.10376963e-01  2.31885090e-01  2.49401778e-01  2.06518739e-01\n","  2.97711641e-01  2.55354613e-01  2.38376722e-01  2.20011815e-01\n","  2.65892088e-01  3.15873355e-01  2.09666938e-01  2.71678865e-01\n"," -1.29122710e+00 -3.54445934e-01 -6.01186216e-01 -7.67963946e-01\n"," -5.47798097e-01  2.16693789e-01 -3.44895214e-01  3.91359061e-01\n"," -2.33645067e-01 -3.47442180e-01 -3.80269438e-02  1.91858485e-01\n","  1.15708061e-01 -8.04163069e-02  4.06892955e-01 -4.41327065e-01\n","  1.14269391e-01 -4.68092412e-02  2.72636618e-02  1.73713028e-01\n","  2.02391281e+01  2.46379562e+02  3.83737412e+01  9.62099304e+01\n","  6.00889740e+01  5.84003334e+01  5.03852844e+01  4.55543671e+01\n","  3.52312126e+01  3.88522301e+01  3.86318436e+01  3.69776649e+01\n","  3.34024696e+01  3.38675728e+01  3.33780746e+01  3.34558792e+01\n","  2.27530861e+01  2.46656685e+01  2.23340740e+01  2.94617195e+01\n"," -1.43622437e+02  1.56254272e+02 -2.39469070e+01  2.49195976e+01\n","  4.64642191e+00  1.78479080e+01 -4.09806919e+00  1.25956612e+01\n"," -3.25636911e+00  5.97522593e+00  5.95453382e-01  4.79132366e+00\n"," -5.18756294e+00 -1.18074453e+00 -5.60044765e+00 -2.08140898e+00\n"," -5.75811768e+00  7.39966273e-01 -2.13303280e+00 -9.87216055e-01\n"," -8.70487823e+01  1.57759308e+02 -2.14264622e+01  2.62773285e+01\n","  2.56323934e+00  1.95455914e+01 -9.20370102e+00  1.30581083e+01\n"," -3.85582137e+00  6.91125298e+00  5.00153065e-01  4.97132778e+00\n"," -5.58494186e+00 -1.14393711e+00 -5.78892803e+00 -1.58643913e+00\n"," -5.83239174e+00  9.37860072e-01 -2.21560764e+00 -8.08511198e-01\n"," -5.26259705e+02 -2.84217094e-14 -9.43095093e+01 -4.53652763e+01\n"," -5.77554588e+01 -3.32613449e+01 -4.74321861e+01 -2.57669449e+01\n"," -3.27644119e+01 -2.99491348e+01 -3.14524479e+01 -3.23959427e+01\n"," -3.52371864e+01 -2.87512455e+01 -3.51562347e+01 -3.07245007e+01\n"," -2.89393063e+01 -2.33151646e+01 -2.71201744e+01 -2.65548649e+01\n"," -5.71119845e-01 -1.39403030e-01 -2.69002825e-01  6.71990216e-02\n","  2.12287694e-01 -6.11849964e-01  7.52376020e-01 -2.68070161e-01\n","  2.18635142e-01 -2.96243519e-01  5.01573011e-02 -1.20930769e-01\n","  3.34765285e-01  2.60819308e-02  2.41439790e-01 -1.79698646e-01\n","  6.96421638e-02 -1.63631275e-01  5.69296889e-02 -1.29682109e-01\n","  1.14312210e+02  2.80438480e+01  2.11934242e+01  2.28911438e+01\n","  1.67095509e+01  1.16292925e+01  1.67849941e+01  7.78492069e+00\n","  8.81816101e+00  9.80483818e+00  7.89915323e+00  7.25404501e+00\n","  7.68016911e+00  7.30656433e+00  6.63710785e+00  8.72796345e+00\n","  6.12060165e+00  6.37891626e+00  6.06636381e+00  6.26663637e+00\n"," -1.37783527e+00  1.13648567e+01  4.84058666e+00  6.17807007e+00\n","  1.88192353e-05 -5.32028496e-01  2.79950023e+00 -2.13060364e-01\n","  3.20631152e+03  1.62538525e+03  1.53240417e+03  6.33735413e+02\n","  6.44705534e-01  4.63583710e+02  8.20657671e-01  5.51724316e+03\n","  1.22743335e+03  1.10887585e+03  2.38272629e+02  9.63468373e-01\n","  4.74980042e+02  3.16082931e+00  7.33657599e-01  9.00708377e-01\n","  3.24202716e-01  7.05406606e-01  3.63573581e-01 -1.48345637e+00\n","  5.98768387e+01  3.73037109e+01  4.24634323e+01  3.55480118e+01\n","  3.68698006e+01  2.89955673e+01  5.21432114e+01  1.76483459e+01\n","  1.43681812e+01  1.74365501e+01  1.76914005e+01  1.87857208e+01\n","  1.70461235e+01  3.63360825e+01  1.68649864e+01  1.40620413e+01\n","  1.71057072e+01  1.72599449e+01  1.82787437e+01  1.67891598e+01\n","  3.81345139e+01  2.96067786e+00  2.97907686e+00  5.90943909e+00\n","  7.34088325e+00  9.78051949e+00  1.11515131e+01  1.28991699e+01\n","  1.23301625e+00  5.93059957e-01  6.07608199e-01  6.11332357e-01\n","  7.41794467e-01  5.77519000e-01 -8.91770199e-02  4.95349693e+00\n","  3.70090723e+00  3.90403652e+00  3.46880412e+00  3.47257352e+00\n","  2.23026800e+00  7.29125834e+00  3.44107121e-01  9.38847656e+03\n","  2.56748560e+03  2.12102051e+03  1.50732422e+02  1.07252002e+00\n","  1.35463562e+03  6.27487183e-01  7.52335131e-01  9.38518167e-01\n","  1.99450421e+00 -7.50012994e-02  5.95468044e-01  1.46359131e-01\n","  9.21082795e-02  3.55467856e-01  3.52751285e-01  8.34530145e-02\n","  6.98609650e-02  7.69308442e-03 -1.10255750e-02 -1.22721821e-01\n","  8.71178508e-02  7.07278587e-03  6.32993225e-03  7.31323613e-03\n"," -1.04878265e-02 -1.25915110e-01  9.45325196e-02  5.94475400e-03\n","  7.16595305e-03 -1.35889754e-01 -1.31177962e-01 -4.40697193e-01\n"," -2.78383970e-01 -5.76357916e-02 -7.85386562e-02  8.65665525e-02\n"," -1.71233594e-01  4.90978390e-01 -8.21340382e-01  2.09391356e-01\n"," -3.34929794e-01  3.10861189e-02  2.62432899e-02  1.15841396e-01\n","  7.20711946e-02  2.10632663e-02  1.84077565e-02  9.85545993e-01\n","  2.04101562e-01  4.98855636e-02  4.73632812e-02  3.90625000e-03\n","  7.62694955e-01  2.10438482e-02  2.00900000e+03  3.94000000e+02]\n","[ 5.26898801e-01 -9.86569941e-01  2.87823498e-01 -7.40383327e-01\n","  3.50621790e-01  1.08391363e-02 -3.07473779e-01  6.55199647e-01\n","  2.25512668e-01 -7.84998775e-01 -6.32341564e-01 -4.70967472e-01\n","  8.75863016e-01  5.14352620e-01  6.52768195e-01  6.37831807e-01\n","  4.70619887e-01  6.06169283e-01  5.89595616e-01  6.75952494e-01\n","  5.99577129e-01  4.94933724e-01  5.21733642e-01  5.16079724e-01\n","  3.11114192e-01  2.73034573e-01  2.63977528e-01  2.95507699e-01\n","  2.39059970e-01  2.31678426e-01  2.74053276e-01  3.02709460e-01\n","  2.69285619e-01  2.25172222e-01  2.04334736e-01  2.13244304e-01\n","  2.63982356e-01  2.77753860e-01  2.37069681e-01  2.65631855e-01\n","  2.40437940e-01  2.34499171e-01  2.76087970e-01  3.09697002e-01\n","  2.61239201e-01  2.25889698e-01  2.09973887e-01  2.23333895e-01\n","  9.58161196e-04  5.70473587e-03  5.40608540e-04  5.58251515e-04\n","  3.34527867e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n","  9.81750369e-01 -1.11903392e-01  8.47589910e-01  2.91300327e-01\n"," -3.01820725e-01  4.28193957e-02 -3.10255706e-01  1.36853546e-01\n","  8.60904753e-02 -1.73744515e-01  5.48078492e-02 -2.57676661e-01\n","  1.90194562e-01  1.15884840e-01  1.43516183e-01  1.45559058e-01\n","  8.56056958e-02  1.09686807e-01  1.11392789e-01  1.23850092e-01\n","  1.16436169e-01  1.02403738e-01  1.00796752e-01  1.04628153e-01\n"," -1.28419602e+00 -5.25692999e-01 -1.00439346e+00 -1.14352798e+00\n"," -6.92779183e-01 -1.07620132e+00 -1.09753275e+00 -1.25023615e+00\n"," -1.19408917e+00 -1.12823987e+00 -9.60854888e-01 -3.63071531e-01\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  6.09971225e-01  5.16762018e-01  5.48841119e-01  5.97188413e-01\n","  5.05321383e-01  5.16563773e-01  5.67925215e-01  6.13852620e-01\n","  5.57248354e-01  4.97490346e-01  4.76350516e-01  4.49811310e-01\n","  5.85443616e-01  4.93500739e-01  5.40683210e-01  6.15927815e-01\n","  5.44315219e-01  5.44319570e-01  5.70330560e-01  6.34842038e-01\n","  5.56504011e-01  4.73149687e-01  4.45293337e-01  4.49629992e-01\n","  3.40139382e-02  3.49209830e-02  3.32288817e-02  1.63628366e-02\n","  1.42648285e-02  1.46236019e-02  2.03030966e-02  1.85805280e-02\n","  1.35907643e-02  1.04017220e-02  2.01330557e-02  1.20538250e-02\n"," -1.31467795e-02  3.27176660e-01  9.87648815e-02 -1.96604192e-01\n"," -2.34888107e-01 -6.60565570e-02 -1.18227623e-01 -2.21136004e-01\n"," -1.78564638e-02  1.79274589e-01  2.90731758e-01  3.33567053e-01\n","  2.93199539e-01  2.15336427e-01  2.79581100e-01  2.95856565e-01\n","  2.29913682e-01  2.75351942e-01  2.82346845e-01  3.01686674e-01\n","  2.94237286e-01  2.86135137e-01  2.69732147e-01  2.20294446e-01\n"," -1.32087970e+00 -8.61077726e-01 -1.04619420e+00 -1.42007840e+00\n"," -9.46596563e-01 -7.90599048e-01 -7.13450909e-01 -9.23515856e-01\n"," -6.62792683e-01 -6.78159058e-01 -1.14830577e+00 -9.07152116e-01\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n","  5.19933045e-01  4.60126907e-01  4.66762006e-01  5.38364708e-01\n","  4.72328991e-01  4.35506612e-01  4.18854177e-01  4.47903037e-01\n","  4.02598053e-01  4.30041552e-01  5.18889070e-01  4.88288879e-01\n","  4.66400027e-01  4.23236907e-01  4.71377552e-01  5.12050629e-01\n","  4.73981440e-01  3.98986012e-01  3.72370899e-01  4.12168771e-01\n","  3.63135576e-01  3.84257972e-01  4.88737375e-01  4.59764481e-01\n","  7.43924058e-04  4.07227926e-04  5.47504344e-04  1.15013006e-03\n","  2.81727733e-03  2.07517087e-03  2.87731178e-03  2.01609312e-03\n","  1.91495498e-03  4.19821916e-03  4.81885904e-03  3.24627478e-03\n","  2.36206129e-01  3.89760643e-01  1.80359557e-01  6.74505979e-02\n","  1.49124295e-01  4.67160404e-01  5.54421246e-01  4.03009236e-01\n","  5.43360531e-01  5.33193171e-01  1.94466576e-01  2.68230855e-01\n","  3.23582351e-01  2.76385605e-01  2.81296343e-01  3.40223610e-01\n","  2.71239460e-01  2.83074439e-01  2.83507764e-01  2.92098343e-01\n","  2.76564926e-01  2.77712196e-01  2.99898118e-01  2.70453066e-01\n","  2.43162513e+00  8.39447558e-01 -6.06657505e-01  6.21394098e-01\n"," -1.44818187e-01  3.56405531e-03  8.51852819e-02 -3.31636518e-01\n","  9.51961502e-02 -2.30178133e-01  5.72318017e-01  1.08039081e-01\n","  4.31348607e-02  1.81372911e-01  1.19896136e-01 -1.60442904e-01\n","  1.93677425e-01  1.19918428e-01  1.51891619e-01  3.80899012e-01\n","  3.33720779e+01  2.22481186e+02  9.16654663e+01  1.49557312e+02\n","  6.61522827e+01  7.70434418e+01  4.67030563e+01  5.85174065e+01\n","  4.68223534e+01  4.29616852e+01  3.93580551e+01  3.91089287e+01\n","  3.59026604e+01  3.30638275e+01  3.98079987e+01  3.76766891e+01\n","  2.68368206e+01  3.25845337e+01  2.91575489e+01  2.79525585e+01\n"," -1.47715927e+02  1.39745972e+02 -2.40861626e+01  4.53796654e+01\n","  3.27325368e+00  1.65839634e+01 -5.66317940e+00  4.30498028e+00\n"," -3.17495775e+00  7.11989999e-01 -8.34388351e+00  1.09806728e+00\n"," -1.00850224e+00 -1.44390965e+00 -8.71126592e-01 -8.00861657e-01\n"," -2.23856544e+00 -7.00719282e-02 -1.14404666e+00 -1.78546166e+00\n"," -1.46719833e+02  1.42169540e+02 -2.35287914e+01  4.51686401e+01\n","  2.14751315e+00  1.70825424e+01 -4.87347746e+00  4.10062361e+00\n"," -3.98132324e+00  8.06666851e-01 -8.67803669e+00  6.94107413e-01\n"," -1.41539419e+00 -1.46378148e+00 -1.14874649e+00 -1.06260777e+00\n"," -2.42327380e+00 -9.32910740e-02 -1.24928796e+00 -1.36984313e+00\n"," -5.00096588e+02 -1.29902353e+01 -1.13119019e+02 -4.06420403e+01\n"," -7.18187485e+01 -5.17236671e+01 -6.03941574e+01 -4.92747574e+01\n"," -4.23332748e+01 -4.38118935e+01 -5.33518486e+01 -4.15616760e+01\n"," -3.34944344e+01 -5.03407326e+01 -3.36953888e+01 -2.90299206e+01\n"," -3.55973663e+01 -2.92103634e+01 -2.48441906e+01 -3.50433273e+01\n"," -6.49517357e-01 -6.10380471e-01  7.85482004e-02  1.50833741e-01\n","  1.49407044e-01 -2.51658231e-01 -1.73604161e-01  7.47238174e-02\n","  3.95021617e-01 -1.33004874e-01  1.32485300e-01  1.45883247e-01\n","  2.36403242e-01 -1.03971653e-01  2.23403215e-01  1.53091431e-01\n","  5.59330992e-02  8.80710110e-02  5.58619499e-02 -2.72924900e-01\n","  7.77617493e+01  3.45896416e+01  3.00663738e+01  2.12328262e+01\n","  1.89631958e+01  1.68231087e+01  1.46466990e+01  1.50595388e+01\n","  1.28447599e+01  1.25904980e+01  1.01706142e+01  9.19579792e+00\n","  8.71373653e+00  9.95076275e+00  8.62301350e+00  8.36936188e+00\n","  7.08092928e+00  7.30702305e+00  7.03701782e+00  6.97766399e+00\n","  3.09769392e-01  1.58172274e+01  5.12047768e+00  4.67570162e+00\n","  1.58599182e-03  7.47181237e-01  2.89902520e+00  2.25580275e-01\n","  3.91409058e+03  1.55501282e+03  1.48416467e+03  5.66852478e+02\n","  6.22612894e-01  4.49275452e+02  3.13872681e+01  8.27233984e+03\n","  1.32203186e+03  1.19648303e+03  2.04470139e+02  3.95280933e+00\n","  7.36053345e+02  3.04421377e+00  2.38219246e-01  5.40328562e-01\n","  1.46976739e-01  5.67766488e-01  3.42714041e-01 -9.76855338e-01\n","  6.08398094e+01  4.00746346e+01  4.02448730e+01  3.24995689e+01\n","  3.37590942e+01  3.02030373e+01  4.93631897e+01  1.83528976e+01\n","  1.57519493e+01  1.67581482e+01  1.65263443e+01  1.73385983e+01\n","  1.74405479e+01  3.64897461e+01  1.78378544e+01  1.53525887e+01\n","  1.62771988e+01  1.62737427e+01  1.66010895e+01  1.73000679e+01\n","  3.57158127e+01  3.71065879e+00  2.13853192e+00  4.37879896e+00\n","  4.35208750e+00  9.06774235e+00  4.99716091e+00  2.07532578e+01\n","  9.86422420e-01  4.64816123e-01  6.51870012e-01  4.40180540e-01\n","  8.82215798e-01  3.86639923e-01  7.10403174e-02  4.77937889e+00\n","  4.58067465e+00  4.57921839e+00  3.41233134e+00  3.63280463e+00\n","  2.43358016e+00  5.65994215e+00  2.75219941e+00  9.77607422e+03\n","  2.69591211e+03  2.45478516e+03  1.83032227e+02  1.10823762e+00\n","  1.38004688e+03  5.45089126e-01  3.57800722e+00  1.30744457e+00\n","  2.49035311e+00  4.62162226e-01  6.06895781e+00  6.37864769e-02\n","  1.96937472e-01  3.35089028e-01  5.10733783e-01  7.19249099e-02\n","  1.47614568e-01 -1.38192745e-02  1.98935512e-02  2.74919029e-02\n","  2.81117260e-02  5.91542618e-03  1.84782241e-02 -1.27821080e-02\n","  1.42576527e-02  2.12155823e-02  1.38455983e-02  5.43208513e-03\n","  1.38589256e-02 -1.41967699e-01 -8.89558420e-02 -1.75657526e-01\n"," -3.12181324e-01 -3.98760177e-02 -2.30100173e-02 -3.84583801e-01\n","  1.45093250e+00  6.39167130e-01  9.37748253e-01  3.15710217e-01\n","  2.20450401e+00  2.63664536e-02  3.40295508e-02  7.38012716e-02\n","  1.08603008e-01  1.57805663e-02  2.32456774e-02  8.72629013e+01\n","  8.15429688e-01  5.37093021e-02  4.05273438e-02  9.76562500e-04\n","  7.77721119e+00  6.19566627e-02  2.01300000e+03  2.46000000e+02]\n"]}]},{"cell_type":"code","source":["# will check feature list to understand how CNN might be implemented\n","# i don't think tf.keras is particularly well suited for this task, because \n","# we would need several different layers for the time series of different\n","# dimensions.\n","# so maybe an ensemble CNN would be a good idea?\n","# i want to try that\n","chroma_cens = xtrain[:,:84] # length 12\n","chroma_cqt = xtrain[:,84:168] # length 12\n","chroma_stft = xtrain[:,168:252]# length 12\n","chroma_mfcc = xtrain[:,252:392] # length 20\n","rmse = xtrain[:,392:399]\n","spectral_bandwidth = xtrain[:,399:406]\n","spectral_centroid = xtrain[:,406:413]\n","spectral_contrast = xtrain[:,413:462]# length 7\n","spectral_rolloff = xtrain[:,462:469] \n","tonnetz = xtrain[:,469:511] # length 6\n","zcr = xtrain[:,511:518]\n","dates = xtrain[:,518]\n","duration = xtrain[:,519]\n","\n","print(chroma_cens.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDrs30wH3yab","executionInfo":{"status":"ok","timestamp":1652198212088,"user_tz":240,"elapsed":294,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"9a74ef70-ef97-446b-cb0f-06fa2fc7fec0"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["(40174, 84)\n"]}]},{"cell_type":"code","source":["# currently, the features are a timeseries for each statistic\n","# but we want to reindex so that all statistics are intermingled\n","# but grouped by time\n","# this function will help with that\n","def get_index_order(subinterval_length):\n","    idxs = []\n","    for i in range(1,subinterval_length+1):\n","        idx = []\n","        for j in range(1,8):\n","            idx.append(subinterval_length*(j-1)+i-1)\n","        idxs.append(idx)\n","    idxs = np.array(idxs).flatten()\n","    #print(chroma_cens_idxs)\n","    return idxs"],"metadata":{"id":"Q3F3MXSUGiev","executionInfo":{"status":"ok","timestamp":1652198217873,"user_tz":240,"elapsed":309,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["order_12 = get_index_order(12)\n","order_20 = get_index_order(20)\n","order_7 = get_index_order(7)\n","order_6 = get_index_order(6)\n","#print(order_12)\n","# reindex timeseries arrays\n","chroma_cens = chroma_cens[:,order_12] # length 12\n","chroma_cqt = chroma_cqt[:,order_12] # length 12\n","chroma_stft = chroma_stft[:,order_12] # length 20\n","chroma_mfcc = chroma_mfcc[:,order_20] # length 20\n","spectral_contrast = spectral_contrast[:,order_7] # length 7\n","tonnetz = tonnetz[:,order_6] # length 6\n","\n","#reshape\n","chroma_cens = chroma_cens.reshape(xtrain.shape[0],int(chroma_cens.shape[1]/7),7)\n","chroma_cqt = chroma_cqt.reshape(xtrain.shape[0],int(chroma_cqt.shape[1]/7),7)\n","chroma_stft = chroma_stft.reshape(xtrain.shape[0],int(chroma_stft.shape[1]/7),7)\n","chroma_mfcc = chroma_mfcc.reshape(xtrain.shape[0],int(chroma_mfcc.shape[1]/7),7)\n","rmse = rmse.reshape(xtrain.shape[0],int(rmse.shape[1]/7),7)\n","spectral_bandwidth = spectral_bandwidth.reshape(xtrain.shape[0],int(spectral_bandwidth.shape[1]/7),7)\n","spectral_centroid = spectral_centroid.reshape(xtrain.shape[0],int(spectral_centroid.shape[1]/7),7)\n","spectral_contrast = spectral_contrast.reshape(xtrain.shape[0],int(spectral_contrast.shape[1]/7),7)\n","spectral_rolloff = spectral_rolloff.reshape(xtrain.shape[0],int(spectral_rolloff.shape[1]/7),7)\n","tonnetz = tonnetz.reshape(xtrain.shape[0],int(tonnetz.shape[1]/7),7)\n","zcr = zcr.reshape(xtrain.shape[0],int(zcr.shape[1]/7),7)\n","\n","print(chroma_cens.shape)\n","#print(chroma_cens[0,:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"az1PGha6O7iw","executionInfo":{"status":"ok","timestamp":1652199055095,"user_tz":240,"elapsed":515,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"83c95dcb-3653-4047-9218-7f4dd29f8be8"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["(40174, 12, 7)\n"]}]},{"cell_type":"code","source":["print(xtrain.shape[0])\n","print(tonnetz.shape[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"raXoNgT71EZX","executionInfo":{"status":"ok","timestamp":1652199061753,"user_tz":240,"elapsed":308,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"2aa35fa5-813b-4197-ad08-0ead9f148f42"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["40174\n","40174\n"]}]},{"cell_type":"code","source":["# define general structure\n","layer_list = [\n","          #layers.BatchNormalization(),\n","          #layers.Conv1D(4,7,strides=7,kernel_initializer='lecun_normal',input_shape=(xtrain.shape[0],84)), #what if we just make 2nd dim xtrain.shape[1]?\n","          layers.Conv1D(7,1,strides=1,kernel_initializer='lecun_normal',input_shape=(chroma_cens.shape[1],7)), # each of 7 statistics is kind of like its own channel!\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Conv1D(8,1,strides=1,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Flatten(), # should have 160 if length is 20?\n","          layers.BatchNormalization(),\n","          layers.Dropout(rate=0.2),\n","          layers.Dense(80,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(40,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(32,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","\n"],"metadata":{"id":"XEOPMtUBRMFW","executionInfo":{"status":"ok","timestamp":1652199998426,"user_tz":240,"elapsed":412,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["# also need to split up xval \n","xval_chroma_cens = xval[:,:84] # length 12\n","xval_chroma_cqt = xval[:,84:168] # length 12\n","xval_chroma_stft = xval[:,168:252]# length 12\n","xval_chroma_mfcc = xval[:,252:392] # length 20\n","xval_rmse = xval[:,392:399]\n","xval_spectral_bandwidth = xval[:,399:406]\n","xval_spectral_centroid = xval[:,406:413]\n","xval_spectral_contrast = xval[:,413:462] # length 7\n","xval_spectral_rolloff = xval[:,462:469] \n","xval_tonnetz = xval[:,469:511] # length 6\n","xval_zcr = xval[:,511:518]\n","xval_dates = xval[:,518]\n","xval_duration = xval[:,519]\n","\n","order_12 = get_index_order(12)\n","order_20 = get_index_order(20)\n","order_7 = get_index_order(7)\n","order_6 = get_index_order(6)\n","\n","# reindex timeseries arrays\n","xval_chroma_cens = xval_chroma_cens[:,order_12] # length 12\n","xval_chroma_cqt = xval_chroma_cqt[:,order_12] # length 12\n","xval_chroma_stft = xval_chroma_stft[:,order_12] # length 12\n","xval_chroma_mfcc = xval_chroma_mfcc[:,order_20] # length 20\n","xval_spectral_contrast = xval_spectral_contrast[:,order_7] # length 7\n","xval_tonnetz = xval_tonnetz[:,order_6] # length 6\n","\n","xval_chroma_cens = xval_chroma_cens.reshape(xval.shape[0],int(xval_chroma_cens.shape[1]/7),7)\n","xval_chroma_cqt = xval_chroma_cqt.reshape(xval.shape[0],int(xval_chroma_cqt.shape[1]/7),7)\n","xval_chroma_stft = xval_chroma_stft.reshape(xval.shape[0],int(xval_chroma_stft.shape[1]/7),7)\n","xval_chroma_mfcc = xval_chroma_mfcc.reshape(xval.shape[0],int(xval_chroma_mfcc.shape[1]/7),7)\n","xval_rmse = xval_rmse.reshape(xval.shape[0],int(xval_rmse.shape[1]/7),7)\n","xval_spectral_bandwidth = xval_spectral_bandwidth.reshape(xval.shape[0],int(xval_spectral_bandwidth.shape[1]/7),7)\n","xval_spectral_centroid = xval_spectral_centroid.reshape(xval.shape[0],int(xval_spectral_centroid.shape[1]/7),7)\n","xval_spectral_contrast = xval_spectral_contrast.reshape(xval.shape[0],int(xval_spectral_contrast.shape[1]/7),7)\n","xval_spectral_rolloff = xval_spectral_rolloff.reshape(xval.shape[0],int(xval_spectral_rolloff.shape[1]/7),7)\n","xval_tonnetz = xval_tonnetz.reshape(xval.shape[0],int(xval_tonnetz.shape[1]/7),7)\n","xval_zcr = xval_zcr.reshape(xval.shape[0],int(xval_zcr.shape[1]/7),7)"],"metadata":{"id":"7DgOw9gBbIgf","executionInfo":{"status":"ok","timestamp":1652199428441,"user_tz":240,"elapsed":268,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["'''\n","print(xval_tonnetz.shape[0])\n","print(xval.shape[0])\n","print(yval_1hot.shape[0])\n","print(ytrain_1hot.shape[0])\n","print(chroma_cens.shape)\n","print(xtrain.shape)\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xvoBkbmf1P8D","executionInfo":{"status":"ok","timestamp":1652199433782,"user_tz":240,"elapsed":315,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"c9f1ae2f-d512-4e40-cfb2-cb6d23ab8247"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["4464\n","4464\n","4464\n","40174\n","(40174, 12, 7)\n","(40174, 520)\n"]}]},{"cell_type":"code","source":["'''\n","# let's just do some preliminary testing on this architecture for a few different things\n","#chroma_cens = chroma_cens.reshape(1,chroma_cens.shape[0],chroma_cens.shape[1])\n","#xval_chroma_cens = xval_chroma_cens.reshape(1,xval_chroma_cens.shape[0],xval_chroma_cens.shape[1])\n","#ytrain_1hot = ytrain_1hot.reshape(1,ytrain_1hot.shape[0],ytrain_1hot.shape[1])\n","#yval_1hot = yval_1hot.reshape(1,yval_1hot.shape[0],yval_1hot.shape[1])\n","chroma_cens_history = model.fit(chroma_cens_test, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_chroma_cens, yval_1hot))\n","chroma_cqt_history = model.fit(chroma_cqt, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_chroma_cqt, yval_1hot))\n","chroma_stft_history = model.fit(chroma_stft, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_chroma_stft, yval_1hot))\n","chroma_mfcc_history = model.fit(chroma_mfcc, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_chroma_mfcc, yval_1hot))\n","spectral_contrast_history = model.fit(spectral_contrast, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_spectral_contrast, yval_1hot))\n","tonnetz_history = model.fit(tonnetz, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_tonnetz, yval_1hot))\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"avMxZRJEaxsx","executionInfo":{"status":"error","timestamp":1651348387120,"user_tz":240,"elapsed":127,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"ca3094e0-edfc-4c99-fc51-9fa0bd67d25d"},"execution_count":26,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-45ed38b6d205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#ytrain_1hot = ytrain_1hot.reshape(1,ytrain_1hot.shape[0],ytrain_1hot.shape[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#yval_1hot = yval_1hot.reshape(1,yval_1hot.shape[0],yval_1hot.shape[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mchroma_cens_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchroma_cens_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval_chroma_cens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mchroma_cqt_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchroma_cqt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval_chroma_cqt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mchroma_stft_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval_chroma_stft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1652\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1\n  y sizes: 40174\nMake sure all arrays contain the same number of samples."]}]},{"cell_type":"code","source":["'''\n","#final preprocessing, hopefully: make our 7 filters\n","#chroma_cens = chroma_cens.reshape(chroma_cens.shape[0],int(chroma_cens.shape[1]/7),7)\n","xval_chroma_cens = xval_chroma_cens.reshape(xval_chroma_cens.shape[0],int(xval_chroma_cens.shape[1]/7),7)\n","# done above\n","'''"],"metadata":{"id":"WIlge3gjlRH1","executionInfo":{"status":"ok","timestamp":1652197333207,"user_tz":240,"elapsed":312,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["'''\n","print(chroma_cens.shape)\n","print(ytrain_1hot.shape)\n","print(xval_chroma_cens.shape)\n","print(yval_1hot.shape)\n","print(xval_chroma_cens.shape)\n","#print(chroma_cens_test.shape)\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PYHUSMMwdqyH","executionInfo":{"status":"ok","timestamp":1652197336196,"user_tz":240,"elapsed":269,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"4c747e4d-9d60-4c70-9854-4e198f6c5db3"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["(40174, 12, 7)\n","(40174, 16)\n","(4464, 12, 7)\n","(4464, 15)\n","(4464, 12, 7)\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QhdickqvbH3o","executionInfo":{"status":"ok","timestamp":1652199539259,"user_tz":240,"elapsed":317,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"c417acfa-bf84-4cb7-dcb5-e7a434980e99"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d_6 (Conv1D)           (None, 1, 7)              56        \n","                                                                 \n"," batch_normalization_18 (Bat  (None, 1, 7)             28        \n"," chNormalization)                                                \n","                                                                 \n"," activation_15 (Activation)  (None, 1, 7)              0         \n","                                                                 \n"," conv1d_7 (Conv1D)           (None, 1, 8)              64        \n","                                                                 \n"," batch_normalization_19 (Bat  (None, 1, 8)             32        \n"," chNormalization)                                                \n","                                                                 \n"," activation_16 (Activation)  (None, 1, 8)              0         \n","                                                                 \n"," flatten_3 (Flatten)         (None, 8)                 0         \n","                                                                 \n"," batch_normalization_20 (Bat  (None, 8)                32        \n"," chNormalization)                                                \n","                                                                 \n"," dropout_3 (Dropout)         (None, 8)                 0         \n","                                                                 \n"," dense_12 (Dense)            (None, 80)                720       \n","                                                                 \n"," batch_normalization_21 (Bat  (None, 80)               320       \n"," chNormalization)                                                \n","                                                                 \n"," activation_17 (Activation)  (None, 80)                0         \n","                                                                 \n"," dense_13 (Dense)            (None, 40)                3240      \n","                                                                 \n"," batch_normalization_22 (Bat  (None, 40)               160       \n"," chNormalization)                                                \n","                                                                 \n"," activation_18 (Activation)  (None, 40)                0         \n","                                                                 \n"," dense_14 (Dense)            (None, 32)                1312      \n","                                                                 \n"," batch_normalization_23 (Bat  (None, 32)               128       \n"," chNormalization)                                                \n","                                                                 \n"," activation_19 (Activation)  (None, 32)                0         \n","                                                                 \n"," dense_15 (Dense)            (None, 16)                528       \n","                                                                 \n","=================================================================\n","Total params: 6,620\n","Trainable params: 6,270\n","Non-trainable params: 350\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# let's just do some preliminary testing on this architecture for a few different things\n","#chroma_cens = chroma_cens.reshape(1,chroma_cens.shape[0],chroma_cens.shape[1])\n","#xval_chroma_cens = xval_chroma_cens.reshape(1,xval_chroma_cens.shape[0],xval_chroma_cens.shape[1])\n","#ytrain_1hot = ytrain_1hot.reshape(1,ytrain_1hot.shape[0],ytrain_1hot.shape[1])\n","#yval_1hot = yval_1hot.reshape(1,yval_1hot.shape[0],yval_1hot.shape[1])\n","chroma_cens_history = model.fit(chroma_cens, ytrain_1hot, batch_size=32, epochs=100, validation_data=(xval_chroma_cens, yval_1hot))\n","#chroma_cqt_history = model.fit(chroma_cqt, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_chroma_cqt, yval_1hot))\n","#chroma_stft_history = model.fit(chroma_stft, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_chroma_stft, yval_1hot))\n","#chroma_mfcc_history = model.fit(chroma_mfcc, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_chroma_mfcc, yval_1hot))\n","#spectral_contrast_history = model.fit(spectral_contrast, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_spectral_contrast, yval_1hot))\n","#tonnetz_history = model.fit(tonnetz, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_tonnetz, yval_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"x-f6RbQYozVu","executionInfo":{"status":"error","timestamp":1652200761449,"user_tz":240,"elapsed":326429,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"f32c8e3d-d174-475a-9d20-da14c4454c0b"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.6911 - accuracy: 0.4204 - val_loss: 1.7210 - val_accuracy: 0.4299\n","Epoch 2/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.6841 - accuracy: 0.4209 - val_loss: 2.0921 - val_accuracy: 0.3609\n","Epoch 3/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.6765 - accuracy: 0.4272 - val_loss: 1.6987 - val_accuracy: 0.4285\n","Epoch 4/100\n","1256/1256 [==============================] - 5s 4ms/step - loss: 1.6759 - accuracy: 0.4239 - val_loss: 1.9108 - val_accuracy: 0.4014\n","Epoch 5/100\n","1256/1256 [==============================] - 5s 4ms/step - loss: 1.6643 - accuracy: 0.4306 - val_loss: 1.6715 - val_accuracy: 0.4427\n","Epoch 6/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.6624 - accuracy: 0.4311 - val_loss: 1.9134 - val_accuracy: 0.4070\n","Epoch 7/100\n","1256/1256 [==============================] - 5s 4ms/step - loss: 1.6566 - accuracy: 0.4304 - val_loss: 1.9863 - val_accuracy: 0.3761\n","Epoch 8/100\n","1256/1256 [==============================] - 5s 4ms/step - loss: 1.6545 - accuracy: 0.4304 - val_loss: 1.9452 - val_accuracy: 0.3963\n","Epoch 9/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6493 - accuracy: 0.4338 - val_loss: 1.7003 - val_accuracy: 0.4308\n","Epoch 10/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6489 - accuracy: 0.4343 - val_loss: 1.7522 - val_accuracy: 0.4180\n","Epoch 11/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6438 - accuracy: 0.4376 - val_loss: 1.6669 - val_accuracy: 0.4368\n","Epoch 12/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6381 - accuracy: 0.4379 - val_loss: 1.6569 - val_accuracy: 0.4458\n","Epoch 13/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6367 - accuracy: 0.4390 - val_loss: 1.6675 - val_accuracy: 0.4456\n","Epoch 14/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.6327 - accuracy: 0.4392 - val_loss: 1.6702 - val_accuracy: 0.4420\n","Epoch 15/100\n","1256/1256 [==============================] - 5s 4ms/step - loss: 1.6294 - accuracy: 0.4432 - val_loss: 1.6270 - val_accuracy: 0.4547\n","Epoch 16/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.6238 - accuracy: 0.4413 - val_loss: 1.6888 - val_accuracy: 0.4317\n","Epoch 17/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6216 - accuracy: 0.4433 - val_loss: 1.8857 - val_accuracy: 0.3510\n","Epoch 18/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6224 - accuracy: 0.4434 - val_loss: 1.6759 - val_accuracy: 0.4364\n","Epoch 19/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6177 - accuracy: 0.4429 - val_loss: 1.6994 - val_accuracy: 0.4256\n","Epoch 20/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6140 - accuracy: 0.4468 - val_loss: 1.9504 - val_accuracy: 0.3703\n","Epoch 21/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6152 - accuracy: 0.4465 - val_loss: 1.9089 - val_accuracy: 0.3694\n","Epoch 22/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6147 - accuracy: 0.4461 - val_loss: 1.9472 - val_accuracy: 0.3286\n","Epoch 23/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6093 - accuracy: 0.4508 - val_loss: 1.7571 - val_accuracy: 0.4120\n","Epoch 24/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.6124 - accuracy: 0.4500 - val_loss: 1.6381 - val_accuracy: 0.4494\n","Epoch 25/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6068 - accuracy: 0.4498 - val_loss: 1.7924 - val_accuracy: 0.4131\n","Epoch 26/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6056 - accuracy: 0.4508 - val_loss: 1.9021 - val_accuracy: 0.3705\n","Epoch 27/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6042 - accuracy: 0.4512 - val_loss: 1.7322 - val_accuracy: 0.4220\n","Epoch 28/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6009 - accuracy: 0.4535 - val_loss: 1.6034 - val_accuracy: 0.4657\n","Epoch 29/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6011 - accuracy: 0.4523 - val_loss: 1.7465 - val_accuracy: 0.4061\n","Epoch 30/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.6043 - accuracy: 0.4476 - val_loss: 1.7841 - val_accuracy: 0.3808\n","Epoch 31/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5962 - accuracy: 0.4556 - val_loss: 1.8314 - val_accuracy: 0.3842\n","Epoch 32/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5926 - accuracy: 0.4553 - val_loss: 1.6164 - val_accuracy: 0.4586\n","Epoch 33/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5952 - accuracy: 0.4553 - val_loss: 1.7373 - val_accuracy: 0.4167\n","Epoch 34/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5923 - accuracy: 0.4540 - val_loss: 1.7331 - val_accuracy: 0.4126\n","Epoch 35/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5938 - accuracy: 0.4523 - val_loss: 1.5980 - val_accuracy: 0.4651\n","Epoch 36/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5881 - accuracy: 0.4569 - val_loss: 1.6860 - val_accuracy: 0.4366\n","Epoch 37/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5897 - accuracy: 0.4547 - val_loss: 1.8487 - val_accuracy: 0.3741\n","Epoch 38/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5891 - accuracy: 0.4586 - val_loss: 1.6182 - val_accuracy: 0.4534\n","Epoch 39/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.5873 - accuracy: 0.4570 - val_loss: 1.6264 - val_accuracy: 0.4608\n","Epoch 40/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5873 - accuracy: 0.4561 - val_loss: 1.6108 - val_accuracy: 0.4568\n","Epoch 41/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5843 - accuracy: 0.4567 - val_loss: 1.6045 - val_accuracy: 0.4657\n","Epoch 42/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.5809 - accuracy: 0.4589 - val_loss: 1.6519 - val_accuracy: 0.4420\n","Epoch 43/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.5837 - accuracy: 0.4579 - val_loss: 1.6270 - val_accuracy: 0.4453\n","Epoch 44/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5819 - accuracy: 0.4580 - val_loss: 1.6528 - val_accuracy: 0.4357\n","Epoch 45/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5778 - accuracy: 0.4583 - val_loss: 1.6655 - val_accuracy: 0.4453\n","Epoch 46/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.5808 - accuracy: 0.4584 - val_loss: 1.5872 - val_accuracy: 0.4695\n","Epoch 47/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5782 - accuracy: 0.4603 - val_loss: 1.5968 - val_accuracy: 0.4666\n","Epoch 48/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5777 - accuracy: 0.4577 - val_loss: 1.5859 - val_accuracy: 0.4711\n","Epoch 49/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5749 - accuracy: 0.4597 - val_loss: 1.5791 - val_accuracy: 0.4785\n","Epoch 50/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5734 - accuracy: 0.4618 - val_loss: 1.8062 - val_accuracy: 0.3869\n","Epoch 51/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5740 - accuracy: 0.4592 - val_loss: 1.6284 - val_accuracy: 0.4483\n","Epoch 52/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5738 - accuracy: 0.4621 - val_loss: 1.6565 - val_accuracy: 0.4413\n","Epoch 53/100\n","1256/1256 [==============================] - 6s 5ms/step - loss: 1.5729 - accuracy: 0.4616 - val_loss: 1.6772 - val_accuracy: 0.4355\n","Epoch 54/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.5713 - accuracy: 0.4624 - val_loss: 1.7380 - val_accuracy: 0.4138\n","Epoch 55/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.5715 - accuracy: 0.4631 - val_loss: 1.7448 - val_accuracy: 0.4084\n","Epoch 56/100\n","1256/1256 [==============================] - 6s 4ms/step - loss: 1.5724 - accuracy: 0.4617 - val_loss: 1.7381 - val_accuracy: 0.4095\n","Epoch 57/100\n"," 990/1256 [======================>.......] - ETA: 1s - loss: 1.5699 - accuracy: 0.4612"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-e8f145b9b588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#ytrain_1hot = ytrain_1hot.reshape(1,ytrain_1hot.shape[0],ytrain_1hot.shape[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#yval_1hot = yval_1hot.reshape(1,yval_1hot.shape[0],yval_1hot.shape[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mchroma_cens_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchroma_cens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval_chroma_cens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#chroma_cqt_history = model.fit(chroma_cqt, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_chroma_cqt, yval_1hot))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#chroma_stft_history = model.fit(chroma_stft, ytrain_1hot, batch_size=32, epochs=10, validation_data=(xval_chroma_stft, yval_1hot))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["layer_list = [\n","          #layers.BatchNormalization(),\n","          #layers.Conv1D(4,7,strides=7,kernel_initializer='lecun_normal',input_shape=(xtrain.shape[0],84)), #what if we just make 2nd dim xtrain.shape[1]?\n","          layers.Conv1D(100,2,strides=1,kernel_initializer='lecun_normal',padding='valid',input_shape=(chroma_cens.shape[1],7)), # each of 7 statistics is kind of like its own channel!\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Flatten(), # should have 160 if length is 20?\n","          #layers.Dropout(rate=0.2),\n","          layers.Dense(80,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(40,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(32,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n"],"metadata":{"id":"pRydXcS6yGBv","executionInfo":{"status":"ok","timestamp":1652201035545,"user_tz":240,"elapsed":298,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["chroma_cens_history = model.fit(chroma_cens, ytrain_1hot, batch_size=32, epochs=100, validation_data=(xval_chroma_cens, yval_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPyfWbRQ22zl","executionInfo":{"status":"ok","timestamp":1652201923285,"user_tz":240,"elapsed":863467,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"cc32366b-e529-419e-a5d9-dd3eaadf2272"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1256/1256 [==============================] - 8s 6ms/step - loss: 1.9884 - accuracy: 0.3347 - val_loss: 1.8796 - val_accuracy: 0.3600\n","Epoch 2/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.7759 - accuracy: 0.3915 - val_loss: 1.9931 - val_accuracy: 0.3190\n","Epoch 3/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.7249 - accuracy: 0.4128 - val_loss: 1.8280 - val_accuracy: 0.3676\n","Epoch 4/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.6911 - accuracy: 0.4243 - val_loss: 1.7441 - val_accuracy: 0.4084\n","Epoch 5/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.6650 - accuracy: 0.4341 - val_loss: 1.6858 - val_accuracy: 0.4384\n","Epoch 6/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.6432 - accuracy: 0.4396 - val_loss: 1.9749 - val_accuracy: 0.3190\n","Epoch 7/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.6252 - accuracy: 0.4466 - val_loss: 1.6977 - val_accuracy: 0.4209\n","Epoch 8/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.6088 - accuracy: 0.4529 - val_loss: 1.7694 - val_accuracy: 0.3828\n","Epoch 9/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.5914 - accuracy: 0.4586 - val_loss: 2.3033 - val_accuracy: 0.2213\n","Epoch 10/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.5780 - accuracy: 0.4639 - val_loss: 1.7750 - val_accuracy: 0.3851\n","Epoch 11/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.5654 - accuracy: 0.4697 - val_loss: 2.1314 - val_accuracy: 0.2583\n","Epoch 12/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.5550 - accuracy: 0.4711 - val_loss: 1.7320 - val_accuracy: 0.3992\n","Epoch 13/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.5442 - accuracy: 0.4774 - val_loss: 1.9517 - val_accuracy: 0.3358\n","Epoch 14/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.5352 - accuracy: 0.4804 - val_loss: 1.6194 - val_accuracy: 0.4583\n","Epoch 15/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.5261 - accuracy: 0.4812 - val_loss: 1.8432 - val_accuracy: 0.3589\n","Epoch 16/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.5140 - accuracy: 0.4879 - val_loss: 2.1407 - val_accuracy: 0.2959\n","Epoch 17/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.5092 - accuracy: 0.4900 - val_loss: 1.6667 - val_accuracy: 0.4427\n","Epoch 18/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.4967 - accuracy: 0.4932 - val_loss: 1.6431 - val_accuracy: 0.4570\n","Epoch 19/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.4890 - accuracy: 0.4944 - val_loss: 1.9954 - val_accuracy: 0.3080\n","Epoch 20/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.4862 - accuracy: 0.4994 - val_loss: 1.8127 - val_accuracy: 0.3743\n","Epoch 21/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.4788 - accuracy: 0.4986 - val_loss: 1.9502 - val_accuracy: 0.3580\n","Epoch 22/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.4689 - accuracy: 0.5021 - val_loss: 1.6919 - val_accuracy: 0.4319\n","Epoch 23/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.4641 - accuracy: 0.5040 - val_loss: 1.6467 - val_accuracy: 0.4422\n","Epoch 24/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.4559 - accuracy: 0.5076 - val_loss: 1.6232 - val_accuracy: 0.4597\n","Epoch 25/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.4483 - accuracy: 0.5072 - val_loss: 2.0133 - val_accuracy: 0.3123\n","Epoch 26/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.4456 - accuracy: 0.5111 - val_loss: 1.6498 - val_accuracy: 0.4384\n","Epoch 27/100\n","1256/1256 [==============================] - 7s 6ms/step - loss: 1.4401 - accuracy: 0.5151 - val_loss: 1.9961 - val_accuracy: 0.3761\n","Epoch 28/100\n","1256/1256 [==============================] - 8s 6ms/step - loss: 1.4375 - accuracy: 0.5150 - val_loss: 1.6253 - val_accuracy: 0.4525\n","Epoch 29/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.4276 - accuracy: 0.5150 - val_loss: 1.5946 - val_accuracy: 0.4659\n","Epoch 30/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.4187 - accuracy: 0.5218 - val_loss: 1.7128 - val_accuracy: 0.4223\n","Epoch 31/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4149 - accuracy: 0.5226 - val_loss: 2.0944 - val_accuracy: 0.3174\n","Epoch 32/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4065 - accuracy: 0.5244 - val_loss: 2.2311 - val_accuracy: 0.2666\n","Epoch 33/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4018 - accuracy: 0.5262 - val_loss: 1.6537 - val_accuracy: 0.4487\n","Epoch 34/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.3990 - accuracy: 0.5270 - val_loss: 1.6003 - val_accuracy: 0.4651\n","Epoch 35/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3943 - accuracy: 0.5292 - val_loss: 1.9323 - val_accuracy: 0.3914\n","Epoch 36/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3913 - accuracy: 0.5269 - val_loss: 1.7281 - val_accuracy: 0.4140\n","Epoch 37/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3824 - accuracy: 0.5314 - val_loss: 1.8362 - val_accuracy: 0.3817\n","Epoch 38/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3789 - accuracy: 0.5328 - val_loss: 2.0443 - val_accuracy: 0.3439\n","Epoch 39/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.3763 - accuracy: 0.5355 - val_loss: 1.7571 - val_accuracy: 0.4245\n","Epoch 40/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.3695 - accuracy: 0.5343 - val_loss: 1.6142 - val_accuracy: 0.4639\n","Epoch 41/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.3635 - accuracy: 0.5389 - val_loss: 2.3455 - val_accuracy: 0.2440\n","Epoch 42/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.3613 - accuracy: 0.5389 - val_loss: 2.1628 - val_accuracy: 0.3347\n","Epoch 43/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3522 - accuracy: 0.5408 - val_loss: 1.7127 - val_accuracy: 0.4265\n","Epoch 44/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.3485 - accuracy: 0.5425 - val_loss: 1.7670 - val_accuracy: 0.4234\n","Epoch 45/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3450 - accuracy: 0.5455 - val_loss: 1.7339 - val_accuracy: 0.4281\n","Epoch 46/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3376 - accuracy: 0.5475 - val_loss: 1.6639 - val_accuracy: 0.4476\n","Epoch 47/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3366 - accuracy: 0.5469 - val_loss: 1.9244 - val_accuracy: 0.3723\n","Epoch 48/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3284 - accuracy: 0.5501 - val_loss: 2.1081 - val_accuracy: 0.3078\n","Epoch 49/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3288 - accuracy: 0.5484 - val_loss: 1.6490 - val_accuracy: 0.4556\n","Epoch 50/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.3223 - accuracy: 0.5520 - val_loss: 2.1118 - val_accuracy: 0.3076\n","Epoch 51/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.3190 - accuracy: 0.5562 - val_loss: 1.6320 - val_accuracy: 0.4642\n","Epoch 52/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3175 - accuracy: 0.5533 - val_loss: 1.8227 - val_accuracy: 0.4001\n","Epoch 53/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.3085 - accuracy: 0.5585 - val_loss: 2.7037 - val_accuracy: 0.2220\n","Epoch 54/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.3057 - accuracy: 0.5568 - val_loss: 1.7888 - val_accuracy: 0.4176\n","Epoch 55/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3060 - accuracy: 0.5565 - val_loss: 1.6775 - val_accuracy: 0.4523\n","Epoch 56/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2981 - accuracy: 0.5607 - val_loss: 1.6771 - val_accuracy: 0.4512\n","Epoch 57/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2957 - accuracy: 0.5637 - val_loss: 1.6472 - val_accuracy: 0.4626\n","Epoch 58/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2921 - accuracy: 0.5610 - val_loss: 1.9369 - val_accuracy: 0.3844\n","Epoch 59/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2844 - accuracy: 0.5642 - val_loss: 1.8532 - val_accuracy: 0.4079\n","Epoch 60/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2796 - accuracy: 0.5688 - val_loss: 2.0875 - val_accuracy: 0.3206\n","Epoch 61/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2794 - accuracy: 0.5657 - val_loss: 2.3410 - val_accuracy: 0.2632\n","Epoch 62/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2748 - accuracy: 0.5676 - val_loss: 1.8582 - val_accuracy: 0.3898\n","Epoch 63/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2733 - accuracy: 0.5680 - val_loss: 1.9825 - val_accuracy: 0.3625\n","Epoch 64/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2720 - accuracy: 0.5665 - val_loss: 2.0780 - val_accuracy: 0.3490\n","Epoch 65/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2658 - accuracy: 0.5703 - val_loss: 1.6502 - val_accuracy: 0.4655\n","Epoch 66/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2611 - accuracy: 0.5723 - val_loss: 1.9064 - val_accuracy: 0.3779\n","Epoch 67/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2571 - accuracy: 0.5741 - val_loss: 1.6527 - val_accuracy: 0.4572\n","Epoch 68/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2542 - accuracy: 0.5757 - val_loss: 1.9605 - val_accuracy: 0.3837\n","Epoch 69/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2554 - accuracy: 0.5742 - val_loss: 2.1215 - val_accuracy: 0.3206\n","Epoch 70/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2487 - accuracy: 0.5768 - val_loss: 1.8112 - val_accuracy: 0.4064\n","Epoch 71/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2461 - accuracy: 0.5782 - val_loss: 1.7190 - val_accuracy: 0.4467\n","Epoch 72/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2449 - accuracy: 0.5785 - val_loss: 2.4865 - val_accuracy: 0.2525\n","Epoch 73/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2453 - accuracy: 0.5776 - val_loss: 1.7348 - val_accuracy: 0.4368\n","Epoch 74/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2336 - accuracy: 0.5833 - val_loss: 1.6978 - val_accuracy: 0.4487\n","Epoch 75/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2323 - accuracy: 0.5826 - val_loss: 1.9207 - val_accuracy: 0.3976\n","Epoch 76/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2299 - accuracy: 0.5859 - val_loss: 2.1970 - val_accuracy: 0.3067\n","Epoch 77/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2290 - accuracy: 0.5841 - val_loss: 1.7917 - val_accuracy: 0.4339\n","Epoch 78/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2237 - accuracy: 0.5863 - val_loss: 1.7229 - val_accuracy: 0.4536\n","Epoch 79/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2211 - accuracy: 0.5875 - val_loss: 1.9482 - val_accuracy: 0.3925\n","Epoch 80/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2208 - accuracy: 0.5879 - val_loss: 2.4696 - val_accuracy: 0.2352\n","Epoch 81/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2168 - accuracy: 0.5892 - val_loss: 1.7093 - val_accuracy: 0.4476\n","Epoch 82/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2089 - accuracy: 0.5890 - val_loss: 1.9552 - val_accuracy: 0.4012\n","Epoch 83/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.2146 - accuracy: 0.5885 - val_loss: 1.7539 - val_accuracy: 0.4447\n","Epoch 84/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2090 - accuracy: 0.5895 - val_loss: 1.9605 - val_accuracy: 0.3983\n","Epoch 85/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2078 - accuracy: 0.5912 - val_loss: 1.9776 - val_accuracy: 0.3761\n","Epoch 86/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1997 - accuracy: 0.5917 - val_loss: 1.7627 - val_accuracy: 0.4330\n","Epoch 87/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.1994 - accuracy: 0.5926 - val_loss: 2.0824 - val_accuracy: 0.3358\n","Epoch 88/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1985 - accuracy: 0.5909 - val_loss: 2.1566 - val_accuracy: 0.3212\n","Epoch 89/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.1974 - accuracy: 0.5930 - val_loss: 1.8333 - val_accuracy: 0.4086\n","Epoch 90/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1897 - accuracy: 0.5960 - val_loss: 1.6941 - val_accuracy: 0.4579\n","Epoch 91/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1873 - accuracy: 0.5964 - val_loss: 2.0753 - val_accuracy: 0.3519\n","Epoch 92/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.1892 - accuracy: 0.5950 - val_loss: 1.9663 - val_accuracy: 0.3858\n","Epoch 93/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1806 - accuracy: 0.5980 - val_loss: 1.7042 - val_accuracy: 0.4612\n","Epoch 94/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1781 - accuracy: 0.5989 - val_loss: 1.9317 - val_accuracy: 0.4001\n","Epoch 95/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1829 - accuracy: 0.5986 - val_loss: 1.7515 - val_accuracy: 0.4456\n","Epoch 96/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1789 - accuracy: 0.5982 - val_loss: 2.3986 - val_accuracy: 0.2625\n","Epoch 97/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.1765 - accuracy: 0.6034 - val_loss: 1.8140 - val_accuracy: 0.4173\n","Epoch 98/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.1710 - accuracy: 0.6015 - val_loss: 1.8520 - val_accuracy: 0.4223\n","Epoch 99/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.1695 - accuracy: 0.6058 - val_loss: 1.7564 - val_accuracy: 0.4418\n","Epoch 100/100\n","1256/1256 [==============================] - 7s 5ms/step - loss: 1.1628 - accuracy: 0.6045 - val_loss: 2.3719 - val_accuracy: 0.3217\n"]}]},{"cell_type":"code","source":["'''\n","big_CNN_thing = np.concatenate((chroma_cens,chroma_cqt,chroma_stft,chroma_mfcc,rmse,spectral_centroid,spectral_bandwidth,spectral_contrast,spectral_rolloff,tonnetz,zcr),axis=-1)\n","big_CNN_thing_val = np.concatenate((xval_chroma_cens,xval_chroma_cqt,xval_chroma_stft,xval_chroma_mfcc,xval_rmse,xval_spectral_centroid,xval_spectral_bandwidth,xval_spectral_contrast,xval_spectral_rolloff,xval_tonnetz,xval_zcr),axis=-1)\n","print(big_CNN_thing.shape)\n","print(big_CNN_thing_val.shape)\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"6JyMcewm6SSS","executionInfo":{"status":"error","timestamp":1652203188611,"user_tz":240,"elapsed":283,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"c523049f-69d1-4879-a610-3e45e07e7f44"},"execution_count":55,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-9060c73913e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbig_CNN_thing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchroma_cens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchroma_cqt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchroma_mfcc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspectral_centroid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspectral_bandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspectral_contrast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspectral_rolloff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtonnetz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzcr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbig_CNN_thing_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval_chroma_cens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval_chroma_cqt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval_chroma_stft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval_chroma_mfcc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval_rmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval_spectral_centroid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval_spectral_bandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval_spectral_contrast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval_spectral_rolloff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval_tonnetz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxval_zcr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_CNN_thing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_CNN_thing_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 12 and the array at index 3 has size 20"]}]},{"cell_type":"code","source":["big_CNN_thing = np.concatenate((chroma_cens,chroma_cqt,chroma_stft,),axis=-1) # the things of length 12\n","big_CNN_thing_val = np.concatenate((xval_chroma_cens,xval_chroma_cqt,xval_chroma_stft),axis=-1)\n","print(big_CNN_thing.shape)\n","print(big_CNN_thing_val.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8dKC6yB_wfv","executionInfo":{"status":"ok","timestamp":1652203543207,"user_tz":240,"elapsed":372,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"86c07401-46b1-495c-d167-4b2a19879a1d"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["(40174, 12, 21)\n","(4464, 12, 21)\n"]}]},{"cell_type":"code","source":["layer_list = [\n","          layers.BatchNormalization(),\n","          #layers.Conv1D(4,7,strides=7,kernel_initializer='lecun_normal',input_shape=(xtrain.shape[0],84)), #what if we just make 2nd dim xtrain.shape[1]?\n","          layers.Conv1D(100,2,strides=1,kernel_initializer='lecun_normal',padding='valid',input_shape=(big_CNN_thing.shape[1],7)), # each of 7 statistics is kind of like its own channel!\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Conv1D(200,2,strides=2,kernel_initializer='lecun_normal',padding='valid'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Flatten(), \n","          #layers.Dropout(rate=0.2),\n","          layers.Dense(80,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(40,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(32,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","big_CNN_thing_history = model.fit(big_CNN_thing, ytrain_1hot, batch_size=32, epochs=100, validation_data=(big_CNN_thing_val, yval_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"61Vjv-EpAXMh","executionInfo":{"status":"error","timestamp":1652208486478,"user_tz":240,"elapsed":537006,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"d8f935cc-c1e5-4465-a7e0-fbf17b4b8863"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1256/1256 [==============================] - 13s 9ms/step - loss: 1.7036 - accuracy: 0.4587 - val_loss: 1.5511 - val_accuracy: 0.4888\n","Epoch 2/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.4834 - accuracy: 0.5089 - val_loss: 1.4736 - val_accuracy: 0.5343\n","Epoch 3/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.4328 - accuracy: 0.5277 - val_loss: 1.4685 - val_accuracy: 0.5284\n","Epoch 4/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.4027 - accuracy: 0.5392 - val_loss: 1.4386 - val_accuracy: 0.5347\n","Epoch 5/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.3739 - accuracy: 0.5472 - val_loss: 1.4188 - val_accuracy: 0.5361\n","Epoch 6/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.3510 - accuracy: 0.5545 - val_loss: 1.3897 - val_accuracy: 0.5533\n","Epoch 7/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.3344 - accuracy: 0.5627 - val_loss: 1.4160 - val_accuracy: 0.5441\n","Epoch 8/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.3137 - accuracy: 0.5686 - val_loss: 1.3711 - val_accuracy: 0.5643\n","Epoch 9/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.2970 - accuracy: 0.5751 - val_loss: 1.4248 - val_accuracy: 0.5423\n","Epoch 10/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.2788 - accuracy: 0.5788 - val_loss: 1.4020 - val_accuracy: 0.5562\n","Epoch 11/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.2597 - accuracy: 0.5870 - val_loss: 1.3905 - val_accuracy: 0.5607\n","Epoch 12/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.2461 - accuracy: 0.5893 - val_loss: 1.4222 - val_accuracy: 0.5495\n","Epoch 13/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.2265 - accuracy: 0.5981 - val_loss: 1.3649 - val_accuracy: 0.5694\n","Epoch 14/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.2134 - accuracy: 0.5993 - val_loss: 1.3665 - val_accuracy: 0.5623\n","Epoch 15/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.1992 - accuracy: 0.6042 - val_loss: 1.3441 - val_accuracy: 0.5791\n","Epoch 16/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.1820 - accuracy: 0.6122 - val_loss: 1.3746 - val_accuracy: 0.5643\n","Epoch 17/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.1650 - accuracy: 0.6157 - val_loss: 1.4232 - val_accuracy: 0.5466\n","Epoch 18/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.1500 - accuracy: 0.6180 - val_loss: 1.3973 - val_accuracy: 0.5661\n","Epoch 19/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.1383 - accuracy: 0.6222 - val_loss: 1.3815 - val_accuracy: 0.5685\n","Epoch 20/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.1166 - accuracy: 0.6296 - val_loss: 1.4046 - val_accuracy: 0.5621\n","Epoch 21/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.1013 - accuracy: 0.6341 - val_loss: 1.3918 - val_accuracy: 0.5643\n","Epoch 22/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.0926 - accuracy: 0.6391 - val_loss: 1.4017 - val_accuracy: 0.5634\n","Epoch 23/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.0743 - accuracy: 0.6425 - val_loss: 1.4170 - val_accuracy: 0.5632\n","Epoch 24/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.0528 - accuracy: 0.6475 - val_loss: 1.3777 - val_accuracy: 0.5802\n","Epoch 25/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.0428 - accuracy: 0.6516 - val_loss: 1.4131 - val_accuracy: 0.5719\n","Epoch 26/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.0307 - accuracy: 0.6577 - val_loss: 1.4160 - val_accuracy: 0.5710\n","Epoch 27/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.0179 - accuracy: 0.6608 - val_loss: 1.4811 - val_accuracy: 0.5535\n","Epoch 28/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.0095 - accuracy: 0.6638 - val_loss: 1.5595 - val_accuracy: 0.5428\n","Epoch 29/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 0.9885 - accuracy: 0.6686 - val_loss: 1.4899 - val_accuracy: 0.5538\n","Epoch 30/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.9772 - accuracy: 0.6708 - val_loss: 1.4575 - val_accuracy: 0.5641\n","Epoch 31/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 0.9600 - accuracy: 0.6771 - val_loss: 1.5310 - val_accuracy: 0.5477\n","Epoch 32/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 0.9444 - accuracy: 0.6821 - val_loss: 1.4991 - val_accuracy: 0.5582\n","Epoch 33/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.9377 - accuracy: 0.6837 - val_loss: 1.5048 - val_accuracy: 0.5576\n","Epoch 34/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.9211 - accuracy: 0.6891 - val_loss: 1.4761 - val_accuracy: 0.5591\n","Epoch 35/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.9114 - accuracy: 0.6936 - val_loss: 1.5307 - val_accuracy: 0.5535\n","Epoch 36/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.8928 - accuracy: 0.6967 - val_loss: 1.5372 - val_accuracy: 0.5544\n","Epoch 37/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.8865 - accuracy: 0.6998 - val_loss: 1.5346 - val_accuracy: 0.5553\n","Epoch 38/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 0.8685 - accuracy: 0.7051 - val_loss: 1.5542 - val_accuracy: 0.5589\n","Epoch 39/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 0.8643 - accuracy: 0.7041 - val_loss: 1.6152 - val_accuracy: 0.5453\n","Epoch 40/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 0.8459 - accuracy: 0.7113 - val_loss: 1.6061 - val_accuracy: 0.5509\n","Epoch 41/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 0.8370 - accuracy: 0.7144 - val_loss: 1.5879 - val_accuracy: 0.5589\n","Epoch 42/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.8183 - accuracy: 0.7236 - val_loss: 1.7516 - val_accuracy: 0.5309\n","Epoch 43/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.8164 - accuracy: 0.7209 - val_loss: 1.5974 - val_accuracy: 0.5509\n","Epoch 44/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.8024 - accuracy: 0.7253 - val_loss: 1.6330 - val_accuracy: 0.5497\n","Epoch 45/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.7967 - accuracy: 0.7283 - val_loss: 1.6454 - val_accuracy: 0.5421\n","Epoch 46/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 0.7808 - accuracy: 0.7340 - val_loss: 1.6832 - val_accuracy: 0.5497\n","Epoch 47/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.7695 - accuracy: 0.7363 - val_loss: 1.6973 - val_accuracy: 0.5397\n","Epoch 48/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 0.7642 - accuracy: 0.7358 - val_loss: 1.6798 - val_accuracy: 0.5358\n","Epoch 49/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 0.7488 - accuracy: 0.7412 - val_loss: 1.8506 - val_accuracy: 0.5269\n","Epoch 50/100\n","1060/1256 [========================>.....] - ETA: 1s - loss: 0.7354 - accuracy: 0.7489"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-dd17603a189d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n\u001b[1;32m     26\u001b[0m     loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mbig_CNN_thing_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_CNN_thing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_CNN_thing_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["layer_list = [\n","          layers.BatchNormalization(),\n","          #layers.Conv1D(4,7,strides=7,kernel_initializer='lecun_normal',input_shape=(xtrain.shape[0],84)), #what if we just make 2nd dim xtrain.shape[1]?\n","          layers.Conv1D(100,2,strides=1,kernel_initializer='lecun_normal',padding='valid',input_shape=(big_CNN_thing.shape[1],7)), # each of 7 statistics is kind of like its own channel!\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Conv1D(200,2,strides=2,kernel_initializer='lecun_normal',padding='valid'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Flatten(), \n","          #layers.Dropout(rate=0.2),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","big_CNN_thing_history = model.fit(big_CNN_thing, ytrain_1hot, batch_size=32, epochs=100, validation_data=(big_CNN_thing_val, yval_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76yL9hryC82Z","executionInfo":{"status":"ok","timestamp":1652205517474,"user_tz":240,"elapsed":871683,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"3a3fd2eb-6893-4295-cd64-3535d9e5ff23"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.7215 - accuracy: 0.4427 - val_loss: 1.6500 - val_accuracy: 0.4648\n","Epoch 2/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5603 - accuracy: 0.4889 - val_loss: 1.5976 - val_accuracy: 0.4810\n","Epoch 3/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5066 - accuracy: 0.5046 - val_loss: 1.6085 - val_accuracy: 0.4899\n","Epoch 4/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4772 - accuracy: 0.5179 - val_loss: 1.5603 - val_accuracy: 0.4960\n","Epoch 5/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4466 - accuracy: 0.5254 - val_loss: 1.5180 - val_accuracy: 0.5184\n","Epoch 6/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4204 - accuracy: 0.5351 - val_loss: 1.5125 - val_accuracy: 0.5164\n","Epoch 7/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4012 - accuracy: 0.5388 - val_loss: 1.4894 - val_accuracy: 0.5251\n","Epoch 8/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3855 - accuracy: 0.5463 - val_loss: 1.4860 - val_accuracy: 0.5246\n","Epoch 9/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3665 - accuracy: 0.5495 - val_loss: 1.4815 - val_accuracy: 0.5276\n","Epoch 10/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3528 - accuracy: 0.5551 - val_loss: 1.4552 - val_accuracy: 0.5392\n","Epoch 11/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3422 - accuracy: 0.5571 - val_loss: 1.4599 - val_accuracy: 0.5417\n","Epoch 12/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.3325 - accuracy: 0.5600 - val_loss: 1.4519 - val_accuracy: 0.5428\n","Epoch 13/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3212 - accuracy: 0.5623 - val_loss: 1.4667 - val_accuracy: 0.5397\n","Epoch 14/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3106 - accuracy: 0.5698 - val_loss: 1.4540 - val_accuracy: 0.5401\n","Epoch 15/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3044 - accuracy: 0.5711 - val_loss: 1.4604 - val_accuracy: 0.5502\n","Epoch 16/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2913 - accuracy: 0.5740 - val_loss: 1.4554 - val_accuracy: 0.5334\n","Epoch 17/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2828 - accuracy: 0.5777 - val_loss: 1.4548 - val_accuracy: 0.5374\n","Epoch 18/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2760 - accuracy: 0.5780 - val_loss: 1.4809 - val_accuracy: 0.5414\n","Epoch 19/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2663 - accuracy: 0.5821 - val_loss: 1.4452 - val_accuracy: 0.5473\n","Epoch 20/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2589 - accuracy: 0.5838 - val_loss: 1.4296 - val_accuracy: 0.5520\n","Epoch 21/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2535 - accuracy: 0.5843 - val_loss: 1.4282 - val_accuracy: 0.5470\n","Epoch 22/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2457 - accuracy: 0.5880 - val_loss: 1.5045 - val_accuracy: 0.5289\n","Epoch 23/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2408 - accuracy: 0.5866 - val_loss: 1.4967 - val_accuracy: 0.5461\n","Epoch 24/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2340 - accuracy: 0.5900 - val_loss: 1.4263 - val_accuracy: 0.5509\n","Epoch 25/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2297 - accuracy: 0.5905 - val_loss: 1.4401 - val_accuracy: 0.5578\n","Epoch 26/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2241 - accuracy: 0.5938 - val_loss: 1.4645 - val_accuracy: 0.5408\n","Epoch 27/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2180 - accuracy: 0.5931 - val_loss: 1.5035 - val_accuracy: 0.5278\n","Epoch 28/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2112 - accuracy: 0.5956 - val_loss: 1.4830 - val_accuracy: 0.5338\n","Epoch 29/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2077 - accuracy: 0.5977 - val_loss: 1.4543 - val_accuracy: 0.5520\n","Epoch 30/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1984 - accuracy: 0.6014 - val_loss: 1.4710 - val_accuracy: 0.5441\n","Epoch 31/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1936 - accuracy: 0.6018 - val_loss: 1.4882 - val_accuracy: 0.5320\n","Epoch 32/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1913 - accuracy: 0.6012 - val_loss: 1.4485 - val_accuracy: 0.5477\n","Epoch 33/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.1845 - accuracy: 0.6037 - val_loss: 1.4498 - val_accuracy: 0.5576\n","Epoch 34/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1779 - accuracy: 0.6067 - val_loss: 1.4578 - val_accuracy: 0.5558\n","Epoch 35/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.1756 - accuracy: 0.6101 - val_loss: 1.5057 - val_accuracy: 0.5293\n","Epoch 36/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.1740 - accuracy: 0.6082 - val_loss: 1.4422 - val_accuracy: 0.5632\n","Epoch 37/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1667 - accuracy: 0.6080 - val_loss: 1.4793 - val_accuracy: 0.5410\n","Epoch 38/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1637 - accuracy: 0.6116 - val_loss: 1.5116 - val_accuracy: 0.5426\n","Epoch 39/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1568 - accuracy: 0.6129 - val_loss: 1.5410 - val_accuracy: 0.5323\n","Epoch 40/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1534 - accuracy: 0.6128 - val_loss: 1.4773 - val_accuracy: 0.5515\n","Epoch 41/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1502 - accuracy: 0.6128 - val_loss: 1.4849 - val_accuracy: 0.5468\n","Epoch 42/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1410 - accuracy: 0.6172 - val_loss: 1.4566 - val_accuracy: 0.5544\n","Epoch 43/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1455 - accuracy: 0.6154 - val_loss: 1.4581 - val_accuracy: 0.5600\n","Epoch 44/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1382 - accuracy: 0.6180 - val_loss: 1.4825 - val_accuracy: 0.5529\n","Epoch 45/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1328 - accuracy: 0.6212 - val_loss: 1.4723 - val_accuracy: 0.5506\n","Epoch 46/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1310 - accuracy: 0.6219 - val_loss: 1.4718 - val_accuracy: 0.5513\n","Epoch 47/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1262 - accuracy: 0.6225 - val_loss: 1.5219 - val_accuracy: 0.5468\n","Epoch 48/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1206 - accuracy: 0.6258 - val_loss: 1.4924 - val_accuracy: 0.5524\n","Epoch 49/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1154 - accuracy: 0.6254 - val_loss: 1.5513 - val_accuracy: 0.5258\n","Epoch 50/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.1119 - accuracy: 0.6291 - val_loss: 1.5087 - val_accuracy: 0.5488\n","Epoch 51/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1115 - accuracy: 0.6255 - val_loss: 1.5547 - val_accuracy: 0.5334\n","Epoch 52/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.1042 - accuracy: 0.6293 - val_loss: 1.5041 - val_accuracy: 0.5464\n","Epoch 53/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.1025 - accuracy: 0.6292 - val_loss: 1.6208 - val_accuracy: 0.5159\n","Epoch 54/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.0938 - accuracy: 0.6333 - val_loss: 1.5283 - val_accuracy: 0.5477\n","Epoch 55/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.0950 - accuracy: 0.6297 - val_loss: 1.5089 - val_accuracy: 0.5441\n","Epoch 56/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0924 - accuracy: 0.6323 - val_loss: 1.4891 - val_accuracy: 0.5529\n","Epoch 57/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.0907 - accuracy: 0.6328 - val_loss: 1.4869 - val_accuracy: 0.5453\n","Epoch 58/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.0874 - accuracy: 0.6341 - val_loss: 1.4990 - val_accuracy: 0.5497\n","Epoch 59/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.0824 - accuracy: 0.6348 - val_loss: 1.5390 - val_accuracy: 0.5401\n","Epoch 60/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0791 - accuracy: 0.6363 - val_loss: 1.5225 - val_accuracy: 0.5473\n","Epoch 61/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.0784 - accuracy: 0.6372 - val_loss: 1.5207 - val_accuracy: 0.5486\n","Epoch 62/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0705 - accuracy: 0.6396 - val_loss: 1.5310 - val_accuracy: 0.5390\n","Epoch 63/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0646 - accuracy: 0.6416 - val_loss: 1.4994 - val_accuracy: 0.5538\n","Epoch 64/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0646 - accuracy: 0.6404 - val_loss: 1.5083 - val_accuracy: 0.5500\n","Epoch 65/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0635 - accuracy: 0.6405 - val_loss: 1.5106 - val_accuracy: 0.5578\n","Epoch 66/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.0611 - accuracy: 0.6430 - val_loss: 1.5414 - val_accuracy: 0.5453\n","Epoch 67/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0567 - accuracy: 0.6454 - val_loss: 1.5501 - val_accuracy: 0.5437\n","Epoch 68/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0548 - accuracy: 0.6454 - val_loss: 1.5350 - val_accuracy: 0.5461\n","Epoch 69/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0548 - accuracy: 0.6424 - val_loss: 1.6017 - val_accuracy: 0.5311\n","Epoch 70/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0496 - accuracy: 0.6448 - val_loss: 1.5109 - val_accuracy: 0.5589\n","Epoch 71/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.0480 - accuracy: 0.6456 - val_loss: 1.5629 - val_accuracy: 0.5446\n","Epoch 72/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0411 - accuracy: 0.6497 - val_loss: 1.5492 - val_accuracy: 0.5486\n","Epoch 73/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0390 - accuracy: 0.6470 - val_loss: 1.5246 - val_accuracy: 0.5551\n","Epoch 74/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0367 - accuracy: 0.6495 - val_loss: 1.6337 - val_accuracy: 0.5161\n","Epoch 75/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0346 - accuracy: 0.6493 - val_loss: 1.5640 - val_accuracy: 0.5410\n","Epoch 76/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0344 - accuracy: 0.6500 - val_loss: 1.5761 - val_accuracy: 0.5338\n","Epoch 77/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0260 - accuracy: 0.6544 - val_loss: 1.5783 - val_accuracy: 0.5379\n","Epoch 78/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.0288 - accuracy: 0.6517 - val_loss: 1.5398 - val_accuracy: 0.5464\n","Epoch 79/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0210 - accuracy: 0.6539 - val_loss: 1.5827 - val_accuracy: 0.5459\n","Epoch 80/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0211 - accuracy: 0.6535 - val_loss: 1.6022 - val_accuracy: 0.5392\n","Epoch 81/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0218 - accuracy: 0.6532 - val_loss: 1.5669 - val_accuracy: 0.5379\n","Epoch 82/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0143 - accuracy: 0.6558 - val_loss: 1.6068 - val_accuracy: 0.5363\n","Epoch 83/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0126 - accuracy: 0.6584 - val_loss: 1.5778 - val_accuracy: 0.5410\n","Epoch 84/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0142 - accuracy: 0.6555 - val_loss: 1.5781 - val_accuracy: 0.5453\n","Epoch 85/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0104 - accuracy: 0.6569 - val_loss: 1.5598 - val_accuracy: 0.5470\n","Epoch 86/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0029 - accuracy: 0.6602 - val_loss: 1.5697 - val_accuracy: 0.5517\n","Epoch 87/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0025 - accuracy: 0.6595 - val_loss: 1.6050 - val_accuracy: 0.5356\n","Epoch 88/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0002 - accuracy: 0.6599 - val_loss: 1.5652 - val_accuracy: 0.5450\n","Epoch 89/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.0029 - accuracy: 0.6596 - val_loss: 1.5761 - val_accuracy: 0.5513\n","Epoch 90/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 0.9925 - accuracy: 0.6630 - val_loss: 1.5929 - val_accuracy: 0.5441\n","Epoch 91/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 0.9926 - accuracy: 0.6629 - val_loss: 1.5718 - val_accuracy: 0.5461\n","Epoch 92/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 0.9925 - accuracy: 0.6657 - val_loss: 1.6121 - val_accuracy: 0.5363\n","Epoch 93/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 0.9946 - accuracy: 0.6630 - val_loss: 1.5959 - val_accuracy: 0.5477\n","Epoch 94/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 0.9904 - accuracy: 0.6633 - val_loss: 1.5541 - val_accuracy: 0.5511\n","Epoch 95/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 0.9835 - accuracy: 0.6643 - val_loss: 1.6094 - val_accuracy: 0.5361\n","Epoch 96/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 0.9795 - accuracy: 0.6668 - val_loss: 1.5943 - val_accuracy: 0.5486\n","Epoch 97/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 0.9829 - accuracy: 0.6649 - val_loss: 1.6132 - val_accuracy: 0.5358\n","Epoch 98/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 0.9759 - accuracy: 0.6665 - val_loss: 1.6042 - val_accuracy: 0.5455\n","Epoch 99/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 0.9791 - accuracy: 0.6679 - val_loss: 1.6125 - val_accuracy: 0.5399\n","Epoch 100/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 0.9751 - accuracy: 0.6672 - val_loss: 1.6259 - val_accuracy: 0.5370\n"]}]},{"cell_type":"code","source":["layer_list = [\n","          layers.BatchNormalization(),\n","          #layers.Conv1D(4,7,strides=7,kernel_initializer='lecun_normal',input_shape=(xtrain.shape[0],84)), #what if we just make 2nd dim xtrain.shape[1]?\n","          layers.Conv1D(100,2,strides=1,kernel_initializer='lecun_normal',padding='valid',input_shape=(big_CNN_thing.shape[1],7)), # each of 7 statistics is kind of like its own channel!\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Conv1D(200,2,strides=2,kernel_initializer='lecun_normal',padding='valid',kernel_regularizer='l1'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Flatten(), \n","          #layers.Dropout(rate=0.2),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","big_CNN_thing_history = model.fit(big_CNN_thing, ytrain_1hot, batch_size=32, epochs=100, validation_data=(big_CNN_thing_val, yval_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3NRS4HLlIBkk","executionInfo":{"status":"ok","timestamp":1652206806308,"user_tz":240,"elapsed":983514,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"c3a8cb5e-b82d-4e00-a547-158c7209bd5b"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1256/1256 [==============================] - 10s 7ms/step - loss: 4.1487 - accuracy: 0.3982 - val_loss: 2.4770 - val_accuracy: 0.4091\n","Epoch 2/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 2.2771 - accuracy: 0.4353 - val_loss: 2.2098 - val_accuracy: 0.4294\n","Epoch 3/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 2.0673 - accuracy: 0.4605 - val_loss: 2.0449 - val_accuracy: 0.4550\n","Epoch 4/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.8540 - accuracy: 0.4811 - val_loss: 1.8079 - val_accuracy: 0.4816\n","Epoch 5/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.7119 - accuracy: 0.4956 - val_loss: 1.7469 - val_accuracy: 0.4866\n","Epoch 6/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.6574 - accuracy: 0.5009 - val_loss: 1.6933 - val_accuracy: 0.4973\n","Epoch 7/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.6324 - accuracy: 0.5031 - val_loss: 1.7339 - val_accuracy: 0.4612\n","Epoch 8/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.6130 - accuracy: 0.5102 - val_loss: 1.6814 - val_accuracy: 0.5000\n","Epoch 9/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.6002 - accuracy: 0.5113 - val_loss: 1.6884 - val_accuracy: 0.4897\n","Epoch 10/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5864 - accuracy: 0.5182 - val_loss: 1.7471 - val_accuracy: 0.4675\n","Epoch 11/100\n","1256/1256 [==============================] - 8s 7ms/step - loss: 1.5772 - accuracy: 0.5180 - val_loss: 1.6833 - val_accuracy: 0.4888\n","Epoch 12/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5741 - accuracy: 0.5196 - val_loss: 1.5975 - val_accuracy: 0.5291\n","Epoch 13/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5652 - accuracy: 0.5207 - val_loss: 1.6401 - val_accuracy: 0.4987\n","Epoch 14/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5623 - accuracy: 0.5234 - val_loss: 1.6614 - val_accuracy: 0.5036\n","Epoch 15/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5566 - accuracy: 0.5248 - val_loss: 1.6205 - val_accuracy: 0.5213\n","Epoch 16/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5603 - accuracy: 0.5237 - val_loss: 1.6646 - val_accuracy: 0.4816\n","Epoch 17/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5518 - accuracy: 0.5269 - val_loss: 1.6122 - val_accuracy: 0.5121\n","Epoch 18/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5423 - accuracy: 0.5286 - val_loss: 1.6487 - val_accuracy: 0.5047\n","Epoch 19/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5431 - accuracy: 0.5273 - val_loss: 1.6040 - val_accuracy: 0.5264\n","Epoch 20/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5357 - accuracy: 0.5285 - val_loss: 1.6563 - val_accuracy: 0.4935\n","Epoch 21/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5302 - accuracy: 0.5312 - val_loss: 1.6189 - val_accuracy: 0.5074\n","Epoch 22/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5307 - accuracy: 0.5337 - val_loss: 1.6982 - val_accuracy: 0.4727\n","Epoch 23/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5341 - accuracy: 0.5318 - val_loss: 1.6694 - val_accuracy: 0.4946\n","Epoch 24/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5317 - accuracy: 0.5329 - val_loss: 1.7508 - val_accuracy: 0.4440\n","Epoch 25/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5275 - accuracy: 0.5353 - val_loss: 1.6647 - val_accuracy: 0.4877\n","Epoch 26/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5258 - accuracy: 0.5314 - val_loss: 1.5947 - val_accuracy: 0.5170\n","Epoch 27/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5191 - accuracy: 0.5331 - val_loss: 1.5785 - val_accuracy: 0.5240\n","Epoch 28/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5192 - accuracy: 0.5354 - val_loss: 1.6074 - val_accuracy: 0.5242\n","Epoch 29/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5252 - accuracy: 0.5341 - val_loss: 1.6513 - val_accuracy: 0.4953\n","Epoch 30/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5186 - accuracy: 0.5355 - val_loss: 1.5689 - val_accuracy: 0.5300\n","Epoch 31/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5168 - accuracy: 0.5375 - val_loss: 1.6495 - val_accuracy: 0.4890\n","Epoch 32/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5184 - accuracy: 0.5334 - val_loss: 1.5877 - val_accuracy: 0.5302\n","Epoch 33/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5176 - accuracy: 0.5366 - val_loss: 1.5904 - val_accuracy: 0.5327\n","Epoch 34/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5157 - accuracy: 0.5349 - val_loss: 1.6167 - val_accuracy: 0.4980\n","Epoch 35/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5159 - accuracy: 0.5349 - val_loss: 1.6173 - val_accuracy: 0.4975\n","Epoch 36/100\n","1256/1256 [==============================] - 9s 8ms/step - loss: 1.5108 - accuracy: 0.5385 - val_loss: 1.6045 - val_accuracy: 0.5045\n","Epoch 37/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5079 - accuracy: 0.5386 - val_loss: 1.6440 - val_accuracy: 0.5087\n","Epoch 38/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5100 - accuracy: 0.5390 - val_loss: 1.6866 - val_accuracy: 0.4852\n","Epoch 39/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5061 - accuracy: 0.5394 - val_loss: 1.5949 - val_accuracy: 0.5164\n","Epoch 40/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5084 - accuracy: 0.5365 - val_loss: 1.6499 - val_accuracy: 0.5112\n","Epoch 41/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5084 - accuracy: 0.5365 - val_loss: 1.7775 - val_accuracy: 0.4478\n","Epoch 42/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5020 - accuracy: 0.5385 - val_loss: 1.6060 - val_accuracy: 0.5049\n","Epoch 43/100\n","1256/1256 [==============================] - 9s 8ms/step - loss: 1.5044 - accuracy: 0.5375 - val_loss: 1.6634 - val_accuracy: 0.4953\n","Epoch 44/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5067 - accuracy: 0.5380 - val_loss: 1.5902 - val_accuracy: 0.5148\n","Epoch 45/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5049 - accuracy: 0.5386 - val_loss: 1.5875 - val_accuracy: 0.5155\n","Epoch 46/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5029 - accuracy: 0.5389 - val_loss: 1.6854 - val_accuracy: 0.5045\n","Epoch 47/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5028 - accuracy: 0.5386 - val_loss: 1.5899 - val_accuracy: 0.5273\n","Epoch 48/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4989 - accuracy: 0.5404 - val_loss: 1.6047 - val_accuracy: 0.5094\n","Epoch 49/100\n","1256/1256 [==============================] - 9s 8ms/step - loss: 1.4978 - accuracy: 0.5395 - val_loss: 1.5861 - val_accuracy: 0.5157\n","Epoch 50/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4955 - accuracy: 0.5416 - val_loss: 1.6613 - val_accuracy: 0.5022\n","Epoch 51/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4960 - accuracy: 0.5383 - val_loss: 1.5618 - val_accuracy: 0.5309\n","Epoch 52/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4934 - accuracy: 0.5421 - val_loss: 1.6357 - val_accuracy: 0.4924\n","Epoch 53/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4926 - accuracy: 0.5409 - val_loss: 1.6277 - val_accuracy: 0.4998\n","Epoch 54/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4954 - accuracy: 0.5426 - val_loss: 1.6027 - val_accuracy: 0.5202\n","Epoch 55/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4919 - accuracy: 0.5415 - val_loss: 1.6160 - val_accuracy: 0.5184\n","Epoch 56/100\n","1256/1256 [==============================] - 9s 8ms/step - loss: 1.4923 - accuracy: 0.5425 - val_loss: 1.6640 - val_accuracy: 0.4922\n","Epoch 57/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4916 - accuracy: 0.5430 - val_loss: 1.6564 - val_accuracy: 0.4807\n","Epoch 58/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4872 - accuracy: 0.5426 - val_loss: 1.5650 - val_accuracy: 0.5271\n","Epoch 59/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4903 - accuracy: 0.5408 - val_loss: 1.5484 - val_accuracy: 0.5441\n","Epoch 60/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4894 - accuracy: 0.5430 - val_loss: 1.6313 - val_accuracy: 0.5047\n","Epoch 61/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4870 - accuracy: 0.5424 - val_loss: 1.6065 - val_accuracy: 0.5217\n","Epoch 62/100\n","1256/1256 [==============================] - 9s 8ms/step - loss: 1.4845 - accuracy: 0.5451 - val_loss: 1.5380 - val_accuracy: 0.5432\n","Epoch 63/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4856 - accuracy: 0.5431 - val_loss: 1.5818 - val_accuracy: 0.5188\n","Epoch 64/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4858 - accuracy: 0.5446 - val_loss: 1.5885 - val_accuracy: 0.5246\n","Epoch 65/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4806 - accuracy: 0.5428 - val_loss: 1.5830 - val_accuracy: 0.5193\n","Epoch 66/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4849 - accuracy: 0.5436 - val_loss: 1.5829 - val_accuracy: 0.5074\n","Epoch 67/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4839 - accuracy: 0.5446 - val_loss: 1.6131 - val_accuracy: 0.5110\n","Epoch 68/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4802 - accuracy: 0.5454 - val_loss: 1.5628 - val_accuracy: 0.5358\n","Epoch 69/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4812 - accuracy: 0.5454 - val_loss: 1.9065 - val_accuracy: 0.4135\n","Epoch 70/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4844 - accuracy: 0.5424 - val_loss: 1.5555 - val_accuracy: 0.5269\n","Epoch 71/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4815 - accuracy: 0.5433 - val_loss: 1.5994 - val_accuracy: 0.5159\n","Epoch 72/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4786 - accuracy: 0.5442 - val_loss: 1.5477 - val_accuracy: 0.5349\n","Epoch 73/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4792 - accuracy: 0.5443 - val_loss: 1.5475 - val_accuracy: 0.5390\n","Epoch 74/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4776 - accuracy: 0.5440 - val_loss: 1.5659 - val_accuracy: 0.5280\n","Epoch 75/100\n","1256/1256 [==============================] - 9s 8ms/step - loss: 1.4817 - accuracy: 0.5435 - val_loss: 1.5387 - val_accuracy: 0.5354\n","Epoch 76/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4744 - accuracy: 0.5480 - val_loss: 1.6093 - val_accuracy: 0.5011\n","Epoch 77/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4787 - accuracy: 0.5469 - val_loss: 1.5671 - val_accuracy: 0.5152\n","Epoch 78/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4786 - accuracy: 0.5445 - val_loss: 1.6036 - val_accuracy: 0.5054\n","Epoch 79/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4754 - accuracy: 0.5458 - val_loss: 1.5581 - val_accuracy: 0.5343\n","Epoch 80/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4719 - accuracy: 0.5470 - val_loss: 1.5266 - val_accuracy: 0.5419\n","Epoch 81/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4730 - accuracy: 0.5449 - val_loss: 1.6343 - val_accuracy: 0.4843\n","Epoch 82/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4692 - accuracy: 0.5462 - val_loss: 1.6480 - val_accuracy: 0.4987\n","Epoch 83/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4702 - accuracy: 0.5466 - val_loss: 1.5798 - val_accuracy: 0.5255\n","Epoch 84/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4744 - accuracy: 0.5461 - val_loss: 1.6072 - val_accuracy: 0.4991\n","Epoch 85/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4695 - accuracy: 0.5462 - val_loss: 1.5785 - val_accuracy: 0.5184\n","Epoch 86/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4716 - accuracy: 0.5455 - val_loss: 1.6090 - val_accuracy: 0.5155\n","Epoch 87/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4702 - accuracy: 0.5476 - val_loss: 1.5322 - val_accuracy: 0.5430\n","Epoch 88/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4667 - accuracy: 0.5469 - val_loss: 1.5209 - val_accuracy: 0.5466\n","Epoch 89/100\n","1256/1256 [==============================] - 9s 8ms/step - loss: 1.4678 - accuracy: 0.5453 - val_loss: 1.5544 - val_accuracy: 0.5231\n","Epoch 90/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4647 - accuracy: 0.5479 - val_loss: 1.6091 - val_accuracy: 0.5009\n","Epoch 91/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4663 - accuracy: 0.5460 - val_loss: 1.5391 - val_accuracy: 0.5318\n","Epoch 92/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4618 - accuracy: 0.5472 - val_loss: 1.6173 - val_accuracy: 0.4982\n","Epoch 93/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4643 - accuracy: 0.5478 - val_loss: 1.6494 - val_accuracy: 0.4776\n","Epoch 94/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4671 - accuracy: 0.5457 - val_loss: 1.5493 - val_accuracy: 0.5383\n","Epoch 95/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4645 - accuracy: 0.5482 - val_loss: 1.6051 - val_accuracy: 0.4980\n","Epoch 96/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4632 - accuracy: 0.5458 - val_loss: 1.5457 - val_accuracy: 0.5347\n","Epoch 97/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4618 - accuracy: 0.5456 - val_loss: 1.8050 - val_accuracy: 0.4355\n","Epoch 98/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4635 - accuracy: 0.5473 - val_loss: 1.5557 - val_accuracy: 0.5204\n","Epoch 99/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4622 - accuracy: 0.5452 - val_loss: 1.5906 - val_accuracy: 0.5166\n","Epoch 100/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4609 - accuracy: 0.5471 - val_loss: 1.5656 - val_accuracy: 0.5237\n"]}]},{"cell_type":"code","source":["layer_list = [\n","          layers.BatchNormalization(),\n","          #layers.Conv1D(4,7,strides=7,kernel_initializer='lecun_normal',input_shape=(xtrain.shape[0],84)), #what if we just make 2nd dim xtrain.shape[1]?\n","          layers.Conv1D(100,2,strides=1,kernel_initializer='lecun_normal',padding='valid',input_shape=(big_CNN_thing.shape[1],7)), # each of 7 statistics is kind of like its own channel!\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Conv1D(200,2,strides=2,kernel_initializer='lecun_normal',padding='valid',kernel_regularizer='l2'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Flatten(), \n","          #layers.Dropout(rate=0.2),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","big_CNN_thing_history = model.fit(big_CNN_thing, ytrain_1hot, batch_size=32, epochs=100, validation_data=(big_CNN_thing_val, yval_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JKB-f6MBNDt7","executionInfo":{"status":"ok","timestamp":1652207808415,"user_tz":240,"elapsed":923619,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"f16cb6d0-60ef-449f-a1c4-ccd9ee86c020"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1256/1256 [==============================] - 10s 7ms/step - loss: 2.2731 - accuracy: 0.4327 - val_loss: 1.7559 - val_accuracy: 0.4668\n","Epoch 2/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.7070 - accuracy: 0.4647 - val_loss: 1.6731 - val_accuracy: 0.4756\n","Epoch 3/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.6414 - accuracy: 0.4784 - val_loss: 1.6901 - val_accuracy: 0.4671\n","Epoch 4/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5894 - accuracy: 0.4990 - val_loss: 1.6226 - val_accuracy: 0.4913\n","Epoch 5/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5435 - accuracy: 0.5089 - val_loss: 1.5678 - val_accuracy: 0.5123\n","Epoch 6/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.5048 - accuracy: 0.5199 - val_loss: 1.5854 - val_accuracy: 0.4955\n","Epoch 7/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4823 - accuracy: 0.5257 - val_loss: 1.5304 - val_accuracy: 0.5139\n","Epoch 8/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4648 - accuracy: 0.5335 - val_loss: 1.6577 - val_accuracy: 0.4875\n","Epoch 9/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4515 - accuracy: 0.5345 - val_loss: 1.5588 - val_accuracy: 0.5125\n","Epoch 10/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4432 - accuracy: 0.5378 - val_loss: 1.5810 - val_accuracy: 0.4913\n","Epoch 11/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4343 - accuracy: 0.5405 - val_loss: 1.6162 - val_accuracy: 0.5011\n","Epoch 12/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4278 - accuracy: 0.5450 - val_loss: 1.6039 - val_accuracy: 0.4839\n","Epoch 13/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4183 - accuracy: 0.5481 - val_loss: 1.5551 - val_accuracy: 0.4975\n","Epoch 14/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4125 - accuracy: 0.5494 - val_loss: 1.4612 - val_accuracy: 0.5491\n","Epoch 15/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4074 - accuracy: 0.5514 - val_loss: 1.6271 - val_accuracy: 0.4948\n","Epoch 16/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.4049 - accuracy: 0.5505 - val_loss: 1.4646 - val_accuracy: 0.5417\n","Epoch 17/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3997 - accuracy: 0.5552 - val_loss: 1.5557 - val_accuracy: 0.4975\n","Epoch 18/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3939 - accuracy: 0.5570 - val_loss: 1.5495 - val_accuracy: 0.4993\n","Epoch 19/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3914 - accuracy: 0.5562 - val_loss: 1.5445 - val_accuracy: 0.5204\n","Epoch 20/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3862 - accuracy: 0.5587 - val_loss: 1.5175 - val_accuracy: 0.5246\n","Epoch 21/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3854 - accuracy: 0.5574 - val_loss: 1.5236 - val_accuracy: 0.5300\n","Epoch 22/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3834 - accuracy: 0.5584 - val_loss: 1.4781 - val_accuracy: 0.5253\n","Epoch 23/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3789 - accuracy: 0.5595 - val_loss: 1.5742 - val_accuracy: 0.5103\n","Epoch 24/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3776 - accuracy: 0.5583 - val_loss: 1.4545 - val_accuracy: 0.5491\n","Epoch 25/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3761 - accuracy: 0.5615 - val_loss: 1.5839 - val_accuracy: 0.5186\n","Epoch 26/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3738 - accuracy: 0.5608 - val_loss: 1.4864 - val_accuracy: 0.5410\n","Epoch 27/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3694 - accuracy: 0.5612 - val_loss: 1.5612 - val_accuracy: 0.5123\n","Epoch 28/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3673 - accuracy: 0.5651 - val_loss: 1.4910 - val_accuracy: 0.5379\n","Epoch 29/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3693 - accuracy: 0.5630 - val_loss: 1.4451 - val_accuracy: 0.5509\n","Epoch 30/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3631 - accuracy: 0.5650 - val_loss: 1.5036 - val_accuracy: 0.5298\n","Epoch 31/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3636 - accuracy: 0.5667 - val_loss: 1.5179 - val_accuracy: 0.5137\n","Epoch 32/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3608 - accuracy: 0.5666 - val_loss: 1.5098 - val_accuracy: 0.5311\n","Epoch 33/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3566 - accuracy: 0.5675 - val_loss: 1.4549 - val_accuracy: 0.5410\n","Epoch 34/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3553 - accuracy: 0.5662 - val_loss: 1.4892 - val_accuracy: 0.5352\n","Epoch 35/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3495 - accuracy: 0.5695 - val_loss: 1.5043 - val_accuracy: 0.5284\n","Epoch 36/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3455 - accuracy: 0.5718 - val_loss: 1.4566 - val_accuracy: 0.5439\n","Epoch 37/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3494 - accuracy: 0.5675 - val_loss: 1.5083 - val_accuracy: 0.5325\n","Epoch 38/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3492 - accuracy: 0.5702 - val_loss: 1.5223 - val_accuracy: 0.5253\n","Epoch 39/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3468 - accuracy: 0.5706 - val_loss: 1.4956 - val_accuracy: 0.5426\n","Epoch 40/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3441 - accuracy: 0.5735 - val_loss: 1.4899 - val_accuracy: 0.5309\n","Epoch 41/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3414 - accuracy: 0.5718 - val_loss: 1.5094 - val_accuracy: 0.5323\n","Epoch 42/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3450 - accuracy: 0.5702 - val_loss: 1.5752 - val_accuracy: 0.5101\n","Epoch 43/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3421 - accuracy: 0.5718 - val_loss: 1.5136 - val_accuracy: 0.5329\n","Epoch 44/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3390 - accuracy: 0.5741 - val_loss: 1.5913 - val_accuracy: 0.4892\n","Epoch 45/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3354 - accuracy: 0.5733 - val_loss: 1.5811 - val_accuracy: 0.5085\n","Epoch 46/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3379 - accuracy: 0.5748 - val_loss: 1.6276 - val_accuracy: 0.4978\n","Epoch 47/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3349 - accuracy: 0.5737 - val_loss: 1.4767 - val_accuracy: 0.5428\n","Epoch 48/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3319 - accuracy: 0.5752 - val_loss: 1.4474 - val_accuracy: 0.5506\n","Epoch 49/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3313 - accuracy: 0.5757 - val_loss: 1.5316 - val_accuracy: 0.5150\n","Epoch 50/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3308 - accuracy: 0.5739 - val_loss: 1.6578 - val_accuracy: 0.4745\n","Epoch 51/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3285 - accuracy: 0.5763 - val_loss: 1.5524 - val_accuracy: 0.5244\n","Epoch 52/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3287 - accuracy: 0.5743 - val_loss: 1.5645 - val_accuracy: 0.5202\n","Epoch 53/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3274 - accuracy: 0.5764 - val_loss: 1.5116 - val_accuracy: 0.5269\n","Epoch 54/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3262 - accuracy: 0.5762 - val_loss: 1.5128 - val_accuracy: 0.5300\n","Epoch 55/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3237 - accuracy: 0.5783 - val_loss: 1.4471 - val_accuracy: 0.5538\n","Epoch 56/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3228 - accuracy: 0.5781 - val_loss: 1.5486 - val_accuracy: 0.5222\n","Epoch 57/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3245 - accuracy: 0.5775 - val_loss: 1.5648 - val_accuracy: 0.5099\n","Epoch 58/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3175 - accuracy: 0.5782 - val_loss: 1.4606 - val_accuracy: 0.5473\n","Epoch 59/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3164 - accuracy: 0.5809 - val_loss: 1.5998 - val_accuracy: 0.4946\n","Epoch 60/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3171 - accuracy: 0.5788 - val_loss: 1.4610 - val_accuracy: 0.5473\n","Epoch 61/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3167 - accuracy: 0.5810 - val_loss: 1.5073 - val_accuracy: 0.5316\n","Epoch 62/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3193 - accuracy: 0.5787 - val_loss: 1.5831 - val_accuracy: 0.5069\n","Epoch 63/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3164 - accuracy: 0.5795 - val_loss: 1.5278 - val_accuracy: 0.5300\n","Epoch 64/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3127 - accuracy: 0.5800 - val_loss: 1.5454 - val_accuracy: 0.5282\n","Epoch 65/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3121 - accuracy: 0.5817 - val_loss: 1.5823 - val_accuracy: 0.5168\n","Epoch 66/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3133 - accuracy: 0.5809 - val_loss: 1.5004 - val_accuracy: 0.5405\n","Epoch 67/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3067 - accuracy: 0.5830 - val_loss: 1.5079 - val_accuracy: 0.5314\n","Epoch 68/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3090 - accuracy: 0.5796 - val_loss: 1.4964 - val_accuracy: 0.5336\n","Epoch 69/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3060 - accuracy: 0.5806 - val_loss: 1.4450 - val_accuracy: 0.5535\n","Epoch 70/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3074 - accuracy: 0.5835 - val_loss: 1.5180 - val_accuracy: 0.5370\n","Epoch 71/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3087 - accuracy: 0.5821 - val_loss: 1.5289 - val_accuracy: 0.5222\n","Epoch 72/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3057 - accuracy: 0.5820 - val_loss: 1.4794 - val_accuracy: 0.5417\n","Epoch 73/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3055 - accuracy: 0.5825 - val_loss: 1.5295 - val_accuracy: 0.5262\n","Epoch 74/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3028 - accuracy: 0.5822 - val_loss: 1.5683 - val_accuracy: 0.5300\n","Epoch 75/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3038 - accuracy: 0.5812 - val_loss: 1.5147 - val_accuracy: 0.5390\n","Epoch 76/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3011 - accuracy: 0.5829 - val_loss: 1.5809 - val_accuracy: 0.5305\n","Epoch 77/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3014 - accuracy: 0.5848 - val_loss: 1.4394 - val_accuracy: 0.5596\n","Epoch 78/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3008 - accuracy: 0.5846 - val_loss: 1.4215 - val_accuracy: 0.5600\n","Epoch 79/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.3000 - accuracy: 0.5845 - val_loss: 1.4952 - val_accuracy: 0.5305\n","Epoch 80/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2979 - accuracy: 0.5875 - val_loss: 1.5454 - val_accuracy: 0.5426\n","Epoch 81/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2937 - accuracy: 0.5859 - val_loss: 1.6414 - val_accuracy: 0.5031\n","Epoch 82/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2931 - accuracy: 0.5856 - val_loss: 1.5187 - val_accuracy: 0.5199\n","Epoch 83/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2985 - accuracy: 0.5831 - val_loss: 1.4527 - val_accuracy: 0.5582\n","Epoch 84/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2961 - accuracy: 0.5859 - val_loss: 1.5587 - val_accuracy: 0.5280\n","Epoch 85/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2958 - accuracy: 0.5847 - val_loss: 1.5021 - val_accuracy: 0.5385\n","Epoch 86/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2919 - accuracy: 0.5855 - val_loss: 1.5071 - val_accuracy: 0.5365\n","Epoch 87/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2926 - accuracy: 0.5865 - val_loss: 1.4711 - val_accuracy: 0.5408\n","Epoch 88/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2946 - accuracy: 0.5849 - val_loss: 1.5639 - val_accuracy: 0.5276\n","Epoch 89/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2908 - accuracy: 0.5860 - val_loss: 1.4765 - val_accuracy: 0.5455\n","Epoch 90/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2871 - accuracy: 0.5879 - val_loss: 1.4718 - val_accuracy: 0.5475\n","Epoch 91/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2885 - accuracy: 0.5877 - val_loss: 1.4915 - val_accuracy: 0.5419\n","Epoch 92/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2865 - accuracy: 0.5885 - val_loss: 1.5331 - val_accuracy: 0.5361\n","Epoch 93/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2864 - accuracy: 0.5880 - val_loss: 1.4794 - val_accuracy: 0.5392\n","Epoch 94/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2825 - accuracy: 0.5915 - val_loss: 1.5318 - val_accuracy: 0.5399\n","Epoch 95/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2853 - accuracy: 0.5889 - val_loss: 1.7225 - val_accuracy: 0.4888\n","Epoch 96/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2853 - accuracy: 0.5863 - val_loss: 1.5587 - val_accuracy: 0.5220\n","Epoch 97/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2810 - accuracy: 0.5901 - val_loss: 1.4922 - val_accuracy: 0.5374\n","Epoch 98/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2815 - accuracy: 0.5906 - val_loss: 1.5075 - val_accuracy: 0.5161\n","Epoch 99/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2829 - accuracy: 0.5878 - val_loss: 1.4830 - val_accuracy: 0.5506\n","Epoch 100/100\n","1256/1256 [==============================] - 9s 7ms/step - loss: 1.2806 - accuracy: 0.5879 - val_loss: 1.4884 - val_accuracy: 0.5477\n"]}]},{"cell_type":"code","source":["layer_list = [\n","          layers.BatchNormalization(),\n","          #layers.Conv1D(4,7,strides=7,kernel_initializer='lecun_normal',input_shape=(xtrain.shape[0],84)), #what if we just make 2nd dim xtrain.shape[1]?\n","          layers.Conv1D(100,2,strides=1,kernel_initializer='lecun_normal',padding='valid',input_shape=(chroma_cqt.shape[1],7)), # each of 7 statistics is kind of like its own channel!\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Conv1D(200,2,strides=2,kernel_initializer='lecun_normal',padding='valid'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Flatten(), \n","          #layers.Dropout(rate=0.2),\n","          layers.Dense(80,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(40,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(32,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","big_CNN_thing_history = model.fit(chroma_cqt, ytrain_1hot, batch_size=32, epochs=100, validation_data=(xval_chroma_cqt, yval_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Dm5xuM70TP2S","executionInfo":{"status":"error","timestamp":1652209405484,"user_tz":240,"elapsed":632857,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"9e431aa0-361d-482a-97a7-054464edce6e"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1256/1256 [==============================] - 43s 8ms/step - loss: 1.8966 - accuracy: 0.3852 - val_loss: 1.7974 - val_accuracy: 0.4064\n","Epoch 2/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.6900 - accuracy: 0.4311 - val_loss: 1.7884 - val_accuracy: 0.4113\n","Epoch 3/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.6574 - accuracy: 0.4435 - val_loss: 1.9166 - val_accuracy: 0.4135\n","Epoch 4/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.6266 - accuracy: 0.4548 - val_loss: 1.7732 - val_accuracy: 0.4245\n","Epoch 5/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.6072 - accuracy: 0.4622 - val_loss: 1.8081 - val_accuracy: 0.4265\n","Epoch 6/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5895 - accuracy: 0.4673 - val_loss: 1.8491 - val_accuracy: 0.4178\n","Epoch 7/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5739 - accuracy: 0.4751 - val_loss: 1.8210 - val_accuracy: 0.4185\n","Epoch 8/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5587 - accuracy: 0.4818 - val_loss: 1.7007 - val_accuracy: 0.4431\n","Epoch 9/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5434 - accuracy: 0.4843 - val_loss: 1.7856 - val_accuracy: 0.4319\n","Epoch 10/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5296 - accuracy: 0.4925 - val_loss: 1.7610 - val_accuracy: 0.4451\n","Epoch 11/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5199 - accuracy: 0.4948 - val_loss: 1.7131 - val_accuracy: 0.4500\n","Epoch 12/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.5076 - accuracy: 0.4963 - val_loss: 1.7819 - val_accuracy: 0.4451\n","Epoch 13/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4960 - accuracy: 0.5008 - val_loss: 1.7745 - val_accuracy: 0.4449\n","Epoch 14/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4919 - accuracy: 0.4982 - val_loss: 1.6928 - val_accuracy: 0.4579\n","Epoch 15/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4793 - accuracy: 0.5068 - val_loss: 1.6795 - val_accuracy: 0.4621\n","Epoch 16/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4701 - accuracy: 0.5069 - val_loss: 1.7047 - val_accuracy: 0.4577\n","Epoch 17/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4592 - accuracy: 0.5122 - val_loss: 1.6876 - val_accuracy: 0.4588\n","Epoch 18/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4500 - accuracy: 0.5135 - val_loss: 1.7349 - val_accuracy: 0.4521\n","Epoch 19/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4442 - accuracy: 0.5156 - val_loss: 1.7016 - val_accuracy: 0.4588\n","Epoch 20/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4344 - accuracy: 0.5182 - val_loss: 1.7583 - val_accuracy: 0.4435\n","Epoch 21/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4288 - accuracy: 0.5217 - val_loss: 1.7566 - val_accuracy: 0.4424\n","Epoch 22/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.4236 - accuracy: 0.5220 - val_loss: 1.7266 - val_accuracy: 0.4597\n","Epoch 23/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4125 - accuracy: 0.5279 - val_loss: 1.7428 - val_accuracy: 0.4503\n","Epoch 24/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.4030 - accuracy: 0.5282 - val_loss: 1.7212 - val_accuracy: 0.4599\n","Epoch 25/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3984 - accuracy: 0.5293 - val_loss: 1.7634 - val_accuracy: 0.4469\n","Epoch 26/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3872 - accuracy: 0.5339 - val_loss: 1.7608 - val_accuracy: 0.4500\n","Epoch 27/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3813 - accuracy: 0.5358 - val_loss: 1.7432 - val_accuracy: 0.4487\n","Epoch 28/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3771 - accuracy: 0.5365 - val_loss: 1.6405 - val_accuracy: 0.4843\n","Epoch 29/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3670 - accuracy: 0.5394 - val_loss: 1.6203 - val_accuracy: 0.4839\n","Epoch 30/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3590 - accuracy: 0.5416 - val_loss: 1.8689 - val_accuracy: 0.4279\n","Epoch 31/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3507 - accuracy: 0.5458 - val_loss: 1.7686 - val_accuracy: 0.4586\n","Epoch 32/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3440 - accuracy: 0.5486 - val_loss: 1.8449 - val_accuracy: 0.4283\n","Epoch 33/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3407 - accuracy: 0.5509 - val_loss: 1.7393 - val_accuracy: 0.4644\n","Epoch 34/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3285 - accuracy: 0.5537 - val_loss: 1.7390 - val_accuracy: 0.4615\n","Epoch 35/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3206 - accuracy: 0.5549 - val_loss: 1.7873 - val_accuracy: 0.4628\n","Epoch 36/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3179 - accuracy: 0.5565 - val_loss: 1.7453 - val_accuracy: 0.4648\n","Epoch 37/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.3091 - accuracy: 0.5561 - val_loss: 1.7107 - val_accuracy: 0.4722\n","Epoch 38/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.2979 - accuracy: 0.5610 - val_loss: 1.6886 - val_accuracy: 0.4740\n","Epoch 39/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.2937 - accuracy: 0.5583 - val_loss: 1.7002 - val_accuracy: 0.4733\n","Epoch 40/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.2846 - accuracy: 0.5684 - val_loss: 1.7878 - val_accuracy: 0.4550\n","Epoch 41/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.2788 - accuracy: 0.5672 - val_loss: 1.7861 - val_accuracy: 0.4659\n","Epoch 42/100\n","1256/1256 [==============================] - 11s 9ms/step - loss: 1.2723 - accuracy: 0.5693 - val_loss: 1.8006 - val_accuracy: 0.4565\n","Epoch 43/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.2645 - accuracy: 0.5731 - val_loss: 1.8471 - val_accuracy: 0.4581\n","Epoch 44/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.2612 - accuracy: 0.5739 - val_loss: 1.7732 - val_accuracy: 0.4642\n","Epoch 45/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.2534 - accuracy: 0.5762 - val_loss: 1.7876 - val_accuracy: 0.4547\n","Epoch 46/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.2457 - accuracy: 0.5791 - val_loss: 1.7510 - val_accuracy: 0.4745\n","Epoch 47/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.2382 - accuracy: 0.5816 - val_loss: 1.8047 - val_accuracy: 0.4684\n","Epoch 48/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.2295 - accuracy: 0.5845 - val_loss: 1.7928 - val_accuracy: 0.4642\n","Epoch 49/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.2266 - accuracy: 0.5834 - val_loss: 1.8720 - val_accuracy: 0.4483\n","Epoch 50/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.2181 - accuracy: 0.5888 - val_loss: 1.8235 - val_accuracy: 0.4559\n","Epoch 51/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.2128 - accuracy: 0.5885 - val_loss: 2.0053 - val_accuracy: 0.4259\n","Epoch 52/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.2074 - accuracy: 0.5904 - val_loss: 1.7912 - val_accuracy: 0.4733\n","Epoch 53/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.1987 - accuracy: 0.5932 - val_loss: 1.7878 - val_accuracy: 0.4689\n","Epoch 54/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.1985 - accuracy: 0.5938 - val_loss: 1.7001 - val_accuracy: 0.4834\n","Epoch 55/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.1865 - accuracy: 0.5967 - val_loss: 1.8870 - val_accuracy: 0.4518\n","Epoch 56/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.1820 - accuracy: 0.5986 - val_loss: 1.8746 - val_accuracy: 0.4561\n","Epoch 57/100\n","1256/1256 [==============================] - 11s 8ms/step - loss: 1.1724 - accuracy: 0.6039 - val_loss: 1.8230 - val_accuracy: 0.4682\n","Epoch 58/100\n","1256/1256 [==============================] - 10s 8ms/step - loss: 1.1670 - accuracy: 0.6062 - val_loss: 1.8021 - val_accuracy: 0.4711\n","Epoch 59/100\n"," 215/1256 [====>.........................] - ETA: 10s - loss: 1.1604 - accuracy: 0.6067"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-4b2a4333ed1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n\u001b[1;32m     26\u001b[0m     loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mbig_CNN_thing_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchroma_cqt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval_chroma_cqt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}