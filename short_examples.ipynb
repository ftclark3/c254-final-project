{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "short_examples.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "9rf95sJihJqc",
        "outputId": "75ca9240-1dcc-4e5d-d6bf-b55db8b9c195"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e6918531-a282-425f-90f1-6f12df936b8f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e6918531-a282-425f-90f1-6f12df936b8f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ytrain.npy to ytrain (3).npy\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8815f662-1871-461e-89ea-1e4faf96a4f3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8815f662-1871-461e-89ea-1e4faf96a4f3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving xtrain.npy to xtrain (2).npy\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-66707aea-dffd-48b7-9133-4810465acaa6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-66707aea-dffd-48b7-9133-4810465acaa6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving yval.npy to yval (2).npy\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fa149d4e-48d0-494d-b60d-1a2b84b0d66d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fa149d4e-48d0-494d-b60d-1a2b84b0d66d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving xval.npy to xval (2).npy\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-01b28882-261b-4fd8-9c66-7adbb0b6f55c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-01b28882-261b-4fd8-9c66-7adbb0b6f55c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ytest.npy to ytest (3).npy\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3895422e-100f-4324-8f91-d88e3181126f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3895422e-100f-4324-8f91-d88e3181126f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving xtest.npy to xtest (2).npy\n"
          ]
        }
      ],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "# import libraries\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# Helper libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "#for greg\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "ytrain_byteseq = files.upload() # choose 'ytrain.npy' from local system\n",
        "ytrain_filelike = io.BytesIO(ytrain_byteseq['ytrain.npy']) # create file-like object\n",
        "ytrain = np.load(ytrain_filelike,allow_pickle=True) # create regular numpy array\n",
        "xtrain_byteseq = files.upload() # choose 'xtrain.npy' from local system\n",
        "xtrain_filelike = io.BytesIO(xtrain_byteseq['xtrain.npy']) # create file-like object\n",
        "xtrain = np.load(xtrain_filelike,allow_pickle=True) # create regular numpy array\n",
        "\n",
        "yval_byteseq = files.upload() # choose 'yval.npy' from local system\n",
        "yval_filelike = io.BytesIO(yval_byteseq['yval.npy']) # create file-like object\n",
        "yval = np.load(yval_filelike,allow_pickle=True) # create regular numpy array\n",
        "xval_byteseq = files.upload() # choose 'xval.npy' from local system\n",
        "xval_filelike = io.BytesIO(xval_byteseq['xval.npy']) # create file-like object\n",
        "xval = np.load(xval_filelike,allow_pickle=True) # create regular numpy array\n",
        "\n",
        "ytest_byteseq = files.upload() # choose 'ytest.npy' from local system\n",
        "ytest_filelike = io.BytesIO(ytest_byteseq['ytest.npy']) # create file-like object\n",
        "ytest = np.load(ytest_filelike,allow_pickle=True) # create regular numpy array\n",
        "xtest_byteseq = files.upload() # choose 'ytest.npy' from local system\n",
        "xtest_filelike = io.BytesIO(xtest_byteseq['xtest.npy']) # create file-like object\n",
        "xtest = np.load(xtest_filelike,allow_pickle=True) # create regular numpy array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the keys for the meaning of each integer label in test sets\n",
        "'''\n",
        "feature_map = {'Rock':0,'Electronic':1,'Experimental':2,'Hip-Hop':3,'Folk':4,'Instrumental':5,'Pop':6,\n",
        "              'International':7,'Classical':8,'Old-Time / Historic':9, 'Jazz':10,'Country':11,'Soul-RnB':12,\n",
        "              'Spoken':13,'Blues':14,'Easy Listening':15}\n",
        "'''\n",
        "ytrain_1hot = to_categorical(ytrain).astype('int')\n",
        "yval_1hot = to_categorical(yval).astype('int')\n",
        "ytest_1hot = to_categorical(ytest).astype('int')\n",
        "\n",
        "# make full trainval set for alternate splits later\n",
        "xtrainval = np.concatenate((xtrain,xval),axis=0)\n",
        "ytrainval = np.concatenate((ytrain,yval),axis=0)\n",
        "ytrainval_1hot = to_categorical(ytrainval).astype('int') \n",
        "\n",
        "# break sets up by features for investigation in smaller groups\n",
        "chroma_cens = xtrain[:,:84] # length 12\n",
        "chroma_cqt = xtrain[:,84:168] # length 12\n",
        "chroma_stft = xtrain[:,168:252]# length 12\n",
        "chroma_mfcc = xtrain[:,252:392] # length 20\n",
        "rmse = xtrain[:,392:399]\n",
        "spectral_bandwidth = xtrain[:,399:406]\n",
        "spectral_centroid = xtrain[:,406:413]\n",
        "spectral_contrast = xtrain[:,413:462]# length 7\n",
        "spectral_rolloff = xtrain[:,462:469] \n",
        "tonnetz = xtrain[:,469:511] # length 6\n",
        "zcr = xtrain[:,511:518]\n",
        "dates = xtrain[:,518]\n",
        "duration = xtrain[:,519]\n",
        "\n",
        "chroma_censtrainval = xtrainval[:,:84] # length 12\n",
        "chroma_cqttrainval = xtrainval[:,84:168] # length 12\n",
        "chroma_stfttrainval = xtrainval[:,168:252]# length 12\n",
        "chroma_mfcctrainval = xtrainval[:,252:392] # length 20\n",
        "rmsetrainval = xtrainval[:,392:399]\n",
        "spectral_bandwidthtrainval = xtrainval[:,399:406]\n",
        "spectral_centroidtrainval = xtrainval[:,406:413]\n",
        "spectral_contrasttrainval = xtrainval[:,413:462]# length 7\n",
        "spectral_rollofftrainval = xtrainval[:,462:469] \n",
        "tonnetztrainval = xtrainval[:,469:511] # length 6\n",
        "zcrtrainval = xtrainval[:,511:518]\n",
        "datestrainval = xtrainval[:,518]\n",
        "durationtrainval = xtrainval[:,519]\n",
        "\n",
        "chroma_censval = xval[:,:84] # length 12\n",
        "chroma_cqtval = xval[:,84:168] # length 12\n",
        "chroma_stftval = xval[:,168:252]# length 12\n",
        "chroma_mfccval = xval[:,252:392] # length 20\n",
        "rmseval = xval[:,392:399]\n",
        "spectral_bandwidthval = xval[:,399:406]\n",
        "spectral_centroidval = xval[:,406:413]\n",
        "spectral_contrastval = xval[:,413:462]# length 7\n",
        "spectral_rolloffval = xval[:,462:469] \n",
        "tonnetzval = xval[:,469:511] # length 6\n",
        "zcrval = xval[:,511:518]\n",
        "datesval = xval[:,518]\n",
        "durationval = xval[:,519]\n",
        "\n",
        "# reorder features for compatibility with CNN\n",
        "\n",
        "# currently, the features are a timeseries for each statistic\n",
        "# but we want to reindex so that all statistics are intermingled\n",
        "# but grouped by time\n",
        "# this function will help with that\n",
        "def get_index_order(subinterval_length):\n",
        "    idxs = []\n",
        "    for i in range(1,subinterval_length+1):\n",
        "        idx = []\n",
        "        for j in range(1,8):\n",
        "            idx.append(subinterval_length*(j-1)+i-1)\n",
        "        idxs.append(idx)\n",
        "    idxs = np.array(idxs).flatten()\n",
        "    return idxs\n",
        "\n",
        "order_12 = get_index_order(12)\n",
        "order_20 = get_index_order(20)\n",
        "order_7 = get_index_order(7)\n",
        "order_6 = get_index_order(6)\n",
        "\n",
        "# reindex timeseries arrays\n",
        "chroma_cens = chroma_cens[:,order_12] # length 12\n",
        "chroma_cqt = chroma_cqt[:,order_12] # length 12\n",
        "chroma_stft = chroma_stft[:,order_12] # length 20\n",
        "chroma_mfcc = chroma_mfcc[:,order_20] # length 20\n",
        "spectral_contrast = spectral_contrast[:,order_7] # length 7\n",
        "tonnetz = tonnetz[:,order_6] # length 6\n",
        "\n",
        "chroma_censval = chroma_censval[:,order_12] # length 12\n",
        "chroma_cqtval = chroma_cqtval[:,order_12] # length 12\n",
        "chroma_stftval = chroma_stftval[:,order_12] # length 20\n",
        "chroma_mfccval = chroma_mfccval[:,order_20] # length 20\n",
        "spectral_contrastval = spectral_contrastval[:,order_7] # length 7\n",
        "tonnetzval = tonnetzval[:,order_6] # length 6\n",
        "\n",
        "chroma_censtrainval = chroma_censtrainval[:,order_12] # length 12\n",
        "chroma_cqttrainval = chroma_cqttrainval[:,order_12] # length 12\n",
        "chroma_stfttrainval = chroma_stfttrainval[:,order_12] # length 20\n",
        "chroma_mfcctrainval = chroma_mfcctrainval[:,order_20] # length 20\n",
        "spectral_contrasttrainval = spectral_contrasttrainval[:,order_7] # length 7\n",
        "tonnetztrainval = tonnetztrainval[:,order_6] # length 6\n",
        "\n",
        "#reshape for cnn\n",
        "cnn_chroma_cens = chroma_cens.reshape(xtrain.shape[0],int(chroma_cens.shape[1]/7),7)\n",
        "cnn_chroma_cqt = chroma_cqt.reshape(xtrain.shape[0],int(chroma_cqt.shape[1]/7),7)\n",
        "cnn_chroma_stft = chroma_stft.reshape(xtrain.shape[0],int(chroma_stft.shape[1]/7),7)\n",
        "cnn_chroma_mfcc = chroma_mfcc.reshape(xtrain.shape[0],int(chroma_mfcc.shape[1]/7),7)\n",
        "cnn_rmse = rmse.reshape(xtrain.shape[0],int(rmse.shape[1]/7),7)\n",
        "cnn_spectral_bandwidth = spectral_bandwidth.reshape(xtrain.shape[0],int(spectral_bandwidth.shape[1]/7),7)\n",
        "cnn_spectral_centroid = spectral_centroid.reshape(xtrain.shape[0],int(spectral_centroid.shape[1]/7),7)\n",
        "cnn_spectral_contrast = spectral_contrast.reshape(xtrain.shape[0],int(spectral_contrast.shape[1]/7),7)\n",
        "cnn_spectral_rolloff = spectral_rolloff.reshape(xtrain.shape[0],int(spectral_rolloff.shape[1]/7),7)\n",
        "cnn_tonnetz = tonnetz.reshape(xtrain.shape[0],int(tonnetz.shape[1]/7),7)\n",
        "cnn_zcr = zcr.reshape(xtrain.shape[0],int(zcr.shape[1]/7),7)\n",
        "\n",
        "cnn_chroma_censval = chroma_censval.reshape(xval.shape[0],int(chroma_censval.shape[1]/7),7)\n",
        "cnn_chroma_cqtval = chroma_cqtval.reshape(xval.shape[0],int(chroma_cqtval.shape[1]/7),7)\n",
        "cnn_chroma_stftval = chroma_stftval.reshape(xval.shape[0],int(chroma_stftval.shape[1]/7),7)\n",
        "cnn_chroma_mfccval = chroma_mfccval.reshape(xval.shape[0],int(chroma_mfccval.shape[1]/7),7)\n",
        "cnn_rmseval = rmseval.reshape(xval.shape[0],int(rmseval.shape[1]/7),7)\n",
        "cnn_spectral_bandwidthval = spectral_bandwidthval.reshape(xval.shape[0],int(spectral_bandwidthval.shape[1]/7),7)\n",
        "cnn_spectral_centroidval = spectral_centroidval.reshape(xval.shape[0],int(spectral_centroidval.shape[1]/7),7)\n",
        "cnn_spectral_contrastval = spectral_contrastval.reshape(xval.shape[0],int(spectral_contrastval.shape[1]/7),7)\n",
        "cnn_spectral_rolloffval = spectral_rolloffval.reshape(xval.shape[0],int(spectral_rolloffval.shape[1]/7),7)\n",
        "cnn_tonnetzval = tonnetzval.reshape(xval.shape[0],int(tonnetzval.shape[1]/7),7)\n",
        "cnn_zcrval = zcrval.reshape(xval.shape[0],int(zcrval.shape[1]/7),7)\n",
        "\n",
        "cnn_chroma_censtrainval = chroma_censtrainval.reshape(xtrainval.shape[0],int(chroma_censtrainval.shape[1]/7),7)\n",
        "cnn_chroma_cqttrainval = chroma_cqttrainval.reshape(xtrainval.shape[0],int(chroma_cqttrainval.shape[1]/7),7)\n",
        "cnn_chroma_stfttrainval = chroma_stfttrainval.reshape(xtrainval.shape[0],int(chroma_stfttrainval.shape[1]/7),7)\n",
        "cnn_chroma_mfcctrainval = chroma_mfcctrainval.reshape(xtrainval.shape[0],int(chroma_mfcctrainval.shape[1]/7),7)\n",
        "cnn_rmsetrainval = rmsetrainval.reshape(xtrainval.shape[0],int(rmsetrainval.shape[1]/7),7)\n",
        "cnn_spectral_bandwidthtrainval = spectral_bandwidthtrainval.reshape(xtrainval.shape[0],int(spectral_bandwidthtrainval.shape[1]/7),7)\n",
        "cnn_spectral_centroidtrainval = spectral_centroidtrainval.reshape(xtrainval.shape[0],int(spectral_centroidtrainval.shape[1]/7),7)\n",
        "cnn_spectral_contrasttrainval = spectral_contrasttrainval.reshape(xtrainval.shape[0],int(spectral_contrasttrainval.shape[1]/7),7)\n",
        "cnn_spectral_rollofftrainval = spectral_rollofftrainval.reshape(xtrainval.shape[0],int(spectral_rollofftrainval.shape[1]/7),7)\n",
        "cnn_tonnetztrainval = tonnetztrainval.reshape(xtrainval.shape[0],int(tonnetztrainval.shape[1]/7),7)\n",
        "cnn_zcrtrainval = zcrtrainval.reshape(xtrainval.shape[0],int(zcrtrainval.shape[1]/7),7)\n",
        "\n",
        "# print number of songs in each category\n",
        "print(np.sum(ytrain_1hot,axis=0))\n",
        "print(np.sum(yval_1hot,axis=0))\n",
        "print(np.sum(ytest_1hot,axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARgyCAMxqOKr",
        "outputId": "fb942ee9-bca1-44c9-f31e-6962bb0f476c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11518  7564  8585  2925  2246  1658  1898  1139   983   436   458   160\n",
            "   142   354    87    21]\n",
            "[1240  868  995  273  263  197  217  126  110   53   56   13   16   29\n",
            "    7    1]\n",
            "[1424  940 1028  354  294  224  217  124  137   65   57   21   17   40\n",
            "   16    2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train and test best MLP architecture using all features \n",
        "layer_list = [ #520 parameters in input\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Dropout(rate=0.2),\n",
        "          layers.Dense(512,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dropout(rate=0.2),\n",
        "          layers.Dense(256,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(128,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(64,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(32,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n",
        "          ]\n",
        "model = Sequential(layer_list)\n",
        "model.compile(optimizer=keras.optimizers.Adam(\n",
        "    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n",
        "    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n",
        "history = model.fit(xtrain, ytrain_1hot, batch_size=32, epochs=100, validation_data=(xval, yval_1hot))\n",
        "from sklearn import preprocessing\n",
        "#scaler = preprocessing.StandardScaler().fit(xtest)\n",
        "#xtest_scaled = scaler.transform(xtest)\n",
        "#model.evaluate(xtest_scaled,ytest_1hot)\n",
        "'''\n",
        "model.evaluate(xtest,ytest_1hot)\n",
        "test_predictions = np.rint(model.predict(xtest))\n",
        "print(test_predictions)\n",
        "test_predictions = np.sum(test_predictions,axis=0)\n",
        "truth = np.sum(ytest_1hot, axis=0)\n",
        "print(test_predictions)\n",
        "print(truth)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulW0EsxXvW-s",
        "outputId": "bae71799-d79b-4de7-8236-d503b224c07b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1256/1256 [==============================] - 21s 15ms/step - loss: 1.4853 - accuracy: 0.5385 - val_loss: 1.2914 - val_accuracy: 0.5717\n",
            "Epoch 2/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.3034 - accuracy: 0.5731 - val_loss: 1.2270 - val_accuracy: 0.5966\n",
            "Epoch 3/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.2728 - accuracy: 0.5844 - val_loss: 1.2298 - val_accuracy: 0.5901\n",
            "Epoch 4/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.2523 - accuracy: 0.5877 - val_loss: 1.1854 - val_accuracy: 0.6129\n",
            "Epoch 5/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.2340 - accuracy: 0.5967 - val_loss: 1.1947 - val_accuracy: 0.6093\n",
            "Epoch 6/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.2146 - accuracy: 0.6020 - val_loss: 1.1696 - val_accuracy: 0.6216\n",
            "Epoch 7/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.2025 - accuracy: 0.6026 - val_loss: 1.1618 - val_accuracy: 0.6147\n",
            "Epoch 8/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.1937 - accuracy: 0.6072 - val_loss: 1.1652 - val_accuracy: 0.6022\n",
            "Epoch 9/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.1849 - accuracy: 0.6097 - val_loss: 1.1278 - val_accuracy: 0.6259\n",
            "Epoch 10/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.1772 - accuracy: 0.6130 - val_loss: 1.1392 - val_accuracy: 0.6230\n",
            "Epoch 11/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.1641 - accuracy: 0.6158 - val_loss: 1.1469 - val_accuracy: 0.6196\n",
            "Epoch 12/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.1544 - accuracy: 0.6215 - val_loss: 1.1302 - val_accuracy: 0.6263\n",
            "Epoch 13/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.1528 - accuracy: 0.6202 - val_loss: 1.1088 - val_accuracy: 0.6346\n",
            "Epoch 14/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.1402 - accuracy: 0.6267 - val_loss: 1.1203 - val_accuracy: 0.6237\n",
            "Epoch 15/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.1336 - accuracy: 0.6285 - val_loss: 1.1153 - val_accuracy: 0.6252\n",
            "Epoch 16/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.1249 - accuracy: 0.6281 - val_loss: 1.0958 - val_accuracy: 0.6389\n",
            "Epoch 17/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.1195 - accuracy: 0.6315 - val_loss: 1.0916 - val_accuracy: 0.6431\n",
            "Epoch 18/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.1149 - accuracy: 0.6327 - val_loss: 1.1166 - val_accuracy: 0.6295\n",
            "Epoch 19/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.1066 - accuracy: 0.6365 - val_loss: 1.0857 - val_accuracy: 0.6429\n",
            "Epoch 20/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.0955 - accuracy: 0.6382 - val_loss: 1.1148 - val_accuracy: 0.6281\n",
            "Epoch 21/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.0861 - accuracy: 0.6434 - val_loss: 1.0917 - val_accuracy: 0.6353\n",
            "Epoch 22/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.0819 - accuracy: 0.6424 - val_loss: 1.0955 - val_accuracy: 0.6360\n",
            "Epoch 23/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 1.0797 - accuracy: 0.6441 - val_loss: 1.0794 - val_accuracy: 0.6398\n",
            "Epoch 24/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.0734 - accuracy: 0.6446 - val_loss: 1.0759 - val_accuracy: 0.6371\n",
            "Epoch 25/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.0631 - accuracy: 0.6505 - val_loss: 1.1006 - val_accuracy: 0.6308\n",
            "Epoch 26/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 1.0550 - accuracy: 0.6532 - val_loss: 1.0669 - val_accuracy: 0.6514\n",
            "Epoch 27/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.0504 - accuracy: 0.6508 - val_loss: 1.0899 - val_accuracy: 0.6490\n",
            "Epoch 28/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 1.0419 - accuracy: 0.6571 - val_loss: 1.0899 - val_accuracy: 0.6431\n",
            "Epoch 29/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.0370 - accuracy: 0.6585 - val_loss: 1.0682 - val_accuracy: 0.6452\n",
            "Epoch 30/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.0272 - accuracy: 0.6567 - val_loss: 1.0849 - val_accuracy: 0.6422\n",
            "Epoch 31/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.0221 - accuracy: 0.6608 - val_loss: 1.0815 - val_accuracy: 0.6429\n",
            "Epoch 32/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 1.0197 - accuracy: 0.6610 - val_loss: 1.0635 - val_accuracy: 0.6532\n",
            "Epoch 33/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.0133 - accuracy: 0.6624 - val_loss: 1.0823 - val_accuracy: 0.6461\n",
            "Epoch 34/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 1.0067 - accuracy: 0.6645 - val_loss: 1.0757 - val_accuracy: 0.6422\n",
            "Epoch 35/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.9976 - accuracy: 0.6680 - val_loss: 1.0613 - val_accuracy: 0.6510\n",
            "Epoch 36/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.9943 - accuracy: 0.6683 - val_loss: 1.0740 - val_accuracy: 0.6481\n",
            "Epoch 37/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.9875 - accuracy: 0.6716 - val_loss: 1.0691 - val_accuracy: 0.6508\n",
            "Epoch 38/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.9849 - accuracy: 0.6732 - val_loss: 1.0769 - val_accuracy: 0.6483\n",
            "Epoch 39/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.9804 - accuracy: 0.6741 - val_loss: 1.0559 - val_accuracy: 0.6517\n",
            "Epoch 40/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.9714 - accuracy: 0.6768 - val_loss: 1.0597 - val_accuracy: 0.6519\n",
            "Epoch 41/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.9594 - accuracy: 0.6813 - val_loss: 1.0556 - val_accuracy: 0.6584\n",
            "Epoch 42/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.9556 - accuracy: 0.6825 - val_loss: 1.0772 - val_accuracy: 0.6476\n",
            "Epoch 43/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.9524 - accuracy: 0.6811 - val_loss: 1.0621 - val_accuracy: 0.6588\n",
            "Epoch 44/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.9435 - accuracy: 0.6865 - val_loss: 1.0745 - val_accuracy: 0.6548\n",
            "Epoch 45/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.9391 - accuracy: 0.6865 - val_loss: 1.0522 - val_accuracy: 0.6579\n",
            "Epoch 46/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.9371 - accuracy: 0.6872 - val_loss: 1.0615 - val_accuracy: 0.6526\n",
            "Epoch 47/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.9362 - accuracy: 0.6872 - val_loss: 1.0731 - val_accuracy: 0.6514\n",
            "Epoch 48/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.9303 - accuracy: 0.6875 - val_loss: 1.0718 - val_accuracy: 0.6476\n",
            "Epoch 49/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.9198 - accuracy: 0.6923 - val_loss: 1.0756 - val_accuracy: 0.6492\n",
            "Epoch 50/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.9187 - accuracy: 0.6936 - val_loss: 1.0523 - val_accuracy: 0.6624\n",
            "Epoch 51/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.9129 - accuracy: 0.6952 - val_loss: 1.0928 - val_accuracy: 0.6409\n",
            "Epoch 52/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.9036 - accuracy: 0.6930 - val_loss: 1.0702 - val_accuracy: 0.6552\n",
            "Epoch 53/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.9060 - accuracy: 0.6982 - val_loss: 1.0627 - val_accuracy: 0.6496\n",
            "Epoch 54/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.9022 - accuracy: 0.6996 - val_loss: 1.0799 - val_accuracy: 0.6503\n",
            "Epoch 55/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.8944 - accuracy: 0.7017 - val_loss: 1.0535 - val_accuracy: 0.6552\n",
            "Epoch 56/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.8854 - accuracy: 0.7001 - val_loss: 1.0921 - val_accuracy: 0.6476\n",
            "Epoch 57/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.8838 - accuracy: 0.7032 - val_loss: 1.0659 - val_accuracy: 0.6624\n",
            "Epoch 58/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.8778 - accuracy: 0.7063 - val_loss: 1.0720 - val_accuracy: 0.6561\n",
            "Epoch 59/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.8706 - accuracy: 0.7054 - val_loss: 1.0854 - val_accuracy: 0.6534\n",
            "Epoch 60/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8678 - accuracy: 0.7081 - val_loss: 1.0650 - val_accuracy: 0.6608\n",
            "Epoch 61/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8683 - accuracy: 0.7077 - val_loss: 1.0717 - val_accuracy: 0.6552\n",
            "Epoch 62/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8608 - accuracy: 0.7108 - val_loss: 1.0573 - val_accuracy: 0.6606\n",
            "Epoch 63/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8555 - accuracy: 0.7121 - val_loss: 1.0617 - val_accuracy: 0.6615\n",
            "Epoch 64/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8467 - accuracy: 0.7116 - val_loss: 1.0823 - val_accuracy: 0.6530\n",
            "Epoch 65/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.8469 - accuracy: 0.7154 - val_loss: 1.0762 - val_accuracy: 0.6566\n",
            "Epoch 66/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8428 - accuracy: 0.7145 - val_loss: 1.0763 - val_accuracy: 0.6597\n",
            "Epoch 67/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.8343 - accuracy: 0.7160 - val_loss: 1.0582 - val_accuracy: 0.6647\n",
            "Epoch 68/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8362 - accuracy: 0.7174 - val_loss: 1.0956 - val_accuracy: 0.6550\n",
            "Epoch 69/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8294 - accuracy: 0.7211 - val_loss: 1.0758 - val_accuracy: 0.6606\n",
            "Epoch 70/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8295 - accuracy: 0.7206 - val_loss: 1.0663 - val_accuracy: 0.6613\n",
            "Epoch 71/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8239 - accuracy: 0.7209 - val_loss: 1.0797 - val_accuracy: 0.6570\n",
            "Epoch 72/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8237 - accuracy: 0.7194 - val_loss: 1.0906 - val_accuracy: 0.6523\n",
            "Epoch 73/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8191 - accuracy: 0.7226 - val_loss: 1.0788 - val_accuracy: 0.6548\n",
            "Epoch 74/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8085 - accuracy: 0.7261 - val_loss: 1.0897 - val_accuracy: 0.6528\n",
            "Epoch 75/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.8072 - accuracy: 0.7229 - val_loss: 1.0703 - val_accuracy: 0.6615\n",
            "Epoch 76/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.8010 - accuracy: 0.7271 - val_loss: 1.0784 - val_accuracy: 0.6557\n",
            "Epoch 77/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.7987 - accuracy: 0.7288 - val_loss: 1.0667 - val_accuracy: 0.6615\n",
            "Epoch 78/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.7981 - accuracy: 0.7300 - val_loss: 1.0677 - val_accuracy: 0.6595\n",
            "Epoch 79/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.7864 - accuracy: 0.7353 - val_loss: 1.0750 - val_accuracy: 0.6642\n",
            "Epoch 80/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.7907 - accuracy: 0.7281 - val_loss: 1.0637 - val_accuracy: 0.6655\n",
            "Epoch 81/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.7844 - accuracy: 0.7328 - val_loss: 1.0795 - val_accuracy: 0.6566\n",
            "Epoch 82/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.7778 - accuracy: 0.7343 - val_loss: 1.0847 - val_accuracy: 0.6564\n",
            "Epoch 83/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.7696 - accuracy: 0.7379 - val_loss: 1.1121 - val_accuracy: 0.6501\n",
            "Epoch 84/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.7738 - accuracy: 0.7365 - val_loss: 1.0969 - val_accuracy: 0.6573\n",
            "Epoch 85/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.7728 - accuracy: 0.7364 - val_loss: 1.0871 - val_accuracy: 0.6591\n",
            "Epoch 86/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.7643 - accuracy: 0.7372 - val_loss: 1.0831 - val_accuracy: 0.6658\n",
            "Epoch 87/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.7644 - accuracy: 0.7396 - val_loss: 1.0725 - val_accuracy: 0.6664\n",
            "Epoch 88/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.7575 - accuracy: 0.7424 - val_loss: 1.0880 - val_accuracy: 0.6593\n",
            "Epoch 89/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.7576 - accuracy: 0.7418 - val_loss: 1.1094 - val_accuracy: 0.6577\n",
            "Epoch 90/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.7530 - accuracy: 0.7425 - val_loss: 1.0852 - val_accuracy: 0.6550\n",
            "Epoch 91/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.7506 - accuracy: 0.7426 - val_loss: 1.0974 - val_accuracy: 0.6586\n",
            "Epoch 92/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.7500 - accuracy: 0.7425 - val_loss: 1.0924 - val_accuracy: 0.6606\n",
            "Epoch 93/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.7476 - accuracy: 0.7440 - val_loss: 1.0832 - val_accuracy: 0.6620\n",
            "Epoch 94/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.7427 - accuracy: 0.7452 - val_loss: 1.1074 - val_accuracy: 0.6514\n",
            "Epoch 95/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.7367 - accuracy: 0.7484 - val_loss: 1.0912 - val_accuracy: 0.6608\n",
            "Epoch 96/100\n",
            "1256/1256 [==============================] - 18s 15ms/step - loss: 0.7425 - accuracy: 0.7435 - val_loss: 1.0923 - val_accuracy: 0.6566\n",
            "Epoch 97/100\n",
            "1256/1256 [==============================] - 19s 15ms/step - loss: 0.7287 - accuracy: 0.7480 - val_loss: 1.1195 - val_accuracy: 0.6528\n",
            "Epoch 98/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.7354 - accuracy: 0.7468 - val_loss: 1.0990 - val_accuracy: 0.6606\n",
            "Epoch 99/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.7276 - accuracy: 0.7488 - val_loss: 1.0826 - val_accuracy: 0.6624\n",
            "Epoch 100/100\n",
            "1256/1256 [==============================] - 18s 14ms/step - loss: 0.7261 - accuracy: 0.7505 - val_loss: 1.0812 - val_accuracy: 0.6660\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 2463.3352 - accuracy: 0.1111\n",
            "[[0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]]\n",
            "[1.500e+02 1.380e+02 1.610e+02 8.500e+01 8.700e+01 4.200e+01 1.400e+01\n",
            " 3.000e+01 5.400e+01 3.500e+01 1.500e+01 5.000e+00 2.000e+00 3.989e+03\n",
            " 0.000e+00 0.000e+00]\n",
            "[1424  940 1028  354  294  224  217  124  137   65   57   21   17   40\n",
            "   16    2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.StandardScaler().fit(xtest)\n",
        "xtest_scaled = scaler.transform(xtest)\n",
        "model.evaluate(xtest_scaled,ytest_1hot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3FnyZpDcouT",
        "outputId": "7531b594-919b-45a6-cfc1-e096f32c6b91"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 1s 7ms/step - loss: 1.1034 - accuracy: 0.6665\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1033774614334106, 0.6665322780609131]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_list = [ #520 parameters in input\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Dense(50,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('relu'),\n",
        "          layers.Dense(512,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(16,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('relu'),\n",
        "          layers.Dense(16,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n",
        "          ]\n",
        "model = Sequential(layer_list)\n",
        "model.compile(optimizer=keras.optimizers.Adam(\n",
        "    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n",
        "    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n",
        "history = model.fit(xtrain, ytrain_1hot, batch_size=32, epochs=50, validation_data=(xval, yval_1hot))\n",
        "model.evaluate(xtest_scaled,ytest_1hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAydWuabEAVz",
        "outputId": "24633bf7-651e-4122-9085-8aa3558ba82e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1256/1256 [==============================] - 8s 5ms/step - loss: 1.5409 - accuracy: 0.5393 - val_loss: 1.3485 - val_accuracy: 0.5609\n",
            "Epoch 2/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.2532 - accuracy: 0.5984 - val_loss: 1.2405 - val_accuracy: 0.5977\n",
            "Epoch 3/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.1933 - accuracy: 0.6154 - val_loss: 1.1705 - val_accuracy: 0.6268\n",
            "Epoch 4/50\n",
            "1256/1256 [==============================] - 7s 5ms/step - loss: 1.1660 - accuracy: 0.6217 - val_loss: 1.1664 - val_accuracy: 0.6203\n",
            "Epoch 5/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.1386 - accuracy: 0.6333 - val_loss: 1.1345 - val_accuracy: 0.6272\n",
            "Epoch 6/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.1173 - accuracy: 0.6390 - val_loss: 1.1448 - val_accuracy: 0.6192\n",
            "Epoch 7/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.0992 - accuracy: 0.6444 - val_loss: 1.1294 - val_accuracy: 0.6241\n",
            "Epoch 8/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.0840 - accuracy: 0.6499 - val_loss: 1.1473 - val_accuracy: 0.6268\n",
            "Epoch 9/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.0715 - accuracy: 0.6541 - val_loss: 1.1342 - val_accuracy: 0.6297\n",
            "Epoch 10/50\n",
            "1256/1256 [==============================] - 7s 5ms/step - loss: 1.0583 - accuracy: 0.6551 - val_loss: 1.1310 - val_accuracy: 0.6331\n",
            "Epoch 11/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.0488 - accuracy: 0.6596 - val_loss: 1.1389 - val_accuracy: 0.6210\n",
            "Epoch 12/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.0355 - accuracy: 0.6625 - val_loss: 1.1073 - val_accuracy: 0.6340\n",
            "Epoch 13/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.0266 - accuracy: 0.6633 - val_loss: 1.1130 - val_accuracy: 0.6351\n",
            "Epoch 14/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.0190 - accuracy: 0.6672 - val_loss: 1.1614 - val_accuracy: 0.6201\n",
            "Epoch 15/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.0140 - accuracy: 0.6712 - val_loss: 1.1294 - val_accuracy: 0.6281\n",
            "Epoch 16/50\n",
            "1256/1256 [==============================] - 7s 5ms/step - loss: 1.0044 - accuracy: 0.6726 - val_loss: 1.0954 - val_accuracy: 0.6418\n",
            "Epoch 17/50\n",
            "1256/1256 [==============================] - 7s 5ms/step - loss: 1.0001 - accuracy: 0.6755 - val_loss: 1.1070 - val_accuracy: 0.6400\n",
            "Epoch 18/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 0.9877 - accuracy: 0.6782 - val_loss: 1.1148 - val_accuracy: 0.6420\n",
            "Epoch 19/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 0.9850 - accuracy: 0.6773 - val_loss: 1.1227 - val_accuracy: 0.6393\n",
            "Epoch 20/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 0.9786 - accuracy: 0.6791 - val_loss: 1.1135 - val_accuracy: 0.6458\n",
            "Epoch 21/50\n",
            "1256/1256 [==============================] - 7s 5ms/step - loss: 0.9697 - accuracy: 0.6823 - val_loss: 1.1441 - val_accuracy: 0.6344\n",
            "Epoch 22/50\n",
            "1256/1256 [==============================] - 7s 6ms/step - loss: 0.9689 - accuracy: 0.6846 - val_loss: 1.1185 - val_accuracy: 0.6416\n",
            "Epoch 23/50\n",
            "1256/1256 [==============================] - 7s 6ms/step - loss: 0.9602 - accuracy: 0.6867 - val_loss: 1.1269 - val_accuracy: 0.6364\n",
            "Epoch 24/50\n",
            "1256/1256 [==============================] - 7s 6ms/step - loss: 0.9514 - accuracy: 0.6894 - val_loss: 1.1261 - val_accuracy: 0.6405\n",
            "Epoch 25/50\n",
            "1256/1256 [==============================] - 7s 6ms/step - loss: 0.9514 - accuracy: 0.6883 - val_loss: 1.1066 - val_accuracy: 0.6452\n",
            "Epoch 26/50\n",
            "1256/1256 [==============================] - 8s 7ms/step - loss: 0.9417 - accuracy: 0.6922 - val_loss: 1.1012 - val_accuracy: 0.6579\n",
            "Epoch 27/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 0.9352 - accuracy: 0.6946 - val_loss: 1.1072 - val_accuracy: 0.6521\n",
            "Epoch 28/50\n",
            "1256/1256 [==============================] - 7s 5ms/step - loss: 0.9326 - accuracy: 0.6948 - val_loss: 1.1180 - val_accuracy: 0.6487\n",
            "Epoch 29/50\n",
            "1256/1256 [==============================] - 7s 5ms/step - loss: 0.9271 - accuracy: 0.6933 - val_loss: 1.1642 - val_accuracy: 0.6246\n",
            "Epoch 30/50\n",
            "1256/1256 [==============================] - 7s 5ms/step - loss: 0.9183 - accuracy: 0.6977 - val_loss: 1.0984 - val_accuracy: 0.6510\n",
            "Epoch 31/50\n",
            "1256/1256 [==============================] - 7s 5ms/step - loss: 0.9216 - accuracy: 0.6961 - val_loss: 1.1327 - val_accuracy: 0.6308\n",
            "Epoch 32/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 0.9094 - accuracy: 0.6996 - val_loss: 1.1082 - val_accuracy: 0.6517\n",
            "Epoch 33/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 0.9068 - accuracy: 0.7010 - val_loss: 1.1205 - val_accuracy: 0.6407\n",
            "Epoch 34/50\n",
            "1256/1256 [==============================] - 7s 6ms/step - loss: 0.9010 - accuracy: 0.7017 - val_loss: 1.1285 - val_accuracy: 0.6465\n",
            "Epoch 35/50\n",
            "1256/1256 [==============================] - 7s 6ms/step - loss: 0.9005 - accuracy: 0.7028 - val_loss: 1.1099 - val_accuracy: 0.6494\n",
            "Epoch 36/50\n",
            "1256/1256 [==============================] - 8s 6ms/step - loss: 0.8944 - accuracy: 0.7039 - val_loss: 1.1315 - val_accuracy: 0.6420\n",
            "Epoch 37/50\n",
            "1256/1256 [==============================] - 8s 7ms/step - loss: 0.8908 - accuracy: 0.7069 - val_loss: 1.1381 - val_accuracy: 0.6384\n",
            "Epoch 38/50\n",
            "1256/1256 [==============================] - 10s 8ms/step - loss: 0.8863 - accuracy: 0.7077 - val_loss: 1.1388 - val_accuracy: 0.6440\n",
            "Epoch 39/50\n",
            "1256/1256 [==============================] - 10s 8ms/step - loss: 0.8829 - accuracy: 0.7075 - val_loss: 1.1377 - val_accuracy: 0.6389\n",
            "Epoch 40/50\n",
            "1256/1256 [==============================] - 10s 8ms/step - loss: 0.8796 - accuracy: 0.7086 - val_loss: 1.1443 - val_accuracy: 0.6391\n",
            "Epoch 41/50\n",
            "1256/1256 [==============================] - 10s 8ms/step - loss: 0.8716 - accuracy: 0.7119 - val_loss: 1.1340 - val_accuracy: 0.6422\n",
            "Epoch 42/50\n",
            "1256/1256 [==============================] - 10s 8ms/step - loss: 0.8720 - accuracy: 0.7122 - val_loss: 1.1433 - val_accuracy: 0.6380\n",
            "Epoch 43/50\n",
            "1256/1256 [==============================] - 10s 8ms/step - loss: 0.8719 - accuracy: 0.7119 - val_loss: 1.1307 - val_accuracy: 0.6434\n",
            "Epoch 44/50\n",
            "1256/1256 [==============================] - 7s 6ms/step - loss: 0.8593 - accuracy: 0.7164 - val_loss: 1.1544 - val_accuracy: 0.6335\n",
            "Epoch 45/50\n",
            "1256/1256 [==============================] - 7s 6ms/step - loss: 0.8575 - accuracy: 0.7163 - val_loss: 1.1629 - val_accuracy: 0.6389\n",
            "Epoch 46/50\n",
            "1256/1256 [==============================] - 8s 6ms/step - loss: 0.8546 - accuracy: 0.7160 - val_loss: 1.1506 - val_accuracy: 0.6335\n",
            "Epoch 47/50\n",
            "1256/1256 [==============================] - 10s 8ms/step - loss: 0.8519 - accuracy: 0.7164 - val_loss: 1.1349 - val_accuracy: 0.6391\n",
            "Epoch 48/50\n",
            "1256/1256 [==============================] - 10s 8ms/step - loss: 0.8478 - accuracy: 0.7180 - val_loss: 1.1243 - val_accuracy: 0.6458\n",
            "Epoch 49/50\n",
            "1256/1256 [==============================] - 8s 6ms/step - loss: 0.8441 - accuracy: 0.7196 - val_loss: 1.1178 - val_accuracy: 0.6461\n",
            "Epoch 50/50\n",
            "1256/1256 [==============================] - 7s 5ms/step - loss: 0.8452 - accuracy: 0.7198 - val_loss: 1.1524 - val_accuracy: 0.6418\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 1.1950 - accuracy: 0.6359\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1949912309646606, 0.635887086391449]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the same model on a smaller subset of features produces worse results on the validation set\n",
        "layer_list2 = [ #520 parameters in input\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Dense(50,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('relu'),\n",
        "          layers.Dense(512,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(16,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('relu'),\n",
        "          layers.Dense(16,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n",
        "          ]\n",
        "chroma_censtest = cnn_chroma_censtest.reshape(cnn_chroma_censtest.shape[0],84)\n",
        "print(chroma_cens.shape)\n",
        "print(chroma_censval.shape)\n",
        "print(cnn_chroma_censtest.shape)\n",
        "model2 = Sequential(layer_list2)\n",
        "model2.compile(optimizer=keras.optimizers.Adam(\n",
        "    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n",
        "    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n",
        "history = model2.fit(chroma_cens, ytrain_1hot, batch_size=32, epochs=20, validation_data=(chroma_censval, yval_1hot))\n",
        "scaler = preprocessing.StandardScaler().fit(chroma_censtest) #defined test set below, not actually doing cnn here\n",
        "chroma_censtest_scaled = scaler.transform(chroma_censtest)\n",
        "model2.evaluate(chroma_censtest_scaled,ytest_1hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0FGx8J4idhM",
        "outputId": "9e28a2f9-7951-4254-96bc-79680b6790d5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40174, 84)\n",
            "(4464, 84)\n",
            "(4960, 12, 7)\n",
            "Epoch 1/20\n",
            "1256/1256 [==============================] - 8s 5ms/step - loss: 2.0058 - accuracy: 0.3329 - val_loss: 1.8572 - val_accuracy: 0.3401\n",
            "Epoch 2/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7940 - accuracy: 0.3750 - val_loss: 1.8121 - val_accuracy: 0.3651\n",
            "Epoch 3/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7573 - accuracy: 0.3866 - val_loss: 1.7802 - val_accuracy: 0.3880\n",
            "Epoch 4/20\n",
            "1256/1256 [==============================] - 6s 4ms/step - loss: 1.7375 - accuracy: 0.3913 - val_loss: 1.8071 - val_accuracy: 0.3833\n",
            "Epoch 5/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7263 - accuracy: 0.3991 - val_loss: 1.7804 - val_accuracy: 0.3920\n",
            "Epoch 6/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7116 - accuracy: 0.4069 - val_loss: 1.7596 - val_accuracy: 0.4032\n",
            "Epoch 7/20\n",
            "1256/1256 [==============================] - 6s 4ms/step - loss: 1.7018 - accuracy: 0.4067 - val_loss: 1.7592 - val_accuracy: 0.4017\n",
            "Epoch 8/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6913 - accuracy: 0.4124 - val_loss: 1.7416 - val_accuracy: 0.4120\n",
            "Epoch 9/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6872 - accuracy: 0.4138 - val_loss: 1.7552 - val_accuracy: 0.4075\n",
            "Epoch 10/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6779 - accuracy: 0.4190 - val_loss: 1.7272 - val_accuracy: 0.4135\n",
            "Epoch 11/20\n",
            "1256/1256 [==============================] - 6s 4ms/step - loss: 1.6765 - accuracy: 0.4189 - val_loss: 1.7303 - val_accuracy: 0.4079\n",
            "Epoch 12/20\n",
            "1256/1256 [==============================] - 6s 4ms/step - loss: 1.6735 - accuracy: 0.4197 - val_loss: 1.7465 - val_accuracy: 0.4028\n",
            "Epoch 13/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6647 - accuracy: 0.4241 - val_loss: 1.7309 - val_accuracy: 0.4225\n",
            "Epoch 14/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6623 - accuracy: 0.4241 - val_loss: 1.7246 - val_accuracy: 0.4120\n",
            "Epoch 15/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6601 - accuracy: 0.4258 - val_loss: 1.7428 - val_accuracy: 0.4160\n",
            "Epoch 16/20\n",
            "1256/1256 [==============================] - 8s 7ms/step - loss: 1.6550 - accuracy: 0.4268 - val_loss: 1.7490 - val_accuracy: 0.4138\n",
            "Epoch 17/20\n",
            "1256/1256 [==============================] - 6s 4ms/step - loss: 1.6551 - accuracy: 0.4279 - val_loss: 1.7435 - val_accuracy: 0.4173\n",
            "Epoch 18/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6508 - accuracy: 0.4285 - val_loss: 1.7167 - val_accuracy: 0.4140\n",
            "Epoch 19/20\n",
            "1256/1256 [==============================] - 5s 4ms/step - loss: 1.6465 - accuracy: 0.4292 - val_loss: 1.7018 - val_accuracy: 0.4236\n",
            "Epoch 20/20\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6420 - accuracy: 0.4326 - val_loss: 1.7294 - val_accuracy: 0.4057\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 1.7050 - accuracy: 0.4145\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7049670219421387, 0.4145161211490631]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# realizing that I forgot to divide test set up by features when preprocessing\n",
        "chroma_censtest = xtest[:,:84] # length 12\n",
        "chroma_cqttest = xtest[:,84:168] # length 12\n",
        "chroma_stfttest = xtest[:,168:252]# length 12\n",
        "chroma_mfcctest = xtest[:,252:392] # length 20\n",
        "rmsetest = xtest[:,392:399]\n",
        "spectral_bandwidthtest = xtest[:,399:406]\n",
        "spectral_centroidtest = xtest[:,406:413]\n",
        "spectral_contrasttest = xtest[:,413:462]# length 7\n",
        "spectral_rollofftest = xtest[:,462:469] \n",
        "tonnetztest = xtest[:,469:511] # length 6\n",
        "zcrtest = xtest[:,511:518]\n",
        "datestest = xtest[:,518]\n",
        "durationtest = xtest[:,519]\n",
        "\n",
        "# reorder features for compatibility with CNN\n",
        "order_12 = get_index_order(12)\n",
        "order_20 = get_index_order(20)\n",
        "order_7 = get_index_order(7)\n",
        "order_6 = get_index_order(6)\n",
        "\n",
        "# reindex timeseries arrays\n",
        "chroma_censtest = chroma_censtest[:,order_12] # length 12\n",
        "chroma_cqttest = chroma_cqttest[:,order_12] # length 12\n",
        "chroma_stfttest = chroma_stfttest[:,order_12] # length 20\n",
        "chroma_mfcctest = chroma_mfcctest[:,order_20] # length 20\n",
        "spectral_contrasttest = spectral_contrasttest[:,order_7] # length 7\n",
        "tonnetztest = tonnetztest[:,order_6] # length 6\n",
        "\n",
        "# reshape\n",
        "cnn_chroma_censtest = chroma_censtest.reshape(xtest.shape[0],int(chroma_censtest.shape[1]/7),7)\n",
        "cnn_chroma_cqttest = chroma_cqttest.reshape(xtest.shape[0],int(chroma_cqttest.shape[1]/7),7)\n",
        "cnn_chroma_stfttest = chroma_stfttest.reshape(xtest.shape[0],int(chroma_stfttest.shape[1]/7),7)\n",
        "cnn_chroma_mfcctest = chroma_mfcctest.reshape(xtest.shape[0],int(chroma_mfcctest.shape[1]/7),7)\n",
        "cnn_rmsetest = rmsetest.reshape(xtest.shape[0],int(rmsetest.shape[1]/7),7)\n",
        "cnn_spectral_bandwidthtest = spectral_bandwidthtest.reshape(xtest.shape[0],int(spectral_bandwidthtest.shape[1]/7),7)\n",
        "cnn_spectral_centroidtest = spectral_centroidtest.reshape(xtest.shape[0],int(spectral_centroidtest.shape[1]/7),7)\n",
        "cnn_spectral_contrasttest = spectral_contrasttest.reshape(xtest.shape[0],int(spectral_contrasttest.shape[1]/7),7)\n",
        "cnn_spectral_rollofftest = spectral_rollofftest.reshape(xtest.shape[0],int(spectral_rollofftest.shape[1]/7),7)\n",
        "cnn_tonnetztest = tonnetztest.reshape(xtest.shape[0],int(tonnetztest.shape[1]/7),7)\n",
        "cnn_zcrtest = zcrtest.reshape(xtest.shape[0],int(zcrtest.shape[1]/7),7)"
      ],
      "metadata": {
        "id": "O1T4nORqFuqT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's take a look at cnn\n",
        "print(cnn_chroma_censtest.shape)\n",
        "layer_list3 = [\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Conv1D(7,1,strides=1,kernel_initializer='lecun_normal',input_shape=(chroma_cens.shape[1],7)), # each of 7 statistics is kind of like its own channel!\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Conv1D(8,1,strides=1,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Flatten(), # should have 160 if length is 20?\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Dropout(rate=0.2),\n",
        "          layers.Dense(80,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(40,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(32,kernel_initializer='lecun_normal'),\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n",
        "          ]\n",
        "model3 = Sequential(layer_list3)\n",
        "model3.compile(optimizer=keras.optimizers.Adam(\n",
        "    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n",
        "    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n",
        "history = model3.fit(cnn_chroma_cens, ytrain_1hot, batch_size=32, epochs=50, validation_data=(cnn_chroma_censval, yval_1hot))\n",
        "scaler = preprocessing.StandardScaler().fit(cnn_chroma_censtest.reshape(cnn_chroma_censtest.shape[0],84)) #standard scaler needs 2d data\n",
        "cnn_chroma_censtest_scaled = scaler.transform(cnn_chroma_censtest.reshape(cnn_chroma_censtest.shape[0],84))\n",
        "# had some technical difficulties getting test accuracy\n",
        "#model2.evaluate(cnn_chroma_censtest_scaled.reshape(cnn_chroma_censtest_scaled.shape[0],12,7),ytest_1hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v8cBhUsEXk5",
        "outputId": "3025d021-9465-4e47-8fe6-fa22ce8839e2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4960, 12, 7)\n",
            "Epoch 1/50\n",
            "1256/1256 [==============================] - 9s 5ms/step - loss: 2.0106 - accuracy: 0.3133 - val_loss: 1.8353 - val_accuracy: 0.3311\n",
            "Epoch 2/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.8267 - accuracy: 0.3540 - val_loss: 1.8202 - val_accuracy: 0.3304\n",
            "Epoch 3/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.8023 - accuracy: 0.3625 - val_loss: 1.7838 - val_accuracy: 0.3562\n",
            "Epoch 4/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7851 - accuracy: 0.3728 - val_loss: 1.7730 - val_accuracy: 0.3642\n",
            "Epoch 5/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7641 - accuracy: 0.3825 - val_loss: 1.7390 - val_accuracy: 0.3965\n",
            "Epoch 6/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7513 - accuracy: 0.3877 - val_loss: 1.7475 - val_accuracy: 0.3869\n",
            "Epoch 7/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7380 - accuracy: 0.3936 - val_loss: 1.7027 - val_accuracy: 0.4106\n",
            "Epoch 8/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7288 - accuracy: 0.3985 - val_loss: 1.6991 - val_accuracy: 0.4160\n",
            "Epoch 9/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7213 - accuracy: 0.3987 - val_loss: 1.7261 - val_accuracy: 0.3952\n",
            "Epoch 10/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7142 - accuracy: 0.4051 - val_loss: 1.6916 - val_accuracy: 0.4205\n",
            "Epoch 11/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7061 - accuracy: 0.4088 - val_loss: 1.6817 - val_accuracy: 0.4245\n",
            "Epoch 12/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.7012 - accuracy: 0.4094 - val_loss: 1.6605 - val_accuracy: 0.4243\n",
            "Epoch 13/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6949 - accuracy: 0.4121 - val_loss: 1.7019 - val_accuracy: 0.4180\n",
            "Epoch 14/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6942 - accuracy: 0.4124 - val_loss: 1.6557 - val_accuracy: 0.4362\n",
            "Epoch 15/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6853 - accuracy: 0.4160 - val_loss: 1.6595 - val_accuracy: 0.4339\n",
            "Epoch 16/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6879 - accuracy: 0.4147 - val_loss: 1.6737 - val_accuracy: 0.4290\n",
            "Epoch 17/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6786 - accuracy: 0.4152 - val_loss: 1.6878 - val_accuracy: 0.4261\n",
            "Epoch 18/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6746 - accuracy: 0.4194 - val_loss: 1.6508 - val_accuracy: 0.4339\n",
            "Epoch 19/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6719 - accuracy: 0.4211 - val_loss: 1.6491 - val_accuracy: 0.4290\n",
            "Epoch 20/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6695 - accuracy: 0.4228 - val_loss: 1.6376 - val_accuracy: 0.4362\n",
            "Epoch 21/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6636 - accuracy: 0.4208 - val_loss: 1.6608 - val_accuracy: 0.4241\n",
            "Epoch 22/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6596 - accuracy: 0.4248 - val_loss: 1.6392 - val_accuracy: 0.4350\n",
            "Epoch 23/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6543 - accuracy: 0.4242 - val_loss: 1.6252 - val_accuracy: 0.4415\n",
            "Epoch 24/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6543 - accuracy: 0.4267 - val_loss: 1.6488 - val_accuracy: 0.4321\n",
            "Epoch 25/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6528 - accuracy: 0.4264 - val_loss: 1.6371 - val_accuracy: 0.4301\n",
            "Epoch 26/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6495 - accuracy: 0.4265 - val_loss: 1.6280 - val_accuracy: 0.4413\n",
            "Epoch 27/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6484 - accuracy: 0.4268 - val_loss: 1.6321 - val_accuracy: 0.4362\n",
            "Epoch 28/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6432 - accuracy: 0.4311 - val_loss: 1.6161 - val_accuracy: 0.4460\n",
            "Epoch 29/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6405 - accuracy: 0.4311 - val_loss: 1.6173 - val_accuracy: 0.4431\n",
            "Epoch 30/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6416 - accuracy: 0.4310 - val_loss: 1.6451 - val_accuracy: 0.4337\n",
            "Epoch 31/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6408 - accuracy: 0.4325 - val_loss: 1.6305 - val_accuracy: 0.4411\n",
            "Epoch 32/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6320 - accuracy: 0.4347 - val_loss: 1.6316 - val_accuracy: 0.4375\n",
            "Epoch 33/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6346 - accuracy: 0.4351 - val_loss: 1.6210 - val_accuracy: 0.4480\n",
            "Epoch 34/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6339 - accuracy: 0.4325 - val_loss: 1.6173 - val_accuracy: 0.4364\n",
            "Epoch 35/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6321 - accuracy: 0.4336 - val_loss: 1.6099 - val_accuracy: 0.4458\n",
            "Epoch 36/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6272 - accuracy: 0.4391 - val_loss: 1.6102 - val_accuracy: 0.4467\n",
            "Epoch 37/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6289 - accuracy: 0.4349 - val_loss: 1.6133 - val_accuracy: 0.4453\n",
            "Epoch 38/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6278 - accuracy: 0.4351 - val_loss: 1.6101 - val_accuracy: 0.4422\n",
            "Epoch 39/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6232 - accuracy: 0.4373 - val_loss: 1.6036 - val_accuracy: 0.4590\n",
            "Epoch 40/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6239 - accuracy: 0.4364 - val_loss: 1.6240 - val_accuracy: 0.4388\n",
            "Epoch 41/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6226 - accuracy: 0.4373 - val_loss: 1.6073 - val_accuracy: 0.4420\n",
            "Epoch 42/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6193 - accuracy: 0.4381 - val_loss: 1.6033 - val_accuracy: 0.4480\n",
            "Epoch 43/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6177 - accuracy: 0.4382 - val_loss: 1.6103 - val_accuracy: 0.4447\n",
            "Epoch 44/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6155 - accuracy: 0.4404 - val_loss: 1.6059 - val_accuracy: 0.4438\n",
            "Epoch 45/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6164 - accuracy: 0.4388 - val_loss: 1.6031 - val_accuracy: 0.4424\n",
            "Epoch 46/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6136 - accuracy: 0.4404 - val_loss: 1.6286 - val_accuracy: 0.4357\n",
            "Epoch 47/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6140 - accuracy: 0.4407 - val_loss: 1.6105 - val_accuracy: 0.4379\n",
            "Epoch 48/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6158 - accuracy: 0.4390 - val_loss: 1.5972 - val_accuracy: 0.4474\n",
            "Epoch 49/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6123 - accuracy: 0.4410 - val_loss: 1.6085 - val_accuracy: 0.4494\n",
            "Epoch 50/50\n",
            "1256/1256 [==============================] - 6s 5ms/step - loss: 1.6131 - accuracy: 0.4406 - val_loss: 1.6075 - val_accuracy: 0.4388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.utils import shuffle\n",
        "ytrainval = ytrainval.reshape(ytrainval.shape[0],1)\n",
        "xtrainval = shuffle(xtrainval)\n",
        "indices = [] \n",
        "num_counter = []\n",
        "for i in range(16):\n",
        "    num_counter.append(0)\n",
        "train_max_list = [1000,1000,1000,1000,1000,1000,1000,1000,1000,100,100,100,100,100,100,20]\n",
        "for i in range(xtrainval.shape[0]):\n",
        "    if num_counter[int(xtrainval[i,-1])] < train_max_list[int(xtrainval[i,-1])]:\n",
        "        num_counter[int(xtrainval[i,-1])] += 1\n",
        "        indices.append(i)\n",
        "print(num_counter)\n",
        "both_train_small = xtrainval[indices]\n",
        "y_train_small = both_train_small[:,-1]\n",
        "y_train_small_1hot = to_categorical(y_train_small).astype('int')\n",
        "x_train_small = both_train_small[:,:-1]\n",
        "print(y_train_small_1hot.shape)\n",
        "print(y_train_small.shape)\n",
        "print(x_train_small.shape)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "ducWCLxPzqM5",
        "outputId": "5b033d9c-57ec-44c0-aa50-095cb0d44def"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-4c7469a68418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain_max_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrainval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnum_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrainval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtrain_max_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrainval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mnum_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrainval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "layer_list = [ #520 parameters in input\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Dropout(0.4),\n",
        "          layers.Dense(10,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n",
        "          layers.BatchNormalization(),\n",
        "          layers.Activation('selu'),\n",
        "          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n",
        "          ]\n",
        "model = Sequential(layer_list)\n",
        "model.compile(optimizer=keras.optimizers.Adam(\n",
        "    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n",
        "    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n",
        "history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=400, validation_data=(x_val_small, y_val_small_1hot))\n",
        "'''"
      ],
      "metadata": {
        "id": "To8kfONB_C09"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}