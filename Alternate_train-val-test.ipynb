{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Alternate_train-val-test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN+jOzFLMxOAvOZXvDXIl/X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":384},"id":"BxvyBn79x4HJ","outputId":"4bfdf670-8f7f-4854-eaab-3b105a884000","executionInfo":{"status":"ok","timestamp":1652026891804,"user_tz":240,"elapsed":1081865,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-13c803da-efbb-4570-80ce-4f379e2187b9\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-13c803da-efbb-4570-80ce-4f379e2187b9\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Y_cleaned_attempt_new.npy to Y_cleaned_attempt_new.npy\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a19402ad-6dd0-4676-aada-99bf6bfb12b1\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a19402ad-6dd0-4676-aada-99bf6bfb12b1\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving X_cleaned_attempt_new.npy to X_cleaned_attempt_new.npy\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-38144d50-4a73-474b-9456-af38e680fc17\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-38144d50-4a73-474b-9456-af38e680fc17\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Y_test.npy to Y_test.npy\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-3e01e8bc-2983-4e55-bc58-cedc44f33452\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-3e01e8bc-2983-4e55-bc58-cedc44f33452\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving X_test.npy to X_test.npy\n","(9349, 520)\n","(9349,)\n","(40249, 520)\n","(40249,)\n","[3.0 3.0 3.0 ... 4.0 0.0 array(0., dtype=float32)]\n","[3.0 6.0 0.0 ... 0.0 0.0 array(0., dtype=float32)]\n","(49598, 520)\n","(49598,)\n"]}],"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","# import libraries\n","%matplotlib inline\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.models import Sequential \n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","# Helper libraries\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from google.colab import files\n","import io\n","from sklearn.utils import shuffle\n","\n","# load mostly preprocessed data (preprocessing accomplished before 3/25 proposal)\n","\n","# would use regular numpy syntax to load locally:\n","#X = np.load('<path>/X_cleaned_attempt_new.npy',allow_pickle=True)\n","#Y = np.load('<path>/Y_cleaned_attempt_new.npy',allow_pickle=True)\n","#X = np.asarray(X).astype('float32')\n","#Y = np.asarray(Y).astype('float32')\n","\n","# i'm using colab, so it's slightly more complicated\n","ytrainval_byteseq = files.upload() # choose 'Y_cleaned_attempt_new.npy' from local system\n","ytrainval_filelike = io.BytesIO(ytrainval_byteseq['Y_cleaned_attempt_new.npy']) # create file-like object\n","ytrainval = np.load(ytrainval_filelike,allow_pickle=True) # create regular numpy array\n","xtrainval_byteseq = files.upload() # choose 'X_cleaned_attempt_new.npy' from local system\n","xtrainval_filelike = io.BytesIO(xtrainval_byteseq['X_cleaned_attempt_new.npy']) # create file-like object\n","xtrainval = np.load(xtrainval_filelike,allow_pickle=True) # create regular numpy array\n","ytest_byteseq = files.upload() # choose 'Y_test.npy' from local system\n","ytest_filelike = io.BytesIO(ytest_byteseq['Y_test.npy']) # create file-like object\n","ytest = np.load(ytest_filelike,allow_pickle=True) # create regular numpy array\n","xtest_byteseq = files.upload() # choose 'X_test.npy' from local system\n","xtest_filelike = io.BytesIO(xtest_byteseq['X_test.npy']) # create file-like object\n","xtest = np.load(xtest_filelike,allow_pickle=True) # create regular numpy array\n","\n","#check shapes\n","print(xtrainval.shape)\n","print(ytrainval.shape)\n","print(xtest.shape)\n","print(ytest.shape)\n","\n","#ytrainval needs to be converted to number representation of labels\n","feature_map = {'Rock':0,'Electronic':1,'Experimental':2,'Hip-Hop':3,'Folk':4,'Instrumental':5,'Pop':6,\n","              'International':7,'Classical':8,'Old-Time / Historic':9, 'Jazz':10,'Country':11,'Soul-RnB':12,\n","              'Spoken':13,'Blues':14,'Easy Listening':15}\n","for i in range(ytrainval.shape[0]):\n","    ytrainval[i] = float(feature_map[ytrainval[i]])\n","ytrainval[i] = np.asarray(ytrainval[i]).astype('float32')\n","\n","print(ytrainval)\n","print(ytest)\n","\n","# for the preliminary report, i did a roughly 80-20 split, but used the 20% as the training set to improve speed\n","# so will recombine and do a 90-10 split, using the 90% as training/validation\n","xfull = np.concatenate((xtrainval,xtest),axis=0)\n","yfull = np.concatenate((ytrainval,ytest),axis=0)\n","print(xfull.shape)\n","print(yfull.shape)\n","\n"]},{"cell_type":"code","source":["# this is where the strategy changes. We need to do a different train/test/val split\n","# let's see what the overall distribution between the categories is\n","yfull_1hot = to_categorical(yfull)\n","yfull_sum = np.sum(yfull_1hot, axis=0)\n","print(yfull_sum)\n"],"metadata":{"id":"_oicdI3ksFWc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652027273638,"user_tz":240,"elapsed":163,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"95e81801-57e3-4b7c-9696-c567bc031ad5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[14182.  9372. 10608.  3552.  2803.  2079.  2332.  1389.  1230.   554.\n","   571.   194.   175.   423.   110.    24.]\n"]}]},{"cell_type":"code","source":["# In an extreme case, we might just take 20 of each class in the train set\n","\n","yfull = yfull.reshape(yfull.shape[0],1)\n","both_full = np.concatenate((xfull, yfull), axis=1)\n","print(both_full.shape)\n","both_full = shuffle(both_full)\n","indices = [] \n","num_counter = []\n","for i in range(16):\n","    num_counter.append(0)\n","for i in range(both_full.shape[0]):\n","    if num_counter[int(both_full[i,-1])] < 20:\n","        num_counter[int(both_full[i,-1])] += 1\n","        indices.append(i)\n","print(num_counter)\n","both_train_small = both_full[indices]\n","y_train_small = both_train_small[:,-1]\n","y_train_small_1hot = to_categorical(y_train_small).astype('float32')\n","x_train_small = both_train_small[:,:-1]\n","print(y_train_small_1hot.shape)\n","print(y_train_small.shape)\n","print(x_train_small.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHC8x8U6txYx","executionInfo":{"status":"ok","timestamp":1652027513424,"user_tz":240,"elapsed":1719,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"de7de20c-f60b-460e-fc8f-c4172a2c6a7d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(49598, 521)\n","[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]\n","(320, 16)\n","(320,)\n","(320, 520)\n"]}]},{"cell_type":"code","source":["# need to implement k-fold cross validation\n","'''\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          layers.Dropout(0.3),\n","          layers.Dense(100,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(256,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(128,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(64,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(32,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","# COMPILE NEW MODEL\n","model.compile(loss='categorical_crossentropy',\n","    optimizer=keras.optimizers.Adam(\n","        learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","        metrics=['accuracy'])\n","\n","\n","# see https://medium.com/the-owl/k-fold-cross-validation-in-keras-3ec4a3a00538\n","from sklearn.model_selection import KFold, StratifiedKFold\n","\n","kf = KFold(n_splits = x_trainval_small.shape[0])\n","for train_index, val_index in kf.split(np.zeros(x_trainval_small.shape[0]),y_trainval_small_1hot):\n","\t\n","\t\n","\t\n","\t\n","\t# FIT THE MODEL\n","\thistory = model.fit(x_trainval_small,\n","\t\t\t    epochs=10,,\n","\t\t\t    validation_data=valid_data_generator)\n","\t#PLOT HISTORY\n","\t#\t\t:\n","\t#\t\t:\n","\t\n","\t# LOAD BEST MODEL to evaluate the performance of the model\n","\tmodel.load_weights(\"/saved_models/model_\"+str(fold_var)+\".h5\")\n","\t\n","\tresults = model.evaluate(valid_data_generator)\n","\tresults = dict(zip(model.metrics_names,results))\n","\t\n","\tVALIDATION_ACCURACY.append(results['accuracy'])\n","\tVALIDATION_LOSS.append(results['loss'])\n","\t\n","\ttf.keras.backend.clear_session()\n","\t\n","\tfold_var += 1\n","  '''"],"metadata":{"id":"LgzwCHxWCteI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# let's give the datasets better names to reflect what i'm actually doing (kind of abandoned above plan)\n","import copy \n","x_trainval_small = x_trainval_small.astype('float32')\n","y_trainval_small_1hot = y_trainval_small_1hot.astype('float32')\n","x_train_small = copy.deepcopy(x_trainval_small)\n","y_train_small_1hot = copy.deepcopy(y_trainval_small_1hot)\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          layers.Dropout(0.3),\n","          layers.Dense(100,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          #layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(256,kernel_initializer='lecun_normal'),\n","          #layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(128,kernel_initializer='lecun_normal'),\n","          #layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(64,kernel_initializer='lecun_normal'),\n","          #layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(32,kernel_initializer='lecun_normal'),\n","          #layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_trainval_small, y_trainval_small_1hot, batch_size=32, epochs=100, validation_data=(x_trainval_small, y_trainval_small_1hot))\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gaXkjgTFXWm","executionInfo":{"status":"ok","timestamp":1651888857167,"user_tz":240,"elapsed":21911,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"1b0a3ccd-e0c1-45d7-adef-9580cd4b4ffc"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","10/10 [==============================] - 1s 37ms/step - loss: 2.9122 - accuracy: 0.1406 - val_loss: 21.3840 - val_accuracy: 0.0719\n","Epoch 2/100\n","10/10 [==============================] - 0s 13ms/step - loss: 2.0922 - accuracy: 0.3375 - val_loss: 19.8783 - val_accuracy: 0.0625\n","Epoch 3/100\n","10/10 [==============================] - 0s 13ms/step - loss: 1.7584 - accuracy: 0.4719 - val_loss: 22.5311 - val_accuracy: 0.0625\n","Epoch 4/100\n","10/10 [==============================] - 0s 9ms/step - loss: 1.4792 - accuracy: 0.5562 - val_loss: 22.1548 - val_accuracy: 0.0625\n","Epoch 5/100\n","10/10 [==============================] - 0s 14ms/step - loss: 1.2724 - accuracy: 0.6094 - val_loss: 23.0078 - val_accuracy: 0.0625\n","Epoch 6/100\n","10/10 [==============================] - 0s 10ms/step - loss: 1.1068 - accuracy: 0.6875 - val_loss: 19.2610 - val_accuracy: 0.0625\n","Epoch 7/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.9062 - accuracy: 0.7437 - val_loss: 18.2128 - val_accuracy: 0.0625\n","Epoch 8/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.8289 - accuracy: 0.7563 - val_loss: 17.4694 - val_accuracy: 0.0656\n","Epoch 9/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.7366 - accuracy: 0.7937 - val_loss: 18.0765 - val_accuracy: 0.0656\n","Epoch 10/100\n","10/10 [==============================] - 0s 15ms/step - loss: 0.6537 - accuracy: 0.8000 - val_loss: 18.7777 - val_accuracy: 0.0656\n","Epoch 11/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.6248 - accuracy: 0.8219 - val_loss: 17.3474 - val_accuracy: 0.0625\n","Epoch 12/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.6057 - accuracy: 0.8062 - val_loss: 17.1283 - val_accuracy: 0.0625\n","Epoch 13/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.5131 - accuracy: 0.8562 - val_loss: 17.5887 - val_accuracy: 0.0625\n","Epoch 14/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.4775 - accuracy: 0.8781 - val_loss: 16.9201 - val_accuracy: 0.0625\n","Epoch 15/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.4787 - accuracy: 0.8594 - val_loss: 16.3216 - val_accuracy: 0.0625\n","Epoch 16/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.4158 - accuracy: 0.8781 - val_loss: 17.5319 - val_accuracy: 0.0625\n","Epoch 17/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.3669 - accuracy: 0.9062 - val_loss: 18.4632 - val_accuracy: 0.0625\n","Epoch 18/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.3213 - accuracy: 0.9125 - val_loss: 17.5572 - val_accuracy: 0.1094\n","Epoch 19/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.3715 - accuracy: 0.9000 - val_loss: 15.6237 - val_accuracy: 0.1000\n","Epoch 20/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.3312 - accuracy: 0.8938 - val_loss: 15.1470 - val_accuracy: 0.1187\n","Epoch 21/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.9094 - val_loss: 14.6911 - val_accuracy: 0.1063\n","Epoch 22/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.2702 - accuracy: 0.9219 - val_loss: 13.6780 - val_accuracy: 0.1156\n","Epoch 23/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.2393 - accuracy: 0.9281 - val_loss: 13.7503 - val_accuracy: 0.0969\n","Epoch 24/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.2887 - accuracy: 0.9094 - val_loss: 11.7448 - val_accuracy: 0.1219\n","Epoch 25/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.2096 - accuracy: 0.9406 - val_loss: 11.3765 - val_accuracy: 0.1219\n","Epoch 26/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.2349 - accuracy: 0.9406 - val_loss: 11.1776 - val_accuracy: 0.1187\n","Epoch 27/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.2268 - accuracy: 0.9156 - val_loss: 9.8222 - val_accuracy: 0.1281\n","Epoch 28/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.2068 - accuracy: 0.9344 - val_loss: 8.5403 - val_accuracy: 0.1281\n","Epoch 29/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.2352 - accuracy: 0.9094 - val_loss: 7.8791 - val_accuracy: 0.1406\n","Epoch 30/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1887 - accuracy: 0.9563 - val_loss: 7.7889 - val_accuracy: 0.1469\n","Epoch 31/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1587 - accuracy: 0.9563 - val_loss: 7.2575 - val_accuracy: 0.1688\n","Epoch 32/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.1733 - accuracy: 0.9563 - val_loss: 6.7141 - val_accuracy: 0.1813\n","Epoch 33/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1615 - accuracy: 0.9563 - val_loss: 6.2245 - val_accuracy: 0.1875\n","Epoch 34/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.2090 - accuracy: 0.9312 - val_loss: 6.2939 - val_accuracy: 0.2000\n","Epoch 35/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.1963 - accuracy: 0.9438 - val_loss: 6.0580 - val_accuracy: 0.1813\n","Epoch 36/100\n","10/10 [==============================] - 0s 11ms/step - loss: 0.1589 - accuracy: 0.9563 - val_loss: 5.8663 - val_accuracy: 0.1969\n","Epoch 37/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.1988 - accuracy: 0.9281 - val_loss: 4.7822 - val_accuracy: 0.2688\n","Epoch 38/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.1529 - accuracy: 0.9531 - val_loss: 4.0128 - val_accuracy: 0.2937\n","Epoch 39/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.1396 - accuracy: 0.9625 - val_loss: 3.0340 - val_accuracy: 0.4031\n","Epoch 40/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.1331 - accuracy: 0.9594 - val_loss: 2.4853 - val_accuracy: 0.4812\n","Epoch 41/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.1318 - accuracy: 0.9688 - val_loss: 1.7412 - val_accuracy: 0.5719\n","Epoch 42/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.1458 - accuracy: 0.9594 - val_loss: 1.0542 - val_accuracy: 0.7000\n","Epoch 43/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1328 - accuracy: 0.9625 - val_loss: 0.6974 - val_accuracy: 0.7188\n","Epoch 44/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.1074 - accuracy: 0.9656 - val_loss: 0.8879 - val_accuracy: 0.7219\n","Epoch 45/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.1768 - accuracy: 0.9406 - val_loss: 0.6255 - val_accuracy: 0.7875\n","Epoch 46/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.2000 - accuracy: 0.9281 - val_loss: 0.1511 - val_accuracy: 0.9563\n","Epoch 47/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.1901 - accuracy: 0.9469 - val_loss: 0.1106 - val_accuracy: 0.9656\n","Epoch 48/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.1268 - accuracy: 0.9625 - val_loss: 0.1973 - val_accuracy: 0.9312\n","Epoch 49/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.1860 - accuracy: 0.9375 - val_loss: 0.1127 - val_accuracy: 0.9594\n","Epoch 50/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1123 - accuracy: 0.9688 - val_loss: 0.0596 - val_accuracy: 0.9781\n","Epoch 51/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.1054 - accuracy: 0.9688 - val_loss: 0.0453 - val_accuracy: 0.9812\n","Epoch 52/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.1175 - accuracy: 0.9500 - val_loss: 0.0400 - val_accuracy: 0.9937\n","Epoch 53/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.1469 - accuracy: 0.9438 - val_loss: 0.0170 - val_accuracy: 1.0000\n","Epoch 54/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1090 - accuracy: 0.9625 - val_loss: 0.0152 - val_accuracy: 0.9969\n","Epoch 55/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.0999 - accuracy: 0.9719 - val_loss: 0.0062 - val_accuracy: 1.0000\n","Epoch 56/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1629 - accuracy: 0.9531 - val_loss: 0.0085 - val_accuracy: 1.0000\n","Epoch 57/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1229 - accuracy: 0.9531 - val_loss: 0.0116 - val_accuracy: 1.0000\n","Epoch 58/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.1079 - accuracy: 0.9688 - val_loss: 0.0070 - val_accuracy: 1.0000\n","Epoch 59/100\n","10/10 [==============================] - 0s 15ms/step - loss: 0.1400 - accuracy: 0.9594 - val_loss: 0.0057 - val_accuracy: 1.0000\n","Epoch 60/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.0797 - accuracy: 0.9688 - val_loss: 0.0115 - val_accuracy: 0.9969\n","Epoch 61/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.1448 - accuracy: 0.9656 - val_loss: 0.0039 - val_accuracy: 1.0000\n","Epoch 62/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.0794 - accuracy: 0.9781 - val_loss: 0.0023 - val_accuracy: 1.0000\n","Epoch 63/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1227 - accuracy: 0.9688 - val_loss: 0.0030 - val_accuracy: 1.0000\n","Epoch 64/100\n","10/10 [==============================] - 0s 15ms/step - loss: 0.1430 - accuracy: 0.9563 - val_loss: 0.0042 - val_accuracy: 1.0000\n","Epoch 65/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.1013 - accuracy: 0.9656 - val_loss: 0.0047 - val_accuracy: 1.0000\n","Epoch 66/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.0826 - accuracy: 0.9688 - val_loss: 0.0031 - val_accuracy: 1.0000\n","Epoch 67/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.1001 - accuracy: 0.9656 - val_loss: 0.0031 - val_accuracy: 1.0000\n","Epoch 68/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1123 - accuracy: 0.9531 - val_loss: 0.0022 - val_accuracy: 1.0000\n","Epoch 69/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.0776 - accuracy: 0.9750 - val_loss: 0.0023 - val_accuracy: 1.0000\n","Epoch 70/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.0831 - accuracy: 0.9719 - val_loss: 0.0044 - val_accuracy: 1.0000\n","Epoch 71/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.0847 - accuracy: 0.9719 - val_loss: 0.0110 - val_accuracy: 0.9937\n","Epoch 72/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1724 - accuracy: 0.9406 - val_loss: 0.0056 - val_accuracy: 1.0000\n","Epoch 73/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.1145 - accuracy: 0.9656 - val_loss: 0.0050 - val_accuracy: 1.0000\n","Epoch 74/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.1217 - accuracy: 0.9594 - val_loss: 0.0042 - val_accuracy: 1.0000\n","Epoch 75/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.1420 - accuracy: 0.9531 - val_loss: 0.0028 - val_accuracy: 1.0000\n","Epoch 76/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.0946 - accuracy: 0.9656 - val_loss: 0.0027 - val_accuracy: 1.0000\n","Epoch 77/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.0784 - accuracy: 0.9719 - val_loss: 0.0020 - val_accuracy: 1.0000\n","Epoch 78/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.0755 - accuracy: 0.9812 - val_loss: 0.0030 - val_accuracy: 1.0000\n","Epoch 79/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.0882 - accuracy: 0.9781 - val_loss: 0.0023 - val_accuracy: 1.0000\n","Epoch 80/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.0978 - accuracy: 0.9625 - val_loss: 0.0027 - val_accuracy: 1.0000\n","Epoch 81/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.0752 - accuracy: 0.9719 - val_loss: 0.0046 - val_accuracy: 1.0000\n","Epoch 82/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.0873 - accuracy: 0.9719 - val_loss: 0.0056 - val_accuracy: 1.0000\n","Epoch 83/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1084 - accuracy: 0.9594 - val_loss: 0.0018 - val_accuracy: 1.0000\n","Epoch 84/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.1571 - accuracy: 0.9531 - val_loss: 0.0024 - val_accuracy: 1.0000\n","Epoch 85/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.1208 - accuracy: 0.9625 - val_loss: 0.0035 - val_accuracy: 1.0000\n","Epoch 86/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.1100 - accuracy: 0.9594 - val_loss: 0.0033 - val_accuracy: 1.0000\n","Epoch 87/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.0973 - accuracy: 0.9656 - val_loss: 0.0039 - val_accuracy: 1.0000\n","Epoch 88/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.1427 - accuracy: 0.9594 - val_loss: 0.0046 - val_accuracy: 0.9969\n","Epoch 89/100\n","10/10 [==============================] - 0s 11ms/step - loss: 0.0387 - accuracy: 0.9906 - val_loss: 0.0016 - val_accuracy: 1.0000\n","Epoch 90/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.0872 - accuracy: 0.9594 - val_loss: 0.0016 - val_accuracy: 1.0000\n","Epoch 91/100\n","10/10 [==============================] - 0s 13ms/step - loss: 0.0664 - accuracy: 0.9750 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 92/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.0727 - accuracy: 0.9750 - val_loss: 9.0346e-04 - val_accuracy: 1.0000\n","Epoch 93/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.0787 - accuracy: 0.9750 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 94/100\n","10/10 [==============================] - 0s 11ms/step - loss: 0.0820 - accuracy: 0.9688 - val_loss: 0.0016 - val_accuracy: 1.0000\n","Epoch 95/100\n","10/10 [==============================] - 0s 9ms/step - loss: 0.1349 - accuracy: 0.9531 - val_loss: 0.0013 - val_accuracy: 1.0000\n","Epoch 96/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.0583 - accuracy: 0.9812 - val_loss: 0.0017 - val_accuracy: 1.0000\n","Epoch 97/100\n","10/10 [==============================] - 0s 10ms/step - loss: 0.0480 - accuracy: 0.9875 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 98/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.1089 - accuracy: 0.9656 - val_loss: 8.8039e-04 - val_accuracy: 1.0000\n","Epoch 99/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.0598 - accuracy: 0.9781 - val_loss: 0.0050 - val_accuracy: 0.9969\n","Epoch 100/100\n","10/10 [==============================] - 0s 14ms/step - loss: 0.0776 - accuracy: 0.9750 - val_loss: 0.0012 - val_accuracy: 1.0000\n"]}]},{"cell_type":"code","source":["'''\n","y_test = np.array([both_full[i,-1] for i in range(2000) if i not in indices])\n","x_test = np.array([both_full[i,:-1] for i in range(2000) if i not in indices])\n","y_test_1hot = to_categorical(y_test)\n","ytrain_sum = np.sum(y_train_small_1hot, axis=0)\n","print(y_test_1hot.shape)\n","print(x_test.shape)\n","ytest_sum = np.sum(y_test_1hot, axis=0)\n","print(ytest_sum)\n","print(yfull_sum)\n","print(ytrain_sum)\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ef8yLrEQP8fH","executionInfo":{"status":"ok","timestamp":1651890334399,"user_tz":240,"elapsed":147,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"d6a79661-c2be-4be0-85f6-17e10e0e162b"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["(1747, 11)\n","(1747, 520)\n","[553. 382. 386. 119.  85.  67.  79.  24.  34.  12.   6.]\n","[14182.  9372. 10608.  3552.  2803.  2079.  2332.  1389.  1230.   554.\n","   571.   194.   175.   423.   110.    24.]\n","[20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20.]\n"]}]},{"cell_type":"code","source":["val_numbers = [(i-20)//2 for i in yfull_sum] # number of each instance to put in val set \n","val_indices = []\n","num_counter = []\n","for i in range(16):\n","    num_counter.append(0)\n","for i in range(both_full.shape[0]):\n","    if i not in indices: # don't count if already in training set\n","        if num_counter[int(both_full[i,-1])] < val_numbers[int(both_full[i,-1])]:\n","            num_counter[int(both_full[i,-1])] += 1\n","            val_indices.append(i)\n","\n","#indices and val_indices should be different lists\n","for i in indices:\n","  for j in val_indices:\n","    assert i!=j\n","\n","both_val_small = both_full[val_indices,:]\n","y_val_small = both_val_small[:,-1]\n","y_val_small_1hot = to_categorical(y_val_small).astype('float32')\n","x_val_small = both_val_small[:,:-1]\n","print(y_val_small_1hot.shape)\n","print(y_val_small.shape)\n","print(x_val_small.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Twm9NLSuVwjn","executionInfo":{"status":"ok","timestamp":1652029665224,"user_tz":240,"elapsed":1389,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"e0547403-ae06-495e-accc-93d16d27a28e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["(24636, 16)\n","(24636,)\n","(24636, 520)\n"]}]},{"cell_type":"code","source":["print(num_counter)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n2siKJSRmpf2","executionInfo":{"status":"ok","timestamp":1652029399076,"user_tz":240,"elapsed":121,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"4146a2a9-0ef9-49a6-c785-2d1f3ec14562"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[7081, 4676, 5294, 1766, 1391, 1029, 1156, 684, 605, 267, 275, 87, 77, 201, 45, 2]\n"]}]},{"cell_type":"code","source":["# now we need to put everything else in the test set\n","test_indices = []\n","for i in range(both_full.shape[0]):\n","    if i not in indices: # don't count if already in training set\n","        if i not in val_indices: # don't count if already in validation set\n","            test_indices.append(i)\n","both_test_small = both_full[test_indices,:]\n","y_test_small = both_test_small[:,-1]\n","y_test_small_1hot = to_categorical(y_test_small).astype('float32')\n","x_test_small = both_test_small[:,:-1]\n","print(y_test_small_1hot.shape)\n","print(y_test_small.shape)\n","print(x_test_small.shape)\n","assert y_test_small.shape[0] + y_val_small.shape[0] + y_train_small.shape[0] == both_full.shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBg14zOwoUoC","executionInfo":{"status":"ok","timestamp":1652029788637,"user_tz":240,"elapsed":14829,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"1e976fa2-6eb4-4d0d-810b-5e3b0ed6e1f0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["(24642, 16)\n","(24642,)\n","(24642, 520)\n"]}]},{"cell_type":"code","source":["from copy import deepcopy\n","#y_train_small_1hot_copy = deepcopy(y_train_small_1hot) float32 copy\n","#y_val_small_1hot_copy = deepcopy(y_val_small_1hot) float32 copy\n","#y_test_small_1hot_copy = deepcopy(y_test_small_1hot) float32 copy\n","x_train_small_copy = deepcopy(x_train_small) # float copy\n","x_val_small_copy = deepcopy(x_val_small) # float copy\n","x_test_small_copy = deepcopy(x_test_small) # float copy\n","\n","x_train_small = x_train_small.astype('float32')\n","x_val_small = x_val_small.astype('float32')\n","x_test_small = x_test_small.astype('float32')\n","\n","y_train_small_1hot = y_train_small_1hot.astype('int')\n","y_val_small_1hot = y_val_small_1hot.astype('int')\n","y_test_small_1hot = y_test_small_1hot.astype('int')"],"metadata":{"id":"AF_XD93Qp_Lm","executionInfo":{"status":"ok","timestamp":1652030309615,"user_tz":240,"elapsed":15190,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# now let's train!\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          layers.Dropout(0.3),\n","          layers.Dense(100,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          #layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(256,kernel_initializer='lecun_normal'),\n","          #layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(128,kernel_initializer='lecun_normal'),\n","          #layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(64,kernel_initializer='lecun_normal'),\n","          #layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(32,kernel_initializer='lecun_normal'),\n","          #layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=10, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tboShY1tpklT","executionInfo":{"status":"ok","timestamp":1652030361491,"user_tz":240,"elapsed":42607,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"6c6f62f5-5cd6-4fc6-b142-f88baf77b8b0"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","10/10 [==============================] - 7s 327ms/step - loss: 2.9433 - accuracy: 0.1219 - val_loss: 8.8840 - val_accuracy: 0.2874\n","Epoch 2/10\n","10/10 [==============================] - 2s 255ms/step - loss: 2.0680 - accuracy: 0.3594 - val_loss: 5.7575 - val_accuracy: 0.2864\n","Epoch 3/10\n","10/10 [==============================] - 2s 252ms/step - loss: 1.7594 - accuracy: 0.4688 - val_loss: 5.6007 - val_accuracy: 0.2854\n","Epoch 4/10\n","10/10 [==============================] - 3s 290ms/step - loss: 1.4062 - accuracy: 0.5813 - val_loss: 4.7052 - val_accuracy: 0.2302\n","Epoch 5/10\n","10/10 [==============================] - 3s 289ms/step - loss: 1.2172 - accuracy: 0.6687 - val_loss: 5.0362 - val_accuracy: 0.0718\n","Epoch 6/10\n","10/10 [==============================] - 2s 255ms/step - loss: 1.0926 - accuracy: 0.7031 - val_loss: 4.4742 - val_accuracy: 0.0756\n","Epoch 7/10\n","10/10 [==============================] - 2s 251ms/step - loss: 0.9115 - accuracy: 0.7500 - val_loss: 4.7534 - val_accuracy: 0.0802\n","Epoch 8/10\n","10/10 [==============================] - 2s 252ms/step - loss: 0.7963 - accuracy: 0.7969 - val_loss: 4.6833 - val_accuracy: 0.0968\n","Epoch 9/10\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6411 - accuracy: 0.8344 - val_loss: 4.8103 - val_accuracy: 0.2099\n","Epoch 10/10\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5540 - accuracy: 0.8531 - val_loss: 5.6899 - val_accuracy: 0.2149\n"]}]},{"cell_type":"code","source":["# clearly we need some strong regularization with this small training set\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          #layers.Dropout(0.4),\n","          layers.Dense(10,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(64,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(32,kernel_initializer='lecun_normal'),\n","          #layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=10, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R3Rmw8A_r91v","executionInfo":{"status":"ok","timestamp":1652030535638,"user_tz":240,"elapsed":26619,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"76aaef20-f995-4e49-be75-82ac4f3989a2"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","10/10 [==============================] - 5s 377ms/step - loss: 3.1246 - accuracy: 0.0719 - val_loss: 55.7526 - val_accuracy: 0.0418\n","Epoch 2/10\n","10/10 [==============================] - 2s 254ms/step - loss: 2.5676 - accuracy: 0.1844 - val_loss: 44.5348 - val_accuracy: 0.0418\n","Epoch 3/10\n","10/10 [==============================] - 2s 257ms/step - loss: 2.3043 - accuracy: 0.2656 - val_loss: 36.5491 - val_accuracy: 0.0418\n","Epoch 4/10\n","10/10 [==============================] - 2s 253ms/step - loss: 2.1448 - accuracy: 0.3688 - val_loss: 30.9776 - val_accuracy: 0.0418\n","Epoch 5/10\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0008 - accuracy: 0.4062 - val_loss: 27.8499 - val_accuracy: 0.0417\n","Epoch 6/10\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8829 - accuracy: 0.4563 - val_loss: 24.6718 - val_accuracy: 0.0416\n","Epoch 7/10\n","10/10 [==============================] - 2s 251ms/step - loss: 1.7615 - accuracy: 0.5031 - val_loss: 21.2001 - val_accuracy: 0.0417\n","Epoch 8/10\n","10/10 [==============================] - 2s 252ms/step - loss: 1.6197 - accuracy: 0.5437 - val_loss: 18.3861 - val_accuracy: 0.0417\n","Epoch 9/10\n","10/10 [==============================] - 3s 289ms/step - loss: 1.5452 - accuracy: 0.5344 - val_loss: 16.4767 - val_accuracy: 0.0417\n","Epoch 10/10\n","10/10 [==============================] - 2s 246ms/step - loss: 1.3721 - accuracy: 0.6156 - val_loss: 15.9595 - val_accuracy: 0.0415\n"]}]},{"cell_type":"code","source":["# clearly we need some strong regularization with this small training set\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          #layers.Dropout(0.4),\n","          layers.Dense(10,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(32,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=200, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzxusPl7sekI","executionInfo":{"status":"ok","timestamp":1652031161188,"user_tz":240,"elapsed":503302,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"7707e516-b6dc-4150-ad9a-922d9ed64720"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","10/10 [==============================] - 4s 290ms/step - loss: 3.2721 - accuracy: 0.0437 - val_loss: 77.1198 - val_accuracy: 0.2148\n","Epoch 2/200\n","10/10 [==============================] - 3s 290ms/step - loss: 2.7602 - accuracy: 0.1594 - val_loss: 66.4227 - val_accuracy: 0.2148\n","Epoch 3/200\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5156 - accuracy: 0.1906 - val_loss: 55.4600 - val_accuracy: 0.2148\n","Epoch 4/200\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3017 - accuracy: 0.2812 - val_loss: 47.9169 - val_accuracy: 0.2148\n","Epoch 5/200\n","10/10 [==============================] - 2s 251ms/step - loss: 2.1912 - accuracy: 0.3125 - val_loss: 41.2534 - val_accuracy: 0.2148\n","Epoch 6/200\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0745 - accuracy: 0.3844 - val_loss: 36.3066 - val_accuracy: 0.2148\n","Epoch 7/200\n","10/10 [==============================] - 2s 251ms/step - loss: 1.9819 - accuracy: 0.4125 - val_loss: 32.1264 - val_accuracy: 0.2147\n","Epoch 8/200\n","10/10 [==============================] - 2s 254ms/step - loss: 1.9052 - accuracy: 0.4344 - val_loss: 28.8704 - val_accuracy: 0.2147\n","Epoch 9/200\n","10/10 [==============================] - 2s 249ms/step - loss: 1.7809 - accuracy: 0.5188 - val_loss: 26.4362 - val_accuracy: 0.2146\n","Epoch 10/200\n","10/10 [==============================] - 3s 290ms/step - loss: 1.7166 - accuracy: 0.5437 - val_loss: 24.4373 - val_accuracy: 0.2146\n","Epoch 11/200\n","10/10 [==============================] - 2s 247ms/step - loss: 1.6138 - accuracy: 0.5594 - val_loss: 22.4483 - val_accuracy: 0.2146\n","Epoch 12/200\n","10/10 [==============================] - 2s 243ms/step - loss: 1.5592 - accuracy: 0.5938 - val_loss: 20.6777 - val_accuracy: 0.2146\n","Epoch 13/200\n","10/10 [==============================] - 2s 242ms/step - loss: 1.4701 - accuracy: 0.6250 - val_loss: 19.0365 - val_accuracy: 0.2145\n","Epoch 14/200\n","10/10 [==============================] - 2s 247ms/step - loss: 1.4123 - accuracy: 0.6656 - val_loss: 17.8300 - val_accuracy: 0.2144\n","Epoch 15/200\n","10/10 [==============================] - 2s 245ms/step - loss: 1.3109 - accuracy: 0.7063 - val_loss: 16.6903 - val_accuracy: 0.2141\n","Epoch 16/200\n","10/10 [==============================] - 3s 290ms/step - loss: 1.2459 - accuracy: 0.7125 - val_loss: 15.6130 - val_accuracy: 0.2140\n","Epoch 17/200\n","10/10 [==============================] - 3s 290ms/step - loss: 1.1760 - accuracy: 0.7437 - val_loss: 14.6602 - val_accuracy: 0.2136\n","Epoch 18/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.0962 - accuracy: 0.7719 - val_loss: 13.8650 - val_accuracy: 0.2127\n","Epoch 19/200\n","10/10 [==============================] - 3s 290ms/step - loss: 1.0347 - accuracy: 0.8031 - val_loss: 13.2067 - val_accuracy: 0.2120\n","Epoch 20/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.9636 - accuracy: 0.8062 - val_loss: 12.3550 - val_accuracy: 0.2112\n","Epoch 21/200\n","10/10 [==============================] - 2s 251ms/step - loss: 0.9034 - accuracy: 0.8344 - val_loss: 11.4973 - val_accuracy: 0.2109\n","Epoch 22/200\n","10/10 [==============================] - 2s 245ms/step - loss: 0.8338 - accuracy: 0.8687 - val_loss: 10.8468 - val_accuracy: 0.2084\n","Epoch 23/200\n","10/10 [==============================] - 2s 247ms/step - loss: 0.7844 - accuracy: 0.8687 - val_loss: 10.2025 - val_accuracy: 0.2045\n","Epoch 24/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.7473 - accuracy: 0.8813 - val_loss: 9.6423 - val_accuracy: 0.1993\n","Epoch 25/200\n","10/10 [==============================] - 2s 252ms/step - loss: 0.6724 - accuracy: 0.9219 - val_loss: 9.1669 - val_accuracy: 0.1997\n","Epoch 26/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6220 - accuracy: 0.9125 - val_loss: 8.6470 - val_accuracy: 0.1905\n","Epoch 27/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5627 - accuracy: 0.9438 - val_loss: 8.1807 - val_accuracy: 0.1718\n","Epoch 28/200\n","10/10 [==============================] - 3s 291ms/step - loss: 0.5440 - accuracy: 0.9469 - val_loss: 7.8136 - val_accuracy: 0.1545\n","Epoch 29/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4896 - accuracy: 0.9500 - val_loss: 7.5135 - val_accuracy: 0.1265\n","Epoch 30/200\n","10/10 [==============================] - 2s 254ms/step - loss: 0.4590 - accuracy: 0.9625 - val_loss: 7.2323 - val_accuracy: 0.1051\n","Epoch 31/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4302 - accuracy: 0.9563 - val_loss: 7.0551 - val_accuracy: 0.0934\n","Epoch 32/200\n","10/10 [==============================] - 2s 250ms/step - loss: 0.4049 - accuracy: 0.9500 - val_loss: 7.0322 - val_accuracy: 0.0771\n","Epoch 33/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3744 - accuracy: 0.9625 - val_loss: 6.9055 - val_accuracy: 0.0697\n","Epoch 34/200\n","10/10 [==============================] - 2s 250ms/step - loss: 0.3393 - accuracy: 0.9750 - val_loss: 6.7614 - val_accuracy: 0.0702\n","Epoch 35/200\n","10/10 [==============================] - 2s 246ms/step - loss: 0.3094 - accuracy: 0.9719 - val_loss: 6.5962 - val_accuracy: 0.0700\n","Epoch 36/200\n","10/10 [==============================] - 2s 249ms/step - loss: 0.3339 - accuracy: 0.9719 - val_loss: 6.2388 - val_accuracy: 0.0793\n","Epoch 37/200\n","10/10 [==============================] - 2s 248ms/step - loss: 0.2962 - accuracy: 0.9719 - val_loss: 6.0574 - val_accuracy: 0.0825\n","Epoch 38/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.2894 - accuracy: 0.9719 - val_loss: 5.7714 - val_accuracy: 0.0858\n","Epoch 39/200\n","10/10 [==============================] - 2s 254ms/step - loss: 0.2283 - accuracy: 0.9937 - val_loss: 5.4306 - val_accuracy: 0.0887\n","Epoch 40/200\n","10/10 [==============================] - 2s 252ms/step - loss: 0.2555 - accuracy: 0.9812 - val_loss: 5.1794 - val_accuracy: 0.0925\n","Epoch 41/200\n","10/10 [==============================] - 2s 245ms/step - loss: 0.2503 - accuracy: 0.9844 - val_loss: 5.0096 - val_accuracy: 0.0975\n","Epoch 42/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.2281 - accuracy: 0.9812 - val_loss: 4.8725 - val_accuracy: 0.1014\n","Epoch 43/200\n","10/10 [==============================] - 2s 246ms/step - loss: 0.1930 - accuracy: 0.9969 - val_loss: 4.6864 - val_accuracy: 0.1086\n","Epoch 44/200\n","10/10 [==============================] - 2s 249ms/step - loss: 0.2084 - accuracy: 0.9844 - val_loss: 4.6041 - val_accuracy: 0.1117\n","Epoch 45/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.2041 - accuracy: 0.9844 - val_loss: 4.5195 - val_accuracy: 0.1131\n","Epoch 46/200\n","10/10 [==============================] - 2s 247ms/step - loss: 0.1980 - accuracy: 0.9812 - val_loss: 4.4002 - val_accuracy: 0.1217\n","Epoch 47/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.1623 - accuracy: 0.9937 - val_loss: 4.2597 - val_accuracy: 0.1296\n","Epoch 48/200\n","10/10 [==============================] - 2s 248ms/step - loss: 0.1531 - accuracy: 0.9937 - val_loss: 4.0751 - val_accuracy: 0.1468\n","Epoch 49/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.1397 - accuracy: 1.0000 - val_loss: 4.1389 - val_accuracy: 0.1423\n","Epoch 50/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.1328 - accuracy: 0.9937 - val_loss: 4.0436 - val_accuracy: 0.1577\n","Epoch 51/200\n","10/10 [==============================] - 2s 247ms/step - loss: 0.1485 - accuracy: 0.9875 - val_loss: 4.0123 - val_accuracy: 0.1632\n","Epoch 52/200\n","10/10 [==============================] - 2s 250ms/step - loss: 0.1310 - accuracy: 0.9937 - val_loss: 4.0890 - val_accuracy: 0.1598\n","Epoch 53/200\n","10/10 [==============================] - 2s 248ms/step - loss: 0.1327 - accuracy: 0.9969 - val_loss: 3.9570 - val_accuracy: 0.1761\n","Epoch 54/200\n","10/10 [==============================] - 2s 246ms/step - loss: 0.1369 - accuracy: 0.9969 - val_loss: 4.0247 - val_accuracy: 0.1691\n","Epoch 55/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.1113 - accuracy: 0.9969 - val_loss: 4.0619 - val_accuracy: 0.1686\n","Epoch 56/200\n","10/10 [==============================] - 2s 249ms/step - loss: 0.1070 - accuracy: 0.9969 - val_loss: 3.9918 - val_accuracy: 0.1832\n","Epoch 57/200\n","10/10 [==============================] - 2s 245ms/step - loss: 0.0993 - accuracy: 0.9969 - val_loss: 3.9161 - val_accuracy: 0.1931\n","Epoch 58/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.1187 - accuracy: 0.9969 - val_loss: 4.0175 - val_accuracy: 0.1805\n","Epoch 59/200\n","10/10 [==============================] - 2s 250ms/step - loss: 0.1020 - accuracy: 0.9969 - val_loss: 3.9557 - val_accuracy: 0.1936\n","Epoch 60/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 4.0126 - val_accuracy: 0.1897\n","Epoch 61/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 4.0592 - val_accuracy: 0.1868\n","Epoch 62/200\n","10/10 [==============================] - 2s 244ms/step - loss: 0.0782 - accuracy: 0.9969 - val_loss: 4.1132 - val_accuracy: 0.1849\n","Epoch 63/200\n","10/10 [==============================] - 2s 245ms/step - loss: 0.0840 - accuracy: 0.9969 - val_loss: 4.0892 - val_accuracy: 0.1915\n","Epoch 64/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0807 - accuracy: 0.9969 - val_loss: 4.0231 - val_accuracy: 0.2030\n","Epoch 65/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0902 - accuracy: 0.9969 - val_loss: 4.1885 - val_accuracy: 0.1869\n","Epoch 66/200\n","10/10 [==============================] - 2s 246ms/step - loss: 0.0807 - accuracy: 0.9969 - val_loss: 4.2736 - val_accuracy: 0.1833\n","Epoch 67/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0949 - accuracy: 1.0000 - val_loss: 4.1690 - val_accuracy: 0.1982\n","Epoch 68/200\n","10/10 [==============================] - 2s 253ms/step - loss: 0.0843 - accuracy: 0.9969 - val_loss: 4.1588 - val_accuracy: 0.2025\n","Epoch 69/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0808 - accuracy: 0.9969 - val_loss: 4.2875 - val_accuracy: 0.1888\n","Epoch 70/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 4.3108 - val_accuracy: 0.1885\n","Epoch 71/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0597 - accuracy: 0.9969 - val_loss: 4.3115 - val_accuracy: 0.1907\n","Epoch 72/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 4.4276 - val_accuracy: 0.1815\n","Epoch 73/200\n","10/10 [==============================] - 2s 253ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 4.4055 - val_accuracy: 0.1877\n","Epoch 74/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 4.4990 - val_accuracy: 0.1790\n","Epoch 75/200\n","10/10 [==============================] - 2s 256ms/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 4.5269 - val_accuracy: 0.1780\n","Epoch 76/200\n","10/10 [==============================] - 2s 245ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 4.4640 - val_accuracy: 0.1877\n","Epoch 77/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 4.4842 - val_accuracy: 0.1873\n","Epoch 78/200\n","10/10 [==============================] - 2s 247ms/step - loss: 0.0517 - accuracy: 0.9937 - val_loss: 4.5512 - val_accuracy: 0.1823\n","Epoch 79/200\n","10/10 [==============================] - 2s 247ms/step - loss: 0.0771 - accuracy: 0.9906 - val_loss: 4.5717 - val_accuracy: 0.1827\n","Epoch 80/200\n","10/10 [==============================] - 2s 254ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 4.5241 - val_accuracy: 0.1916\n","Epoch 81/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0537 - accuracy: 0.9969 - val_loss: 4.6401 - val_accuracy: 0.1815\n","Epoch 82/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0606 - accuracy: 0.9969 - val_loss: 4.7456 - val_accuracy: 0.1734\n","Epoch 83/200\n","10/10 [==============================] - 2s 254ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 4.6394 - val_accuracy: 0.1864\n","Epoch 84/200\n","10/10 [==============================] - 2s 250ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 4.5038 - val_accuracy: 0.2064\n","Epoch 85/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 4.4980 - val_accuracy: 0.2097\n","Epoch 86/200\n","10/10 [==============================] - 3s 293ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 4.6943 - val_accuracy: 0.1880\n","Epoch 87/200\n","10/10 [==============================] - 2s 247ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 4.7515 - val_accuracy: 0.1812\n","Epoch 88/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.0485 - accuracy: 0.9969 - val_loss: 4.6551 - val_accuracy: 0.1938\n","Epoch 89/200\n","10/10 [==============================] - 2s 251ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 4.6047 - val_accuracy: 0.2036\n","Epoch 90/200\n","10/10 [==============================] - 2s 248ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 4.6736 - val_accuracy: 0.1963\n","Epoch 91/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 4.7473 - val_accuracy: 0.1874\n","Epoch 92/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 4.7647 - val_accuracy: 0.1896\n","Epoch 93/200\n","10/10 [==============================] - 2s 250ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 4.7256 - val_accuracy: 0.1985\n","Epoch 94/200\n","10/10 [==============================] - 3s 293ms/step - loss: 0.0469 - accuracy: 0.9969 - val_loss: 4.8381 - val_accuracy: 0.1840\n","Epoch 95/200\n","10/10 [==============================] - 3s 302ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 4.8445 - val_accuracy: 0.1837\n","Epoch 96/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 4.8716 - val_accuracy: 0.1879\n","Epoch 97/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 4.8792 - val_accuracy: 0.1869\n","Epoch 98/200\n","10/10 [==============================] - 2s 248ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 4.8694 - val_accuracy: 0.1881\n","Epoch 99/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 4.8474 - val_accuracy: 0.1915\n","Epoch 100/200\n","10/10 [==============================] - 3s 291ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 4.9354 - val_accuracy: 0.1813\n","Epoch 101/200\n","10/10 [==============================] - 2s 258ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 4.8967 - val_accuracy: 0.1877\n","Epoch 102/200\n","10/10 [==============================] - 2s 251ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 4.9371 - val_accuracy: 0.1860\n","Epoch 103/200\n","10/10 [==============================] - 2s 250ms/step - loss: 0.0337 - accuracy: 0.9969 - val_loss: 4.9995 - val_accuracy: 0.1808\n","Epoch 104/200\n","10/10 [==============================] - 2s 250ms/step - loss: 0.0284 - accuracy: 0.9969 - val_loss: 4.9657 - val_accuracy: 0.1865\n","Epoch 105/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 4.9670 - val_accuracy: 0.1871\n","Epoch 106/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 4.8868 - val_accuracy: 0.1964\n","Epoch 107/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 4.9213 - val_accuracy: 0.1954\n","Epoch 108/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 4.9893 - val_accuracy: 0.1894\n","Epoch 109/200\n","10/10 [==============================] - 2s 253ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 5.0296 - val_accuracy: 0.1858\n","Epoch 110/200\n","10/10 [==============================] - 2s 245ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 5.0241 - val_accuracy: 0.1876\n","Epoch 111/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 5.0775 - val_accuracy: 0.1807\n","Epoch 112/200\n","10/10 [==============================] - 2s 252ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 5.0717 - val_accuracy: 0.1831\n","Epoch 113/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 5.1108 - val_accuracy: 0.1848\n","Epoch 114/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 5.1063 - val_accuracy: 0.1897\n","Epoch 115/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 5.1123 - val_accuracy: 0.1859\n","Epoch 116/200\n","10/10 [==============================] - 3s 291ms/step - loss: 0.0292 - accuracy: 0.9969 - val_loss: 5.1709 - val_accuracy: 0.1805\n","Epoch 117/200\n","10/10 [==============================] - 3s 293ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 5.1765 - val_accuracy: 0.1829\n","Epoch 118/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 5.1976 - val_accuracy: 0.1874\n","Epoch 119/200\n","10/10 [==============================] - 2s 251ms/step - loss: 0.0291 - accuracy: 0.9969 - val_loss: 5.2371 - val_accuracy: 0.1852\n","Epoch 120/200\n","10/10 [==============================] - 2s 244ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 5.2171 - val_accuracy: 0.1907\n","Epoch 121/200\n","10/10 [==============================] - 2s 249ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 5.2541 - val_accuracy: 0.1864\n","Epoch 122/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 5.2740 - val_accuracy: 0.1817\n","Epoch 123/200\n","10/10 [==============================] - 2s 243ms/step - loss: 0.0515 - accuracy: 0.9937 - val_loss: 5.2551 - val_accuracy: 0.1840\n","Epoch 124/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 5.3009 - val_accuracy: 0.1817\n","Epoch 125/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 5.2610 - val_accuracy: 0.1822\n","Epoch 126/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0426 - accuracy: 0.9937 - val_loss: 5.1682 - val_accuracy: 0.1931\n","Epoch 127/200\n","10/10 [==============================] - 2s 253ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 5.3020 - val_accuracy: 0.1821\n","Epoch 128/200\n","10/10 [==============================] - 2s 254ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 5.2542 - val_accuracy: 0.1877\n","Epoch 129/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0311 - accuracy: 0.9969 - val_loss: 5.2248 - val_accuracy: 0.1861\n","Epoch 130/200\n","10/10 [==============================] - 3s 291ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 5.1779 - val_accuracy: 0.1899\n","Epoch 131/200\n","10/10 [==============================] - 2s 254ms/step - loss: 0.0298 - accuracy: 0.9969 - val_loss: 5.2217 - val_accuracy: 0.1858\n","Epoch 132/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0312 - accuracy: 0.9969 - val_loss: 5.3525 - val_accuracy: 0.1769\n","Epoch 133/200\n","10/10 [==============================] - 2s 256ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 5.3728 - val_accuracy: 0.1799\n","Epoch 134/200\n","10/10 [==============================] - 2s 253ms/step - loss: 0.0266 - accuracy: 0.9969 - val_loss: 5.2391 - val_accuracy: 0.1953\n","Epoch 135/200\n","10/10 [==============================] - 2s 267ms/step - loss: 0.0341 - accuracy: 0.9969 - val_loss: 5.3199 - val_accuracy: 0.1882\n","Epoch 136/200\n","10/10 [==============================] - 2s 257ms/step - loss: 0.0267 - accuracy: 0.9969 - val_loss: 5.4705 - val_accuracy: 0.1740\n","Epoch 137/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 5.4541 - val_accuracy: 0.1758\n","Epoch 138/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0269 - accuracy: 0.9969 - val_loss: 5.3675 - val_accuracy: 0.1826\n","Epoch 139/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0325 - accuracy: 0.9969 - val_loss: 5.3863 - val_accuracy: 0.1835\n","Epoch 140/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 5.3779 - val_accuracy: 0.1907\n","Epoch 141/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 5.2784 - val_accuracy: 0.1983\n","Epoch 142/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 5.3326 - val_accuracy: 0.1918\n","Epoch 143/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 5.3778 - val_accuracy: 0.1873\n","Epoch 144/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0211 - accuracy: 0.9969 - val_loss: 5.3616 - val_accuracy: 0.1863\n","Epoch 145/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 5.3127 - val_accuracy: 0.1930\n","Epoch 146/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 5.4013 - val_accuracy: 0.1890\n","Epoch 147/200\n","10/10 [==============================] - 2s 259ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 5.5536 - val_accuracy: 0.1786\n","Epoch 148/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 5.4238 - val_accuracy: 0.1891\n","Epoch 149/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 5.3865 - val_accuracy: 0.1925\n","Epoch 150/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 5.4192 - val_accuracy: 0.1900\n","Epoch 151/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 5.4329 - val_accuracy: 0.1903\n","Epoch 152/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 5.4252 - val_accuracy: 0.1939\n","Epoch 153/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 5.4360 - val_accuracy: 0.1927\n","Epoch 154/200\n","10/10 [==============================] - 2s 261ms/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 5.4204 - val_accuracy: 0.2005\n","Epoch 155/200\n","10/10 [==============================] - 2s 259ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 5.4725 - val_accuracy: 0.1947\n","Epoch 156/200\n","10/10 [==============================] - 2s 252ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 5.5299 - val_accuracy: 0.1909\n","Epoch 157/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 5.5802 - val_accuracy: 0.1824\n","Epoch 158/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 5.4899 - val_accuracy: 0.1934\n","Epoch 159/200\n","10/10 [==============================] - 2s 263ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 5.4844 - val_accuracy: 0.1952\n","Epoch 160/200\n","10/10 [==============================] - 2s 254ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 5.7433 - val_accuracy: 0.1761\n","Epoch 161/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 5.7327 - val_accuracy: 0.1773\n","Epoch 162/200\n","10/10 [==============================] - 2s 250ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 5.6561 - val_accuracy: 0.1816\n","Epoch 163/200\n","10/10 [==============================] - 3s 293ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 5.6285 - val_accuracy: 0.1842\n","Epoch 164/200\n","10/10 [==============================] - 2s 250ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 5.7567 - val_accuracy: 0.1719\n","Epoch 165/200\n","10/10 [==============================] - 2s 253ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 5.7314 - val_accuracy: 0.1771\n","Epoch 166/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 5.7374 - val_accuracy: 0.1824\n","Epoch 167/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 5.6845 - val_accuracy: 0.1868\n","Epoch 168/200\n","10/10 [==============================] - 3s 292ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 5.6683 - val_accuracy: 0.1880\n","Epoch 169/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 5.7285 - val_accuracy: 0.1836\n","Epoch 170/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 5.8318 - val_accuracy: 0.1758\n","Epoch 171/200\n","10/10 [==============================] - 2s 257ms/step - loss: 0.0175 - accuracy: 0.9969 - val_loss: 5.8604 - val_accuracy: 0.1741\n","Epoch 172/200\n","10/10 [==============================] - 2s 262ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 5.7327 - val_accuracy: 0.1847\n","Epoch 173/200\n","10/10 [==============================] - 2s 260ms/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 5.5253 - val_accuracy: 0.2165\n","Epoch 174/200\n","10/10 [==============================] - 2s 254ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 5.7989 - val_accuracy: 0.1869\n","Epoch 175/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 5.8716 - val_accuracy: 0.1855\n","Epoch 176/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 5.6629 - val_accuracy: 0.1991\n","Epoch 177/200\n","10/10 [==============================] - 3s 292ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 5.7061 - val_accuracy: 0.1914\n","Epoch 178/200\n","10/10 [==============================] - 2s 258ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 5.8157 - val_accuracy: 0.1816\n","Epoch 179/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 5.7464 - val_accuracy: 0.1864\n","Epoch 180/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 5.8129 - val_accuracy: 0.1795\n","Epoch 181/200\n","10/10 [==============================] - 2s 257ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 5.7785 - val_accuracy: 0.1842\n","Epoch 182/200\n","10/10 [==============================] - 2s 254ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 5.7444 - val_accuracy: 0.1902\n","Epoch 183/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 5.7810 - val_accuracy: 0.1874\n","Epoch 184/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 5.8204 - val_accuracy: 0.1868\n","Epoch 185/200\n","10/10 [==============================] - 2s 257ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 5.7463 - val_accuracy: 0.1894\n","Epoch 186/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 5.8196 - val_accuracy: 0.1870\n","Epoch 187/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 5.8502 - val_accuracy: 0.1891\n","Epoch 188/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 5.8903 - val_accuracy: 0.1891\n","Epoch 189/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0307 - accuracy: 0.9937 - val_loss: 5.9653 - val_accuracy: 0.1805\n","Epoch 190/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 5.7882 - val_accuracy: 0.1990\n","Epoch 191/200\n","10/10 [==============================] - 2s 251ms/step - loss: 0.0256 - accuracy: 0.9969 - val_loss: 5.7417 - val_accuracy: 0.2038\n","Epoch 192/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 6.1022 - val_accuracy: 0.1756\n","Epoch 193/200\n","10/10 [==============================] - 2s 257ms/step - loss: 0.0209 - accuracy: 0.9969 - val_loss: 5.9523 - val_accuracy: 0.1878\n","Epoch 194/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0296 - accuracy: 0.9969 - val_loss: 5.8126 - val_accuracy: 0.2000\n","Epoch 195/200\n","10/10 [==============================] - 2s 257ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 5.8967 - val_accuracy: 0.1957\n","Epoch 196/200\n","10/10 [==============================] - 2s 257ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 5.9163 - val_accuracy: 0.1958\n","Epoch 197/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 5.8375 - val_accuracy: 0.1987\n","Epoch 198/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.0234 - accuracy: 0.9969 - val_loss: 5.8033 - val_accuracy: 0.2040\n","Epoch 199/200\n","10/10 [==============================] - 2s 255ms/step - loss: 0.0297 - accuracy: 0.9969 - val_loss: 5.9093 - val_accuracy: 0.1962\n","Epoch 200/200\n","10/10 [==============================] - 2s 256ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 5.7918 - val_accuracy: 0.2109\n"]}]},{"cell_type":"code","source":["# clearly we need some strong regularization with this small training set\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          layers.Dropout(0.4),\n","          layers.Dense(10,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=200, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DvMApe85ttHM","executionInfo":{"status":"ok","timestamp":1652032283467,"user_tz":240,"elapsed":503066,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"f6d3fa3f-40f4-4a43-8022-e45fb451de84"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","10/10 [==============================] - 4s 320ms/step - loss: 3.0625 - accuracy: 0.0812 - val_loss: 122.4370 - val_accuracy: 0.1898\n","Epoch 2/200\n","10/10 [==============================] - 2s 241ms/step - loss: 2.8030 - accuracy: 0.1312 - val_loss: 90.4884 - val_accuracy: 0.1898\n","Epoch 3/200\n","10/10 [==============================] - 2s 233ms/step - loss: 2.6270 - accuracy: 0.1531 - val_loss: 69.8426 - val_accuracy: 0.1898\n","Epoch 4/200\n","10/10 [==============================] - 2s 239ms/step - loss: 2.5114 - accuracy: 0.1719 - val_loss: 53.6959 - val_accuracy: 0.1898\n","Epoch 5/200\n","10/10 [==============================] - 2s 244ms/step - loss: 2.3816 - accuracy: 0.2406 - val_loss: 44.6991 - val_accuracy: 0.1898\n","Epoch 6/200\n","10/10 [==============================] - 2s 236ms/step - loss: 2.2969 - accuracy: 0.2719 - val_loss: 38.1150 - val_accuracy: 0.1898\n","Epoch 7/200\n","10/10 [==============================] - 3s 289ms/step - loss: 2.2598 - accuracy: 0.2781 - val_loss: 31.9511 - val_accuracy: 0.1898\n","Epoch 8/200\n","10/10 [==============================] - 2s 229ms/step - loss: 2.2285 - accuracy: 0.3219 - val_loss: 26.7344 - val_accuracy: 0.1898\n","Epoch 9/200\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1539 - accuracy: 0.3531 - val_loss: 22.8648 - val_accuracy: 0.1898\n","Epoch 10/200\n","10/10 [==============================] - 3s 289ms/step - loss: 2.1165 - accuracy: 0.3719 - val_loss: 20.0690 - val_accuracy: 0.1898\n","Epoch 11/200\n","10/10 [==============================] - 2s 237ms/step - loss: 2.0600 - accuracy: 0.3594 - val_loss: 18.0596 - val_accuracy: 0.1898\n","Epoch 12/200\n","10/10 [==============================] - 2s 239ms/step - loss: 2.0200 - accuracy: 0.4000 - val_loss: 15.9572 - val_accuracy: 0.1898\n","Epoch 13/200\n","10/10 [==============================] - 2s 231ms/step - loss: 1.9772 - accuracy: 0.4062 - val_loss: 14.3070 - val_accuracy: 0.1898\n","Epoch 14/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9388 - accuracy: 0.4437 - val_loss: 12.7175 - val_accuracy: 0.1898\n","Epoch 15/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9168 - accuracy: 0.4375 - val_loss: 11.3721 - val_accuracy: 0.1898\n","Epoch 16/200\n","10/10 [==============================] - 2s 232ms/step - loss: 1.8970 - accuracy: 0.4656 - val_loss: 10.0116 - val_accuracy: 0.1898\n","Epoch 17/200\n","10/10 [==============================] - 2s 231ms/step - loss: 1.8574 - accuracy: 0.4531 - val_loss: 8.8747 - val_accuracy: 0.1900\n","Epoch 18/200\n","10/10 [==============================] - 2s 244ms/step - loss: 1.8043 - accuracy: 0.4469 - val_loss: 8.0363 - val_accuracy: 0.1902\n","Epoch 19/200\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8059 - accuracy: 0.5125 - val_loss: 7.2756 - val_accuracy: 0.1902\n","Epoch 20/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.7468 - accuracy: 0.5094 - val_loss: 6.6090 - val_accuracy: 0.1904\n","Epoch 21/200\n","10/10 [==============================] - 2s 238ms/step - loss: 1.7413 - accuracy: 0.5281 - val_loss: 6.0747 - val_accuracy: 0.1908\n","Epoch 22/200\n","10/10 [==============================] - 2s 235ms/step - loss: 1.6906 - accuracy: 0.5188 - val_loss: 5.6756 - val_accuracy: 0.1908\n","Epoch 23/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.6526 - accuracy: 0.5125 - val_loss: 5.0940 - val_accuracy: 0.1917\n","Epoch 24/200\n","10/10 [==============================] - 3s 290ms/step - loss: 1.6605 - accuracy: 0.5406 - val_loss: 4.6471 - val_accuracy: 0.1926\n","Epoch 25/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.6231 - accuracy: 0.5500 - val_loss: 4.2631 - val_accuracy: 0.1944\n","Epoch 26/200\n","10/10 [==============================] - 2s 237ms/step - loss: 1.6075 - accuracy: 0.5312 - val_loss: 3.9590 - val_accuracy: 0.1975\n","Epoch 27/200\n","10/10 [==============================] - 2s 240ms/step - loss: 1.5493 - accuracy: 0.6062 - val_loss: 3.7097 - val_accuracy: 0.2006\n","Epoch 28/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.5093 - accuracy: 0.6031 - val_loss: 3.4627 - val_accuracy: 0.2083\n","Epoch 29/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.5363 - accuracy: 0.5781 - val_loss: 3.1741 - val_accuracy: 0.2150\n","Epoch 30/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.5053 - accuracy: 0.5719 - val_loss: 2.9360 - val_accuracy: 0.2196\n","Epoch 31/200\n","10/10 [==============================] - 2s 234ms/step - loss: 1.5216 - accuracy: 0.5406 - val_loss: 2.7225 - val_accuracy: 0.2274\n","Epoch 32/200\n","10/10 [==============================] - 2s 232ms/step - loss: 1.4833 - accuracy: 0.6031 - val_loss: 2.5758 - val_accuracy: 0.2348\n","Epoch 33/200\n","10/10 [==============================] - 2s 234ms/step - loss: 1.4752 - accuracy: 0.6187 - val_loss: 2.4556 - val_accuracy: 0.2506\n","Epoch 34/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.4553 - accuracy: 0.6156 - val_loss: 2.3851 - val_accuracy: 0.2610\n","Epoch 35/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.4316 - accuracy: 0.6031 - val_loss: 2.3588 - val_accuracy: 0.2570\n","Epoch 36/200\n","10/10 [==============================] - 2s 238ms/step - loss: 1.3750 - accuracy: 0.6281 - val_loss: 2.3299 - val_accuracy: 0.2539\n","Epoch 37/200\n","10/10 [==============================] - 3s 290ms/step - loss: 1.3597 - accuracy: 0.6219 - val_loss: 2.3011 - val_accuracy: 0.2609\n","Epoch 38/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.3188 - accuracy: 0.6469 - val_loss: 2.3075 - val_accuracy: 0.2588\n","Epoch 39/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.3653 - accuracy: 0.6250 - val_loss: 2.2765 - val_accuracy: 0.2741\n","Epoch 40/200\n","10/10 [==============================] - 2s 241ms/step - loss: 1.2875 - accuracy: 0.6562 - val_loss: 2.2477 - val_accuracy: 0.2908\n","Epoch 41/200\n","10/10 [==============================] - 3s 290ms/step - loss: 1.2714 - accuracy: 0.6406 - val_loss: 2.2385 - val_accuracy: 0.2980\n","Epoch 42/200\n","10/10 [==============================] - 3s 291ms/step - loss: 1.2379 - accuracy: 0.6875 - val_loss: 2.2464 - val_accuracy: 0.3004\n","Epoch 43/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.2630 - accuracy: 0.6938 - val_loss: 2.2358 - val_accuracy: 0.3112\n","Epoch 44/200\n","10/10 [==============================] - 2s 242ms/step - loss: 1.2192 - accuracy: 0.6625 - val_loss: 2.2239 - val_accuracy: 0.3200\n","Epoch 45/200\n","10/10 [==============================] - 2s 238ms/step - loss: 1.1645 - accuracy: 0.7063 - val_loss: 2.2321 - val_accuracy: 0.3214\n","Epoch 46/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.2156 - accuracy: 0.6781 - val_loss: 2.2418 - val_accuracy: 0.3213\n","Epoch 47/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.2103 - accuracy: 0.6625 - val_loss: 2.2454 - val_accuracy: 0.3213\n","Epoch 48/200\n","10/10 [==============================] - 2s 241ms/step - loss: 1.1836 - accuracy: 0.6625 - val_loss: 2.2813 - val_accuracy: 0.3090\n","Epoch 49/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.1507 - accuracy: 0.6844 - val_loss: 2.2939 - val_accuracy: 0.3100\n","Epoch 50/200\n","10/10 [==============================] - 2s 235ms/step - loss: 1.1398 - accuracy: 0.7031 - val_loss: 2.3195 - val_accuracy: 0.3030\n","Epoch 51/200\n","10/10 [==============================] - 2s 234ms/step - loss: 1.1258 - accuracy: 0.6875 - val_loss: 2.3488 - val_accuracy: 0.2957\n","Epoch 52/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.1747 - accuracy: 0.6938 - val_loss: 2.3494 - val_accuracy: 0.2990\n","Epoch 53/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.0959 - accuracy: 0.7500 - val_loss: 2.3673 - val_accuracy: 0.2961\n","Epoch 54/200\n","10/10 [==============================] - 2s 231ms/step - loss: 1.1000 - accuracy: 0.7219 - val_loss: 2.3722 - val_accuracy: 0.2997\n","Epoch 55/200\n","10/10 [==============================] - 2s 234ms/step - loss: 1.1137 - accuracy: 0.6875 - val_loss: 2.3901 - val_accuracy: 0.2977\n","Epoch 56/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.1181 - accuracy: 0.6969 - val_loss: 2.4058 - val_accuracy: 0.2947\n","Epoch 57/200\n","10/10 [==============================] - 2s 241ms/step - loss: 1.0939 - accuracy: 0.7125 - val_loss: 2.4248 - val_accuracy: 0.2912\n","Epoch 58/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.0446 - accuracy: 0.7094 - val_loss: 2.4540 - val_accuracy: 0.2795\n","Epoch 59/200\n","10/10 [==============================] - 2s 235ms/step - loss: 1.0190 - accuracy: 0.7500 - val_loss: 2.4719 - val_accuracy: 0.2724\n","Epoch 60/200\n","10/10 [==============================] - 2s 237ms/step - loss: 1.0541 - accuracy: 0.7063 - val_loss: 2.4801 - val_accuracy: 0.2751\n","Epoch 61/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.9792 - accuracy: 0.7281 - val_loss: 2.5147 - val_accuracy: 0.2640\n","Epoch 62/200\n","10/10 [==============================] - 2s 244ms/step - loss: 1.0291 - accuracy: 0.7219 - val_loss: 2.5242 - val_accuracy: 0.2655\n","Epoch 63/200\n","10/10 [==============================] - 2s 237ms/step - loss: 1.0010 - accuracy: 0.7375 - val_loss: 2.4890 - val_accuracy: 0.2830\n","Epoch 64/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.9843 - accuracy: 0.7469 - val_loss: 2.4770 - val_accuracy: 0.2901\n","Epoch 65/200\n","10/10 [==============================] - 3s 290ms/step - loss: 1.0185 - accuracy: 0.7250 - val_loss: 2.5371 - val_accuracy: 0.2702\n","Epoch 66/200\n","10/10 [==============================] - 3s 289ms/step - loss: 1.0014 - accuracy: 0.7250 - val_loss: 2.5560 - val_accuracy: 0.2642\n","Epoch 67/200\n","10/10 [==============================] - 2s 235ms/step - loss: 0.9577 - accuracy: 0.7812 - val_loss: 2.5862 - val_accuracy: 0.2551\n","Epoch 68/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.9244 - accuracy: 0.7625 - val_loss: 2.6101 - val_accuracy: 0.2528\n","Epoch 69/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.9575 - accuracy: 0.7469 - val_loss: 2.6228 - val_accuracy: 0.2539\n","Epoch 70/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.9306 - accuracy: 0.7688 - val_loss: 2.6273 - val_accuracy: 0.2550\n","Epoch 71/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.8976 - accuracy: 0.7656 - val_loss: 2.6290 - val_accuracy: 0.2556\n","Epoch 72/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.8867 - accuracy: 0.7719 - val_loss: 2.6130 - val_accuracy: 0.2618\n","Epoch 73/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.8416 - accuracy: 0.7937 - val_loss: 2.6208 - val_accuracy: 0.2625\n","Epoch 74/200\n","10/10 [==============================] - 2s 231ms/step - loss: 0.8583 - accuracy: 0.7531 - val_loss: 2.6398 - val_accuracy: 0.2598\n","Epoch 75/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.8232 - accuracy: 0.7594 - val_loss: 2.6669 - val_accuracy: 0.2518\n","Epoch 76/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.8857 - accuracy: 0.7281 - val_loss: 2.6949 - val_accuracy: 0.2447\n","Epoch 77/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.7855 - accuracy: 0.8031 - val_loss: 2.6829 - val_accuracy: 0.2533\n","Epoch 78/200\n","10/10 [==============================] - 3s 291ms/step - loss: 0.8558 - accuracy: 0.7812 - val_loss: 2.6925 - val_accuracy: 0.2550\n","Epoch 79/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.8098 - accuracy: 0.7906 - val_loss: 2.6938 - val_accuracy: 0.2586\n","Epoch 80/200\n","10/10 [==============================] - 2s 232ms/step - loss: 0.8176 - accuracy: 0.7781 - val_loss: 2.6890 - val_accuracy: 0.2627\n","Epoch 81/200\n","10/10 [==============================] - 2s 235ms/step - loss: 0.8140 - accuracy: 0.7656 - val_loss: 2.7319 - val_accuracy: 0.2513\n","Epoch 82/200\n","10/10 [==============================] - 2s 235ms/step - loss: 0.8145 - accuracy: 0.7719 - val_loss: 2.7611 - val_accuracy: 0.2467\n","Epoch 83/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.8104 - accuracy: 0.7625 - val_loss: 2.7499 - val_accuracy: 0.2510\n","Epoch 84/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7848 - accuracy: 0.7969 - val_loss: 2.7452 - val_accuracy: 0.2570\n","Epoch 85/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.7805 - accuracy: 0.8031 - val_loss: 2.7607 - val_accuracy: 0.2585\n","Epoch 86/200\n","10/10 [==============================] - 2s 232ms/step - loss: 0.8105 - accuracy: 0.7781 - val_loss: 2.8137 - val_accuracy: 0.2453\n","Epoch 87/200\n","10/10 [==============================] - 2s 235ms/step - loss: 0.8432 - accuracy: 0.7688 - val_loss: 2.8237 - val_accuracy: 0.2444\n","Epoch 88/200\n","10/10 [==============================] - 2s 234ms/step - loss: 0.7467 - accuracy: 0.8188 - val_loss: 2.8503 - val_accuracy: 0.2385\n","Epoch 89/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7610 - accuracy: 0.7844 - val_loss: 2.8320 - val_accuracy: 0.2473\n","Epoch 90/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.7972 - accuracy: 0.7844 - val_loss: 2.8296 - val_accuracy: 0.2481\n","Epoch 91/200\n","10/10 [==============================] - 2s 240ms/step - loss: 0.7338 - accuracy: 0.8281 - val_loss: 2.8360 - val_accuracy: 0.2470\n","Epoch 92/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7541 - accuracy: 0.7937 - val_loss: 2.8566 - val_accuracy: 0.2431\n","Epoch 93/200\n","10/10 [==============================] - 2s 244ms/step - loss: 0.7157 - accuracy: 0.8219 - val_loss: 2.8461 - val_accuracy: 0.2479\n","Epoch 94/200\n","10/10 [==============================] - 2s 228ms/step - loss: 0.7399 - accuracy: 0.8000 - val_loss: 2.8413 - val_accuracy: 0.2509\n","Epoch 95/200\n","10/10 [==============================] - 2s 235ms/step - loss: 0.7313 - accuracy: 0.8156 - val_loss: 2.8631 - val_accuracy: 0.2491\n","Epoch 96/200\n","10/10 [==============================] - 2s 231ms/step - loss: 0.7345 - accuracy: 0.8062 - val_loss: 2.8394 - val_accuracy: 0.2558\n","Epoch 97/200\n","10/10 [==============================] - 2s 233ms/step - loss: 0.7533 - accuracy: 0.7844 - val_loss: 2.8515 - val_accuracy: 0.2553\n","Epoch 98/200\n","10/10 [==============================] - 2s 233ms/step - loss: 0.7652 - accuracy: 0.7719 - val_loss: 2.9126 - val_accuracy: 0.2407\n","Epoch 99/200\n","10/10 [==============================] - 2s 238ms/step - loss: 0.7301 - accuracy: 0.7906 - val_loss: 2.9344 - val_accuracy: 0.2370\n","Epoch 100/200\n","10/10 [==============================] - 2s 237ms/step - loss: 0.7119 - accuracy: 0.8125 - val_loss: 2.9332 - val_accuracy: 0.2369\n","Epoch 101/200\n","10/10 [==============================] - 2s 233ms/step - loss: 0.7071 - accuracy: 0.8062 - val_loss: 2.9406 - val_accuracy: 0.2399\n","Epoch 102/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.7399 - accuracy: 0.7750 - val_loss: 2.9334 - val_accuracy: 0.2424\n","Epoch 103/200\n","10/10 [==============================] - 2s 238ms/step - loss: 0.7447 - accuracy: 0.7781 - val_loss: 2.9272 - val_accuracy: 0.2436\n","Epoch 104/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7676 - accuracy: 0.7688 - val_loss: 2.9446 - val_accuracy: 0.2425\n","Epoch 105/200\n","10/10 [==============================] - 2s 237ms/step - loss: 0.6981 - accuracy: 0.8125 - val_loss: 2.9509 - val_accuracy: 0.2448\n","Epoch 106/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7097 - accuracy: 0.8000 - val_loss: 2.9305 - val_accuracy: 0.2537\n","Epoch 107/200\n","10/10 [==============================] - 2s 230ms/step - loss: 0.6739 - accuracy: 0.8094 - val_loss: 2.9473 - val_accuracy: 0.2502\n","Epoch 108/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6172 - accuracy: 0.8438 - val_loss: 2.9698 - val_accuracy: 0.2460\n","Epoch 109/200\n","10/10 [==============================] - 2s 231ms/step - loss: 0.6831 - accuracy: 0.8000 - val_loss: 2.9654 - val_accuracy: 0.2524\n","Epoch 110/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6785 - accuracy: 0.8125 - val_loss: 3.0061 - val_accuracy: 0.2474\n","Epoch 111/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6779 - accuracy: 0.8250 - val_loss: 3.0373 - val_accuracy: 0.2418\n","Epoch 112/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6682 - accuracy: 0.8188 - val_loss: 3.0209 - val_accuracy: 0.2433\n","Epoch 113/200\n","10/10 [==============================] - 2s 231ms/step - loss: 0.6053 - accuracy: 0.8375 - val_loss: 3.0428 - val_accuracy: 0.2379\n","Epoch 114/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.6477 - accuracy: 0.8188 - val_loss: 3.0128 - val_accuracy: 0.2483\n","Epoch 115/200\n","10/10 [==============================] - 2s 240ms/step - loss: 0.6578 - accuracy: 0.8125 - val_loss: 3.0002 - val_accuracy: 0.2545\n","Epoch 116/200\n","10/10 [==============================] - 3s 292ms/step - loss: 0.6329 - accuracy: 0.8062 - val_loss: 3.0814 - val_accuracy: 0.2366\n","Epoch 117/200\n","10/10 [==============================] - 2s 234ms/step - loss: 0.6303 - accuracy: 0.8250 - val_loss: 3.1225 - val_accuracy: 0.2287\n","Epoch 118/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.6549 - accuracy: 0.8250 - val_loss: 3.0793 - val_accuracy: 0.2380\n","Epoch 119/200\n","10/10 [==============================] - 2s 240ms/step - loss: 0.6443 - accuracy: 0.8344 - val_loss: 3.0641 - val_accuracy: 0.2426\n","Epoch 120/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.7204 - accuracy: 0.8062 - val_loss: 3.0858 - val_accuracy: 0.2398\n","Epoch 121/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.5574 - accuracy: 0.8562 - val_loss: 3.0697 - val_accuracy: 0.2451\n","Epoch 122/200\n","10/10 [==============================] - 2s 240ms/step - loss: 0.6929 - accuracy: 0.7937 - val_loss: 3.0524 - val_accuracy: 0.2494\n","Epoch 123/200\n","10/10 [==============================] - 2s 240ms/step - loss: 0.6233 - accuracy: 0.8281 - val_loss: 3.1024 - val_accuracy: 0.2406\n","Epoch 124/200\n","10/10 [==============================] - 2s 231ms/step - loss: 0.6566 - accuracy: 0.8125 - val_loss: 3.1487 - val_accuracy: 0.2328\n","Epoch 125/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6131 - accuracy: 0.8344 - val_loss: 3.1435 - val_accuracy: 0.2339\n","Epoch 126/200\n","10/10 [==============================] - 2s 237ms/step - loss: 0.6343 - accuracy: 0.8313 - val_loss: 3.1585 - val_accuracy: 0.2333\n","Epoch 127/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5858 - accuracy: 0.8375 - val_loss: 3.1278 - val_accuracy: 0.2425\n","Epoch 128/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6154 - accuracy: 0.8188 - val_loss: 3.1299 - val_accuracy: 0.2435\n","Epoch 129/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5596 - accuracy: 0.8438 - val_loss: 3.1066 - val_accuracy: 0.2521\n","Epoch 130/200\n","10/10 [==============================] - 2s 238ms/step - loss: 0.7153 - accuracy: 0.7906 - val_loss: 3.1014 - val_accuracy: 0.2546\n","Epoch 131/200\n","10/10 [==============================] - 2s 234ms/step - loss: 0.5519 - accuracy: 0.8656 - val_loss: 3.1526 - val_accuracy: 0.2428\n","Epoch 132/200\n","10/10 [==============================] - 2s 240ms/step - loss: 0.5887 - accuracy: 0.8344 - val_loss: 3.1334 - val_accuracy: 0.2483\n","Epoch 133/200\n","10/10 [==============================] - 2s 238ms/step - loss: 0.6040 - accuracy: 0.8031 - val_loss: 3.1277 - val_accuracy: 0.2473\n","Epoch 134/200\n","10/10 [==============================] - 2s 240ms/step - loss: 0.6198 - accuracy: 0.7875 - val_loss: 3.1328 - val_accuracy: 0.2455\n","Epoch 135/200\n","10/10 [==============================] - 2s 237ms/step - loss: 0.5830 - accuracy: 0.8438 - val_loss: 3.1280 - val_accuracy: 0.2517\n","Epoch 136/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5583 - accuracy: 0.8469 - val_loss: 3.1436 - val_accuracy: 0.2474\n","Epoch 137/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5584 - accuracy: 0.8281 - val_loss: 3.1537 - val_accuracy: 0.2446\n","Epoch 138/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.6253 - accuracy: 0.8031 - val_loss: 3.1351 - val_accuracy: 0.2476\n","Epoch 139/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.5608 - accuracy: 0.8500 - val_loss: 3.1355 - val_accuracy: 0.2478\n","Epoch 140/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5687 - accuracy: 0.8313 - val_loss: 3.1102 - val_accuracy: 0.2586\n","Epoch 141/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.6243 - accuracy: 0.8188 - val_loss: 3.1240 - val_accuracy: 0.2606\n","Epoch 142/200\n","10/10 [==============================] - 2s 238ms/step - loss: 0.6108 - accuracy: 0.8062 - val_loss: 3.1453 - val_accuracy: 0.2560\n","Epoch 143/200\n","10/10 [==============================] - 2s 237ms/step - loss: 0.5772 - accuracy: 0.8438 - val_loss: 3.1969 - val_accuracy: 0.2459\n","Epoch 144/200\n","10/10 [==============================] - 2s 241ms/step - loss: 0.5907 - accuracy: 0.8500 - val_loss: 3.2161 - val_accuracy: 0.2425\n","Epoch 145/200\n","10/10 [==============================] - 2s 234ms/step - loss: 0.5889 - accuracy: 0.8156 - val_loss: 3.2293 - val_accuracy: 0.2438\n","Epoch 146/200\n","10/10 [==============================] - 2s 239ms/step - loss: 0.5918 - accuracy: 0.8156 - val_loss: 3.2280 - val_accuracy: 0.2487\n","Epoch 147/200\n","10/10 [==============================] - 2s 243ms/step - loss: 0.6655 - accuracy: 0.7937 - val_loss: 3.2100 - val_accuracy: 0.2519\n","Epoch 148/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5802 - accuracy: 0.8125 - val_loss: 3.2263 - val_accuracy: 0.2501\n","Epoch 149/200\n","10/10 [==============================] - 2s 239ms/step - loss: 0.5801 - accuracy: 0.8281 - val_loss: 3.2479 - val_accuracy: 0.2493\n","Epoch 150/200\n","10/10 [==============================] - 2s 241ms/step - loss: 0.5494 - accuracy: 0.8625 - val_loss: 3.2378 - val_accuracy: 0.2505\n","Epoch 151/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5823 - accuracy: 0.8250 - val_loss: 3.2415 - val_accuracy: 0.2464\n","Epoch 152/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.5280 - accuracy: 0.8562 - val_loss: 3.2611 - val_accuracy: 0.2450\n","Epoch 153/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.6256 - accuracy: 0.8000 - val_loss: 3.2799 - val_accuracy: 0.2425\n","Epoch 154/200\n","10/10 [==============================] - 2s 239ms/step - loss: 0.5567 - accuracy: 0.8219 - val_loss: 3.3138 - val_accuracy: 0.2399\n","Epoch 155/200\n","10/10 [==============================] - 2s 235ms/step - loss: 0.5722 - accuracy: 0.8500 - val_loss: 3.3647 - val_accuracy: 0.2316\n","Epoch 156/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4962 - accuracy: 0.8719 - val_loss: 3.4020 - val_accuracy: 0.2295\n","Epoch 157/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5826 - accuracy: 0.8281 - val_loss: 3.4052 - val_accuracy: 0.2325\n","Epoch 158/200\n","10/10 [==============================] - 2s 239ms/step - loss: 0.5271 - accuracy: 0.8562 - val_loss: 3.3544 - val_accuracy: 0.2394\n","Epoch 159/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5323 - accuracy: 0.8500 - val_loss: 3.3139 - val_accuracy: 0.2471\n","Epoch 160/200\n","10/10 [==============================] - 2s 231ms/step - loss: 0.5781 - accuracy: 0.8469 - val_loss: 3.2888 - val_accuracy: 0.2555\n","Epoch 161/200\n","10/10 [==============================] - 2s 238ms/step - loss: 0.5517 - accuracy: 0.8344 - val_loss: 3.3251 - val_accuracy: 0.2503\n","Epoch 162/200\n","10/10 [==============================] - 2s 233ms/step - loss: 0.5410 - accuracy: 0.8500 - val_loss: 3.3072 - val_accuracy: 0.2517\n","Epoch 163/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5348 - accuracy: 0.8500 - val_loss: 3.2989 - val_accuracy: 0.2517\n","Epoch 164/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.6075 - accuracy: 0.8219 - val_loss: 3.2932 - val_accuracy: 0.2526\n","Epoch 165/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5552 - accuracy: 0.8469 - val_loss: 3.3196 - val_accuracy: 0.2496\n","Epoch 166/200\n","10/10 [==============================] - 2s 231ms/step - loss: 0.4693 - accuracy: 0.8813 - val_loss: 3.3632 - val_accuracy: 0.2443\n","Epoch 167/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5730 - accuracy: 0.8281 - val_loss: 3.3576 - val_accuracy: 0.2494\n","Epoch 168/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.5047 - accuracy: 0.8469 - val_loss: 3.3503 - val_accuracy: 0.2518\n","Epoch 169/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5492 - accuracy: 0.8062 - val_loss: 3.3605 - val_accuracy: 0.2513\n","Epoch 170/200\n","10/10 [==============================] - 2s 244ms/step - loss: 0.5658 - accuracy: 0.8188 - val_loss: 3.3966 - val_accuracy: 0.2472\n","Epoch 171/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.5483 - accuracy: 0.8469 - val_loss: 3.4309 - val_accuracy: 0.2383\n","Epoch 172/200\n","10/10 [==============================] - 2s 235ms/step - loss: 0.4835 - accuracy: 0.8438 - val_loss: 3.3831 - val_accuracy: 0.2487\n","Epoch 173/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4922 - accuracy: 0.8687 - val_loss: 3.3331 - val_accuracy: 0.2586\n","Epoch 174/200\n","10/10 [==============================] - 2s 234ms/step - loss: 0.5212 - accuracy: 0.8469 - val_loss: 3.3454 - val_accuracy: 0.2594\n","Epoch 175/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.5294 - accuracy: 0.8250 - val_loss: 3.3606 - val_accuracy: 0.2585\n","Epoch 176/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5316 - accuracy: 0.8500 - val_loss: 3.3840 - val_accuracy: 0.2598\n","Epoch 177/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5499 - accuracy: 0.8188 - val_loss: 3.4403 - val_accuracy: 0.2476\n","Epoch 178/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4939 - accuracy: 0.8531 - val_loss: 3.4669 - val_accuracy: 0.2408\n","Epoch 179/200\n","10/10 [==============================] - 2s 233ms/step - loss: 0.5505 - accuracy: 0.8281 - val_loss: 3.4684 - val_accuracy: 0.2416\n","Epoch 180/200\n","10/10 [==============================] - 2s 238ms/step - loss: 0.5590 - accuracy: 0.8219 - val_loss: 3.4799 - val_accuracy: 0.2439\n","Epoch 181/200\n","10/10 [==============================] - 2s 238ms/step - loss: 0.5631 - accuracy: 0.8344 - val_loss: 3.4497 - val_accuracy: 0.2502\n","Epoch 182/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5220 - accuracy: 0.8406 - val_loss: 3.4325 - val_accuracy: 0.2502\n","Epoch 183/200\n","10/10 [==============================] - 2s 238ms/step - loss: 0.5001 - accuracy: 0.8531 - val_loss: 3.4107 - val_accuracy: 0.2540\n","Epoch 184/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5180 - accuracy: 0.8438 - val_loss: 3.4119 - val_accuracy: 0.2501\n","Epoch 185/200\n","10/10 [==============================] - 2s 243ms/step - loss: 0.4777 - accuracy: 0.8687 - val_loss: 3.3882 - val_accuracy: 0.2531\n","Epoch 186/200\n","10/10 [==============================] - 2s 237ms/step - loss: 0.5218 - accuracy: 0.8500 - val_loss: 3.3964 - val_accuracy: 0.2547\n","Epoch 187/200\n","10/10 [==============================] - 2s 234ms/step - loss: 0.4611 - accuracy: 0.8531 - val_loss: 3.4084 - val_accuracy: 0.2560\n","Epoch 188/200\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4953 - accuracy: 0.8719 - val_loss: 3.4234 - val_accuracy: 0.2545\n","Epoch 189/200\n","10/10 [==============================] - 2s 238ms/step - loss: 0.4810 - accuracy: 0.8750 - val_loss: 3.4745 - val_accuracy: 0.2486\n","Epoch 190/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5337 - accuracy: 0.8094 - val_loss: 3.4872 - val_accuracy: 0.2483\n","Epoch 191/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4622 - accuracy: 0.8500 - val_loss: 3.4902 - val_accuracy: 0.2446\n","Epoch 192/200\n","10/10 [==============================] - 2s 244ms/step - loss: 0.5041 - accuracy: 0.8281 - val_loss: 3.4437 - val_accuracy: 0.2541\n","Epoch 193/200\n","10/10 [==============================] - 2s 236ms/step - loss: 0.4878 - accuracy: 0.8594 - val_loss: 3.4146 - val_accuracy: 0.2593\n","Epoch 194/200\n","10/10 [==============================] - 2s 233ms/step - loss: 0.5247 - accuracy: 0.8500 - val_loss: 3.4927 - val_accuracy: 0.2487\n","Epoch 195/200\n","10/10 [==============================] - 2s 239ms/step - loss: 0.4599 - accuracy: 0.8625 - val_loss: 3.5785 - val_accuracy: 0.2366\n","Epoch 196/200\n","10/10 [==============================] - 2s 237ms/step - loss: 0.5305 - accuracy: 0.8344 - val_loss: 3.5635 - val_accuracy: 0.2417\n","Epoch 197/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4397 - accuracy: 0.8719 - val_loss: 3.4867 - val_accuracy: 0.2559\n","Epoch 198/200\n","10/10 [==============================] - 2s 239ms/step - loss: 0.4615 - accuracy: 0.8719 - val_loss: 3.4648 - val_accuracy: 0.2562\n","Epoch 199/200\n","10/10 [==============================] - 2s 233ms/step - loss: 0.4717 - accuracy: 0.8719 - val_loss: 3.4726 - val_accuracy: 0.2522\n","Epoch 200/200\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4806 - accuracy: 0.8594 - val_loss: 3.4590 - val_accuracy: 0.2554\n"]}]},{"cell_type":"code","source":["# the previous model is starting to look like a real neural network, but one that's overfitting\n","# maybe more complexity could also help it get toward 100% also, but overfitting is the main concern\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          #layers.Dropout(0.4),\n","          layers.Dense(520,kernel_initializer='lecun_normal',kernel_regularizer='l1'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(8,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=100, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-o3QVBFb0YRQ","executionInfo":{"status":"ok","timestamp":1652033116289,"user_tz":240,"elapsed":263218,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"4e6d1fa6-7c6d-4daa-bed1-e9ebb67166f0"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","10/10 [==============================] - 4s 302ms/step - loss: 91.2457 - accuracy: 0.1281 - val_loss: 110.9479 - val_accuracy: 0.0418\n","Epoch 2/100\n","10/10 [==============================] - 3s 290ms/step - loss: 71.2869 - accuracy: 0.2594 - val_loss: 86.3873 - val_accuracy: 0.0418\n","Epoch 3/100\n","10/10 [==============================] - 2s 261ms/step - loss: 54.1958 - accuracy: 0.3094 - val_loss: 61.3516 - val_accuracy: 0.0418\n","Epoch 4/100\n","10/10 [==============================] - 3s 290ms/step - loss: 40.3256 - accuracy: 0.3812 - val_loss: 49.5336 - val_accuracy: 0.0418\n","Epoch 5/100\n","10/10 [==============================] - 2s 266ms/step - loss: 29.5327 - accuracy: 0.4313 - val_loss: 38.7593 - val_accuracy: 0.0418\n","Epoch 6/100\n","10/10 [==============================] - 2s 268ms/step - loss: 21.5527 - accuracy: 0.4500 - val_loss: 28.5247 - val_accuracy: 0.0418\n","Epoch 7/100\n","10/10 [==============================] - 2s 262ms/step - loss: 15.6865 - accuracy: 0.4719 - val_loss: 23.3326 - val_accuracy: 0.0418\n","Epoch 8/100\n","10/10 [==============================] - 3s 290ms/step - loss: 11.5388 - accuracy: 0.4375 - val_loss: 15.1290 - val_accuracy: 0.0417\n","Epoch 9/100\n","10/10 [==============================] - 2s 260ms/step - loss: 8.7407 - accuracy: 0.4406 - val_loss: 17.9397 - val_accuracy: 0.0417\n","Epoch 10/100\n","10/10 [==============================] - 3s 290ms/step - loss: 6.8540 - accuracy: 0.4281 - val_loss: 12.3733 - val_accuracy: 0.0417\n","Epoch 11/100\n","10/10 [==============================] - 3s 290ms/step - loss: 5.6044 - accuracy: 0.4094 - val_loss: 10.7381 - val_accuracy: 0.0417\n","Epoch 12/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.9998 - accuracy: 0.3594 - val_loss: 7.4336 - val_accuracy: 0.0417\n","Epoch 13/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.5762 - accuracy: 0.3688 - val_loss: 7.1955 - val_accuracy: 0.0417\n","Epoch 14/100\n","10/10 [==============================] - 2s 254ms/step - loss: 4.3704 - accuracy: 0.3438 - val_loss: 6.0628 - val_accuracy: 0.0419\n","Epoch 15/100\n","10/10 [==============================] - 2s 252ms/step - loss: 4.3284 - accuracy: 0.3625 - val_loss: 5.5665 - val_accuracy: 0.0417\n","Epoch 16/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.2854 - accuracy: 0.3750 - val_loss: 6.2961 - val_accuracy: 0.0416\n","Epoch 17/100\n","10/10 [==============================] - 5s 574ms/step - loss: 4.2820 - accuracy: 0.3531 - val_loss: 6.9565 - val_accuracy: 0.0417\n","Epoch 18/100\n","10/10 [==============================] - 2s 256ms/step - loss: 4.1170 - accuracy: 0.3594 - val_loss: 6.5077 - val_accuracy: 0.0418\n","Epoch 19/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.0922 - accuracy: 0.3594 - val_loss: 5.9326 - val_accuracy: 0.0509\n","Epoch 20/100\n","10/10 [==============================] - 2s 254ms/step - loss: 4.0592 - accuracy: 0.3500 - val_loss: 5.4273 - val_accuracy: 0.0446\n","Epoch 21/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.0561 - accuracy: 0.3750 - val_loss: 5.3376 - val_accuracy: 0.0418\n","Epoch 22/100\n","10/10 [==============================] - 3s 289ms/step - loss: 4.1343 - accuracy: 0.3656 - val_loss: 5.0713 - val_accuracy: 0.0416\n","Epoch 23/100\n","10/10 [==============================] - 2s 253ms/step - loss: 3.9402 - accuracy: 0.3969 - val_loss: 5.2870 - val_accuracy: 0.0419\n","Epoch 24/100\n","10/10 [==============================] - 2s 258ms/step - loss: 3.9886 - accuracy: 0.3781 - val_loss: 5.0348 - val_accuracy: 0.0420\n","Epoch 25/100\n","10/10 [==============================] - 2s 257ms/step - loss: 3.8631 - accuracy: 0.4281 - val_loss: 4.8793 - val_accuracy: 0.0419\n","Epoch 26/100\n","10/10 [==============================] - 3s 289ms/step - loss: 3.8915 - accuracy: 0.3969 - val_loss: 4.8229 - val_accuracy: 0.0460\n","Epoch 27/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.8129 - accuracy: 0.4187 - val_loss: 5.1313 - val_accuracy: 0.0418\n","Epoch 28/100\n","10/10 [==============================] - 2s 256ms/step - loss: 3.9125 - accuracy: 0.4125 - val_loss: 5.4379 - val_accuracy: 0.0421\n","Epoch 29/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.8046 - accuracy: 0.4437 - val_loss: 4.7900 - val_accuracy: 0.0557\n","Epoch 30/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.7306 - accuracy: 0.4156 - val_loss: 4.5407 - val_accuracy: 0.0474\n","Epoch 31/100\n","10/10 [==============================] - 2s 258ms/step - loss: 3.6796 - accuracy: 0.4344 - val_loss: 4.5569 - val_accuracy: 0.0878\n","Epoch 32/100\n","10/10 [==============================] - 2s 264ms/step - loss: 3.7114 - accuracy: 0.4531 - val_loss: 4.6882 - val_accuracy: 0.0527\n","Epoch 33/100\n","10/10 [==============================] - 2s 263ms/step - loss: 3.6599 - accuracy: 0.4219 - val_loss: 4.9956 - val_accuracy: 0.0467\n","Epoch 34/100\n","10/10 [==============================] - 2s 259ms/step - loss: 3.7753 - accuracy: 0.4406 - val_loss: 4.7925 - val_accuracy: 0.0599\n","Epoch 35/100\n","10/10 [==============================] - 2s 263ms/step - loss: 3.6112 - accuracy: 0.4844 - val_loss: 4.4462 - val_accuracy: 0.0904\n","Epoch 36/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.7203 - accuracy: 0.4469 - val_loss: 4.4879 - val_accuracy: 0.0966\n","Epoch 37/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.5718 - accuracy: 0.4812 - val_loss: 4.4606 - val_accuracy: 0.0969\n","Epoch 38/100\n","10/10 [==============================] - 2s 256ms/step - loss: 3.6114 - accuracy: 0.4656 - val_loss: 4.3525 - val_accuracy: 0.1271\n","Epoch 39/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.5844 - accuracy: 0.5031 - val_loss: 4.1724 - val_accuracy: 0.1995\n","Epoch 40/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.4681 - accuracy: 0.4719 - val_loss: 4.3818 - val_accuracy: 0.1281\n","Epoch 41/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.4968 - accuracy: 0.5000 - val_loss: 4.3173 - val_accuracy: 0.1279\n","Epoch 42/100\n","10/10 [==============================] - 2s 260ms/step - loss: 3.4548 - accuracy: 0.5125 - val_loss: 4.3773 - val_accuracy: 0.1418\n","Epoch 43/100\n","10/10 [==============================] - 2s 262ms/step - loss: 3.5119 - accuracy: 0.4781 - val_loss: 4.2952 - val_accuracy: 0.1411\n","Epoch 44/100\n","10/10 [==============================] - 2s 259ms/step - loss: 3.3393 - accuracy: 0.5156 - val_loss: 4.2104 - val_accuracy: 0.1478\n","Epoch 45/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.4489 - accuracy: 0.4719 - val_loss: 4.2053 - val_accuracy: 0.2239\n","Epoch 46/100\n","10/10 [==============================] - 2s 260ms/step - loss: 3.4517 - accuracy: 0.4969 - val_loss: 4.3381 - val_accuracy: 0.1456\n","Epoch 47/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.3290 - accuracy: 0.5344 - val_loss: 4.1844 - val_accuracy: 0.1654\n","Epoch 48/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.4293 - accuracy: 0.5312 - val_loss: 4.2233 - val_accuracy: 0.1912\n","Epoch 49/100\n","10/10 [==============================] - 2s 260ms/step - loss: 3.3030 - accuracy: 0.5312 - val_loss: 4.1880 - val_accuracy: 0.2105\n","Epoch 50/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.2625 - accuracy: 0.5688 - val_loss: 4.1294 - val_accuracy: 0.2298\n","Epoch 51/100\n","10/10 [==============================] - 2s 263ms/step - loss: 3.2513 - accuracy: 0.5813 - val_loss: 4.1696 - val_accuracy: 0.2374\n","Epoch 52/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.3336 - accuracy: 0.5688 - val_loss: 4.2940 - val_accuracy: 0.1977\n","Epoch 53/100\n","10/10 [==============================] - 2s 263ms/step - loss: 3.3322 - accuracy: 0.5375 - val_loss: 4.1214 - val_accuracy: 0.2403\n","Epoch 54/100\n","10/10 [==============================] - 2s 258ms/step - loss: 3.2013 - accuracy: 0.6000 - val_loss: 4.2227 - val_accuracy: 0.2088\n","Epoch 55/100\n","10/10 [==============================] - 2s 260ms/step - loss: 3.1475 - accuracy: 0.6156 - val_loss: 4.1489 - val_accuracy: 0.2193\n","Epoch 56/100\n","10/10 [==============================] - 2s 259ms/step - loss: 3.1767 - accuracy: 0.5906 - val_loss: 4.1745 - val_accuracy: 0.2292\n","Epoch 57/100\n","10/10 [==============================] - 2s 262ms/step - loss: 3.1800 - accuracy: 0.5719 - val_loss: 4.1261 - val_accuracy: 0.2397\n","Epoch 58/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.9457 - accuracy: 0.6375 - val_loss: 3.9800 - val_accuracy: 0.2364\n","Epoch 59/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.8870 - accuracy: 0.6531 - val_loss: 3.9894 - val_accuracy: 0.2334\n","Epoch 60/100\n","10/10 [==============================] - 3s 292ms/step - loss: 2.9315 - accuracy: 0.6000 - val_loss: 4.0969 - val_accuracy: 0.2182\n","Epoch 61/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.9635 - accuracy: 0.6156 - val_loss: 4.0435 - val_accuracy: 0.2320\n","Epoch 62/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.8297 - accuracy: 0.6562 - val_loss: 3.9938 - val_accuracy: 0.2572\n","Epoch 63/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.7773 - accuracy: 0.6594 - val_loss: 3.9829 - val_accuracy: 0.2322\n","Epoch 64/100\n","10/10 [==============================] - 2s 259ms/step - loss: 2.7869 - accuracy: 0.6438 - val_loss: 3.9784 - val_accuracy: 0.2422\n","Epoch 65/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.7141 - accuracy: 0.6781 - val_loss: 4.0139 - val_accuracy: 0.2331\n","Epoch 66/100\n","10/10 [==============================] - 2s 256ms/step - loss: 2.7502 - accuracy: 0.6406 - val_loss: 4.0528 - val_accuracy: 0.2271\n","Epoch 67/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.7904 - accuracy: 0.6469 - val_loss: 3.9638 - val_accuracy: 0.2918\n","Epoch 68/100\n","10/10 [==============================] - 3s 292ms/step - loss: 2.8774 - accuracy: 0.6313 - val_loss: 4.0563 - val_accuracy: 0.2519\n","Epoch 69/100\n","10/10 [==============================] - 2s 275ms/step - loss: 2.6939 - accuracy: 0.7000 - val_loss: 4.0050 - val_accuracy: 0.2667\n","Epoch 70/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6841 - accuracy: 0.6906 - val_loss: 4.1624 - val_accuracy: 0.2555\n","Epoch 71/100\n","10/10 [==============================] - 2s 274ms/step - loss: 2.7020 - accuracy: 0.6625 - val_loss: 4.0259 - val_accuracy: 0.2566\n","Epoch 72/100\n","10/10 [==============================] - 3s 280ms/step - loss: 2.6661 - accuracy: 0.7000 - val_loss: 4.0681 - val_accuracy: 0.2563\n","Epoch 73/100\n","10/10 [==============================] - 2s 263ms/step - loss: 2.6569 - accuracy: 0.6844 - val_loss: 4.1486 - val_accuracy: 0.1973\n","Epoch 74/100\n","10/10 [==============================] - 2s 261ms/step - loss: 2.5050 - accuracy: 0.7125 - val_loss: 4.1305 - val_accuracy: 0.2098\n","Epoch 75/100\n","10/10 [==============================] - 2s 262ms/step - loss: 2.5059 - accuracy: 0.7250 - val_loss: 4.0307 - val_accuracy: 0.2380\n","Epoch 76/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4249 - accuracy: 0.7531 - val_loss: 4.0185 - val_accuracy: 0.2137\n","Epoch 77/100\n","10/10 [==============================] - 2s 263ms/step - loss: 2.3838 - accuracy: 0.7719 - val_loss: 4.0116 - val_accuracy: 0.2341\n","Epoch 78/100\n","10/10 [==============================] - 2s 262ms/step - loss: 2.3845 - accuracy: 0.7656 - val_loss: 4.2210 - val_accuracy: 0.1875\n","Epoch 79/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3795 - accuracy: 0.7656 - val_loss: 4.0593 - val_accuracy: 0.2285\n","Epoch 80/100\n","10/10 [==============================] - 2s 263ms/step - loss: 2.3914 - accuracy: 0.7719 - val_loss: 4.1231 - val_accuracy: 0.2324\n","Epoch 81/100\n","10/10 [==============================] - 2s 261ms/step - loss: 2.4488 - accuracy: 0.7406 - val_loss: 4.3324 - val_accuracy: 0.1935\n","Epoch 82/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4594 - accuracy: 0.7594 - val_loss: 4.2288 - val_accuracy: 0.2336\n","Epoch 83/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2694 - accuracy: 0.8125 - val_loss: 4.1890 - val_accuracy: 0.2076\n","Epoch 84/100\n","10/10 [==============================] - 2s 260ms/step - loss: 2.2810 - accuracy: 0.7844 - val_loss: 4.3120 - val_accuracy: 0.1905\n","Epoch 85/100\n","10/10 [==============================] - 2s 264ms/step - loss: 2.2819 - accuracy: 0.7969 - val_loss: 4.1976 - val_accuracy: 0.2070\n","Epoch 86/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2317 - accuracy: 0.8156 - val_loss: 4.0290 - val_accuracy: 0.2598\n","Epoch 87/100\n","10/10 [==============================] - 2s 265ms/step - loss: 2.1867 - accuracy: 0.8031 - val_loss: 4.2468 - val_accuracy: 0.1860\n","Epoch 88/100\n","10/10 [==============================] - 2s 262ms/step - loss: 2.2675 - accuracy: 0.7750 - val_loss: 4.1823 - val_accuracy: 0.2442\n","Epoch 89/100\n","10/10 [==============================] - 3s 292ms/step - loss: 2.2413 - accuracy: 0.7937 - val_loss: 4.3129 - val_accuracy: 0.2011\n","Epoch 90/100\n","10/10 [==============================] - 2s 260ms/step - loss: 2.1239 - accuracy: 0.8500 - val_loss: 4.1442 - val_accuracy: 0.2276\n","Epoch 91/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1442 - accuracy: 0.8438 - val_loss: 4.2048 - val_accuracy: 0.2133\n","Epoch 92/100\n","10/10 [==============================] - 2s 260ms/step - loss: 2.0803 - accuracy: 0.8188 - val_loss: 4.2601 - val_accuracy: 0.2060\n","Epoch 93/100\n","10/10 [==============================] - 2s 264ms/step - loss: 2.0910 - accuracy: 0.8562 - val_loss: 4.1892 - val_accuracy: 0.2165\n","Epoch 94/100\n","10/10 [==============================] - 2s 263ms/step - loss: 2.1230 - accuracy: 0.8219 - val_loss: 4.4030 - val_accuracy: 0.1930\n","Epoch 95/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1540 - accuracy: 0.8375 - val_loss: 4.2982 - val_accuracy: 0.2243\n","Epoch 96/100\n","10/10 [==============================] - 3s 291ms/step - loss: 2.0581 - accuracy: 0.8562 - val_loss: 4.2539 - val_accuracy: 0.2084\n","Epoch 97/100\n","10/10 [==============================] - 3s 291ms/step - loss: 1.9875 - accuracy: 0.8594 - val_loss: 4.0756 - val_accuracy: 0.2336\n","Epoch 98/100\n","10/10 [==============================] - 3s 292ms/step - loss: 1.9424 - accuracy: 0.8750 - val_loss: 4.1511 - val_accuracy: 0.2232\n","Epoch 99/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0089 - accuracy: 0.8562 - val_loss: 4.4665 - val_accuracy: 0.1769\n","Epoch 100/100\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0702 - accuracy: 0.8375 - val_loss: 4.4039 - val_accuracy: 0.1997\n"]}]},{"cell_type":"code","source":["# maybe dropout makes a difference\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          layers.Dropout(0.4),\n","          layers.Dense(520,kernel_initializer='lecun_normal',kernel_regularizer='l1'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(8,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=100, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ExTieBe2gGz","executionInfo":{"status":"ok","timestamp":1652033481803,"user_tz":240,"elapsed":263394,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"ec6e477e-e839-4fa8-8f23-1baf30fadad3"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","10/10 [==============================] - 4s 307ms/step - loss: 91.3345 - accuracy: 0.1125 - val_loss: 142.0910 - val_accuracy: 0.0564\n","Epoch 2/100\n","10/10 [==============================] - 3s 290ms/step - loss: 72.1185 - accuracy: 0.2000 - val_loss: 97.7510 - val_accuracy: 0.0564\n","Epoch 3/100\n","10/10 [==============================] - 3s 290ms/step - loss: 55.7825 - accuracy: 0.2375 - val_loss: 68.9922 - val_accuracy: 0.0565\n","Epoch 4/100\n","10/10 [==============================] - 3s 290ms/step - loss: 42.2298 - accuracy: 0.2937 - val_loss: 49.8858 - val_accuracy: 0.0565\n","Epoch 5/100\n","10/10 [==============================] - 2s 267ms/step - loss: 31.4682 - accuracy: 0.3063 - val_loss: 35.9525 - val_accuracy: 0.0517\n","Epoch 6/100\n","10/10 [==============================] - 3s 291ms/step - loss: 23.3935 - accuracy: 0.3094 - val_loss: 25.3103 - val_accuracy: 0.0472\n","Epoch 7/100\n","10/10 [==============================] - 3s 290ms/step - loss: 17.3160 - accuracy: 0.3625 - val_loss: 17.8044 - val_accuracy: 0.1987\n","Epoch 8/100\n","10/10 [==============================] - 2s 262ms/step - loss: 13.0133 - accuracy: 0.3719 - val_loss: 13.4070 - val_accuracy: 0.0575\n","Epoch 9/100\n","10/10 [==============================] - 2s 267ms/step - loss: 9.9640 - accuracy: 0.3438 - val_loss: 10.6529 - val_accuracy: 0.0597\n","Epoch 10/100\n","10/10 [==============================] - 3s 290ms/step - loss: 8.0378 - accuracy: 0.3313 - val_loss: 8.2917 - val_accuracy: 0.1495\n","Epoch 11/100\n","10/10 [==============================] - 2s 265ms/step - loss: 6.5620 - accuracy: 0.3844 - val_loss: 8.1569 - val_accuracy: 0.0085\n","Epoch 12/100\n","10/10 [==============================] - 3s 290ms/step - loss: 5.8779 - accuracy: 0.3406 - val_loss: 6.4385 - val_accuracy: 0.0709\n","Epoch 13/100\n","10/10 [==============================] - 3s 290ms/step - loss: 5.1829 - accuracy: 0.3219 - val_loss: 5.9953 - val_accuracy: 0.0469\n","Epoch 14/100\n","10/10 [==============================] - 3s 291ms/step - loss: 5.1414 - accuracy: 0.3344 - val_loss: 5.2108 - val_accuracy: 0.2747\n","Epoch 15/100\n","10/10 [==============================] - 2s 264ms/step - loss: 4.8685 - accuracy: 0.2969 - val_loss: 5.9365 - val_accuracy: 0.1174\n","Epoch 16/100\n","10/10 [==============================] - 2s 265ms/step - loss: 4.8855 - accuracy: 0.3562 - val_loss: 5.2085 - val_accuracy: 0.2866\n","Epoch 17/100\n","10/10 [==============================] - 2s 270ms/step - loss: 4.7559 - accuracy: 0.2969 - val_loss: 5.2204 - val_accuracy: 0.2141\n","Epoch 18/100\n","10/10 [==============================] - 2s 263ms/step - loss: 4.6141 - accuracy: 0.3250 - val_loss: 5.1393 - val_accuracy: 0.2134\n","Epoch 19/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.5469 - accuracy: 0.3469 - val_loss: 5.0230 - val_accuracy: 0.2181\n","Epoch 20/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.5595 - accuracy: 0.3250 - val_loss: 5.7441 - val_accuracy: 0.0559\n","Epoch 21/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.5498 - accuracy: 0.3531 - val_loss: 5.1927 - val_accuracy: 0.1242\n","Epoch 22/100\n","10/10 [==============================] - 3s 283ms/step - loss: 4.6055 - accuracy: 0.3500 - val_loss: 5.1067 - val_accuracy: 0.1417\n","Epoch 23/100\n","10/10 [==============================] - 3s 282ms/step - loss: 4.5647 - accuracy: 0.3125 - val_loss: 4.9970 - val_accuracy: 0.0355\n","Epoch 24/100\n","10/10 [==============================] - 2s 268ms/step - loss: 4.5241 - accuracy: 0.3125 - val_loss: 4.9173 - val_accuracy: 0.2849\n","Epoch 25/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.5017 - accuracy: 0.3594 - val_loss: 4.9436 - val_accuracy: 0.0596\n","Epoch 26/100\n","10/10 [==============================] - 2s 265ms/step - loss: 4.4076 - accuracy: 0.3313 - val_loss: 4.8057 - val_accuracy: 0.0859\n","Epoch 27/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.3696 - accuracy: 0.3250 - val_loss: 5.0066 - val_accuracy: 0.1419\n","Epoch 28/100\n","10/10 [==============================] - 2s 266ms/step - loss: 4.4541 - accuracy: 0.3187 - val_loss: 4.8087 - val_accuracy: 0.1571\n","Epoch 29/100\n","10/10 [==============================] - 2s 271ms/step - loss: 4.4212 - accuracy: 0.3406 - val_loss: 4.6588 - val_accuracy: 0.3242\n","Epoch 30/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.5034 - accuracy: 0.2906 - val_loss: 4.7319 - val_accuracy: 0.2034\n","Epoch 31/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.2022 - accuracy: 0.3469 - val_loss: 4.7315 - val_accuracy: 0.1666\n","Epoch 32/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.3928 - accuracy: 0.3500 - val_loss: 4.7145 - val_accuracy: 0.2391\n","Epoch 33/100\n","10/10 [==============================] - 2s 265ms/step - loss: 4.2711 - accuracy: 0.3594 - val_loss: 4.9109 - val_accuracy: 0.0831\n","Epoch 34/100\n","10/10 [==============================] - 2s 265ms/step - loss: 4.3842 - accuracy: 0.3781 - val_loss: 4.9608 - val_accuracy: 0.1055\n","Epoch 35/100\n","10/10 [==============================] - 2s 267ms/step - loss: 4.2708 - accuracy: 0.4062 - val_loss: 4.6001 - val_accuracy: 0.2062\n","Epoch 36/100\n","10/10 [==============================] - 2s 271ms/step - loss: 4.3157 - accuracy: 0.3625 - val_loss: 4.8866 - val_accuracy: 0.1350\n","Epoch 37/100\n","10/10 [==============================] - 2s 267ms/step - loss: 4.3874 - accuracy: 0.3906 - val_loss: 4.6875 - val_accuracy: 0.2480\n","Epoch 38/100\n","10/10 [==============================] - 2s 261ms/step - loss: 4.1354 - accuracy: 0.3781 - val_loss: 4.8457 - val_accuracy: 0.0811\n","Epoch 39/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.3841 - accuracy: 0.3656 - val_loss: 4.7834 - val_accuracy: 0.1682\n","Epoch 40/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.1868 - accuracy: 0.3938 - val_loss: 4.6254 - val_accuracy: 0.2202\n","Epoch 41/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.2748 - accuracy: 0.3938 - val_loss: 4.5973 - val_accuracy: 0.2768\n","Epoch 42/100\n","10/10 [==============================] - 2s 262ms/step - loss: 4.1493 - accuracy: 0.4062 - val_loss: 4.5755 - val_accuracy: 0.2588\n","Epoch 43/100\n","10/10 [==============================] - 2s 267ms/step - loss: 4.3351 - accuracy: 0.3875 - val_loss: 4.6851 - val_accuracy: 0.2426\n","Epoch 44/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.1415 - accuracy: 0.3469 - val_loss: 4.6670 - val_accuracy: 0.1789\n","Epoch 45/100\n","10/10 [==============================] - 2s 264ms/step - loss: 4.2271 - accuracy: 0.3750 - val_loss: 4.5119 - val_accuracy: 0.2615\n","Epoch 46/100\n","10/10 [==============================] - 2s 274ms/step - loss: 4.1069 - accuracy: 0.3812 - val_loss: 4.6449 - val_accuracy: 0.2222\n","Epoch 47/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.2692 - accuracy: 0.3375 - val_loss: 4.6204 - val_accuracy: 0.2146\n","Epoch 48/100\n","10/10 [==============================] - 2s 263ms/step - loss: 4.0985 - accuracy: 0.3906 - val_loss: 4.5314 - val_accuracy: 0.2528\n","Epoch 49/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.1250 - accuracy: 0.3781 - val_loss: 4.5466 - val_accuracy: 0.2261\n","Epoch 50/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.0990 - accuracy: 0.4125 - val_loss: 4.5476 - val_accuracy: 0.2617\n","Epoch 51/100\n","10/10 [==============================] - 2s 270ms/step - loss: 3.9477 - accuracy: 0.4187 - val_loss: 4.5621 - val_accuracy: 0.2059\n","Epoch 52/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.0460 - accuracy: 0.4000 - val_loss: 4.5204 - val_accuracy: 0.3087\n","Epoch 53/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.0727 - accuracy: 0.4000 - val_loss: 4.6620 - val_accuracy: 0.1673\n","Epoch 54/100\n","10/10 [==============================] - 2s 262ms/step - loss: 4.0039 - accuracy: 0.4281 - val_loss: 4.5292 - val_accuracy: 0.2466\n","Epoch 55/100\n","10/10 [==============================] - 2s 263ms/step - loss: 4.0376 - accuracy: 0.3875 - val_loss: 4.4602 - val_accuracy: 0.2284\n","Epoch 56/100\n","10/10 [==============================] - 2s 262ms/step - loss: 4.0162 - accuracy: 0.3969 - val_loss: 4.6353 - val_accuracy: 0.1922\n","Epoch 57/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.0507 - accuracy: 0.4219 - val_loss: 4.5551 - val_accuracy: 0.2912\n","Epoch 58/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.0033 - accuracy: 0.4500 - val_loss: 4.4701 - val_accuracy: 0.2376\n","Epoch 59/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.9085 - accuracy: 0.4531 - val_loss: 4.5491 - val_accuracy: 0.2153\n","Epoch 60/100\n","10/10 [==============================] - 2s 265ms/step - loss: 3.9867 - accuracy: 0.4437 - val_loss: 4.5277 - val_accuracy: 0.2535\n","Epoch 61/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.9180 - accuracy: 0.4563 - val_loss: 4.3723 - val_accuracy: 0.3078\n","Epoch 62/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.9266 - accuracy: 0.3969 - val_loss: 4.4674 - val_accuracy: 0.2662\n","Epoch 63/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.9360 - accuracy: 0.4125 - val_loss: 4.3619 - val_accuracy: 0.3087\n","Epoch 64/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.8491 - accuracy: 0.4469 - val_loss: 4.4813 - val_accuracy: 0.2240\n","Epoch 65/100\n","10/10 [==============================] - 2s 268ms/step - loss: 3.8277 - accuracy: 0.4250 - val_loss: 4.3629 - val_accuracy: 0.2927\n","Epoch 66/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.8955 - accuracy: 0.4625 - val_loss: 4.5089 - val_accuracy: 0.2644\n","Epoch 67/100\n","10/10 [==============================] - 2s 262ms/step - loss: 3.9338 - accuracy: 0.4250 - val_loss: 4.4959 - val_accuracy: 0.2436\n","Epoch 68/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.7986 - accuracy: 0.4469 - val_loss: 4.3909 - val_accuracy: 0.2306\n","Epoch 69/100\n","10/10 [==============================] - 2s 270ms/step - loss: 3.9056 - accuracy: 0.4156 - val_loss: 4.5131 - val_accuracy: 0.2749\n","Epoch 70/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.8723 - accuracy: 0.4344 - val_loss: 4.4759 - val_accuracy: 0.2350\n","Epoch 71/100\n","10/10 [==============================] - 2s 269ms/step - loss: 3.8111 - accuracy: 0.4594 - val_loss: 4.4464 - val_accuracy: 0.2309\n","Epoch 72/100\n","10/10 [==============================] - 2s 268ms/step - loss: 3.7765 - accuracy: 0.4531 - val_loss: 4.4882 - val_accuracy: 0.2492\n","Epoch 73/100\n","10/10 [==============================] - 2s 268ms/step - loss: 3.8413 - accuracy: 0.4406 - val_loss: 4.5065 - val_accuracy: 0.2195\n","Epoch 74/100\n","10/10 [==============================] - 2s 270ms/step - loss: 3.7475 - accuracy: 0.4531 - val_loss: 4.4425 - val_accuracy: 0.2391\n","Epoch 75/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.7168 - accuracy: 0.4625 - val_loss: 4.3383 - val_accuracy: 0.2286\n","Epoch 76/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.6509 - accuracy: 0.4781 - val_loss: 4.4206 - val_accuracy: 0.2015\n","Epoch 77/100\n","10/10 [==============================] - 2s 264ms/step - loss: 3.6905 - accuracy: 0.4500 - val_loss: 4.5963 - val_accuracy: 0.2152\n","Epoch 78/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.7750 - accuracy: 0.4750 - val_loss: 4.4354 - val_accuracy: 0.2296\n","Epoch 79/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.6187 - accuracy: 0.4719 - val_loss: 4.3725 - val_accuracy: 0.2368\n","Epoch 80/100\n","10/10 [==============================] - 2s 266ms/step - loss: 3.6230 - accuracy: 0.4375 - val_loss: 4.4957 - val_accuracy: 0.1955\n","Epoch 81/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.6554 - accuracy: 0.4563 - val_loss: 4.3597 - val_accuracy: 0.2743\n","Epoch 82/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.6956 - accuracy: 0.4219 - val_loss: 4.4532 - val_accuracy: 0.2237\n","Epoch 83/100\n","10/10 [==============================] - 2s 274ms/step - loss: 3.6001 - accuracy: 0.5125 - val_loss: 4.3776 - val_accuracy: 0.2425\n","Epoch 84/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.6231 - accuracy: 0.5156 - val_loss: 4.3976 - val_accuracy: 0.2448\n","Epoch 85/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.6140 - accuracy: 0.4844 - val_loss: 4.4140 - val_accuracy: 0.1987\n","Epoch 86/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.4675 - accuracy: 0.5063 - val_loss: 4.3057 - val_accuracy: 0.2215\n","Epoch 87/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.4228 - accuracy: 0.5000 - val_loss: 4.1810 - val_accuracy: 0.2793\n","Epoch 88/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.4444 - accuracy: 0.5469 - val_loss: 4.2214 - val_accuracy: 0.2848\n","Epoch 89/100\n","10/10 [==============================] - 2s 263ms/step - loss: 3.5617 - accuracy: 0.4437 - val_loss: 4.2973 - val_accuracy: 0.2530\n","Epoch 90/100\n","10/10 [==============================] - 2s 268ms/step - loss: 3.3912 - accuracy: 0.5094 - val_loss: 4.2352 - val_accuracy: 0.2524\n","Epoch 91/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.5227 - accuracy: 0.4844 - val_loss: 4.2711 - val_accuracy: 0.2869\n","Epoch 92/100\n","10/10 [==============================] - 2s 266ms/step - loss: 3.4215 - accuracy: 0.5594 - val_loss: 4.3462 - val_accuracy: 0.2609\n","Epoch 93/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.4262 - accuracy: 0.5469 - val_loss: 4.2832 - val_accuracy: 0.2502\n","Epoch 94/100\n","10/10 [==============================] - 2s 270ms/step - loss: 3.4734 - accuracy: 0.5031 - val_loss: 4.3194 - val_accuracy: 0.2967\n","Epoch 95/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.4557 - accuracy: 0.5094 - val_loss: 4.3654 - val_accuracy: 0.2197\n","Epoch 96/100\n","10/10 [==============================] - 2s 274ms/step - loss: 3.5287 - accuracy: 0.5000 - val_loss: 4.4490 - val_accuracy: 0.2399\n","Epoch 97/100\n","10/10 [==============================] - 2s 266ms/step - loss: 3.4637 - accuracy: 0.5031 - val_loss: 4.3596 - val_accuracy: 0.2588\n","Epoch 98/100\n","10/10 [==============================] - 2s 275ms/step - loss: 3.3555 - accuracy: 0.5531 - val_loss: 4.2742 - val_accuracy: 0.2419\n","Epoch 99/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.3180 - accuracy: 0.5344 - val_loss: 4.3756 - val_accuracy: 0.2138\n","Epoch 100/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.4463 - accuracy: 0.5437 - val_loss: 4.2544 - val_accuracy: 0.3024\n"]}]},{"cell_type":"code","source":["# maybe dropout makes a difference\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          layers.Dropout(0.4),\n","          layers.Dense(520,kernel_initializer='lecun_normal',kernel_regularizer='l1',bias_regularizer='l1'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          #layers.Dense(8,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          #layers.BatchNormalization(),\n","          #layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=100, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uaUZ2JTf3-RO","executionInfo":{"status":"ok","timestamp":1652034297020,"user_tz":240,"elapsed":253764,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"5b2c2505-778c-46fb-9757-0d40b2b879f5"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","10/10 [==============================] - 4s 291ms/step - loss: 91.2994 - accuracy: 0.1187 - val_loss: 145.3068 - val_accuracy: 0.0018\n","Epoch 2/100\n","10/10 [==============================] - 3s 289ms/step - loss: 72.6765 - accuracy: 0.3281 - val_loss: 98.0844 - val_accuracy: 0.0278\n","Epoch 3/100\n","10/10 [==============================] - 2s 257ms/step - loss: 57.1016 - accuracy: 0.4469 - val_loss: 76.6164 - val_accuracy: 0.0278\n","Epoch 4/100\n","10/10 [==============================] - 3s 290ms/step - loss: 44.3137 - accuracy: 0.5188 - val_loss: 55.7263 - val_accuracy: 0.0287\n","Epoch 5/100\n","10/10 [==============================] - 3s 290ms/step - loss: 33.8649 - accuracy: 0.6156 - val_loss: 43.5479 - val_accuracy: 0.0475\n","Epoch 6/100\n","10/10 [==============================] - 3s 290ms/step - loss: 25.7644 - accuracy: 0.5844 - val_loss: 36.5957 - val_accuracy: 0.0419\n","Epoch 7/100\n","10/10 [==============================] - 3s 290ms/step - loss: 19.5518 - accuracy: 0.6594 - val_loss: 33.0448 - val_accuracy: 0.0417\n","Epoch 8/100\n","10/10 [==============================] - 3s 290ms/step - loss: 15.0568 - accuracy: 0.6469 - val_loss: 27.9490 - val_accuracy: 0.1857\n","Epoch 9/100\n","10/10 [==============================] - 3s 290ms/step - loss: 12.0503 - accuracy: 0.6531 - val_loss: 23.2171 - val_accuracy: 0.1828\n","Epoch 10/100\n","10/10 [==============================] - 2s 257ms/step - loss: 10.3842 - accuracy: 0.5938 - val_loss: 28.8232 - val_accuracy: 0.0417\n","Epoch 11/100\n","10/10 [==============================] - 3s 289ms/step - loss: 9.4215 - accuracy: 0.5719 - val_loss: 28.6326 - val_accuracy: 0.0418\n","Epoch 12/100\n","10/10 [==============================] - 3s 290ms/step - loss: 9.0557 - accuracy: 0.5375 - val_loss: 28.5129 - val_accuracy: 0.0417\n","Epoch 13/100\n","10/10 [==============================] - 3s 290ms/step - loss: 8.4690 - accuracy: 0.5594 - val_loss: 23.8640 - val_accuracy: 0.0417\n","Epoch 14/100\n","10/10 [==============================] - 2s 257ms/step - loss: 7.7962 - accuracy: 0.6250 - val_loss: 24.0737 - val_accuracy: 0.0417\n","Epoch 15/100\n","10/10 [==============================] - 2s 254ms/step - loss: 7.1653 - accuracy: 0.6438 - val_loss: 20.3283 - val_accuracy: 0.0418\n","Epoch 16/100\n","10/10 [==============================] - 2s 258ms/step - loss: 7.4116 - accuracy: 0.5594 - val_loss: 18.7428 - val_accuracy: 0.0766\n","Epoch 17/100\n","10/10 [==============================] - 2s 256ms/step - loss: 7.1266 - accuracy: 0.6469 - val_loss: 15.5063 - val_accuracy: 0.1037\n","Epoch 18/100\n","10/10 [==============================] - 3s 290ms/step - loss: 6.6459 - accuracy: 0.6469 - val_loss: 13.7652 - val_accuracy: 0.0417\n","Epoch 19/100\n","10/10 [==============================] - 3s 290ms/step - loss: 6.4091 - accuracy: 0.6531 - val_loss: 14.1137 - val_accuracy: 0.0417\n","Epoch 20/100\n","10/10 [==============================] - 2s 255ms/step - loss: 6.3776 - accuracy: 0.6187 - val_loss: 10.4531 - val_accuracy: 0.0734\n","Epoch 21/100\n","10/10 [==============================] - 2s 254ms/step - loss: 6.3525 - accuracy: 0.6313 - val_loss: 12.0613 - val_accuracy: 0.0393\n","Epoch 22/100\n","10/10 [==============================] - 3s 290ms/step - loss: 6.2317 - accuracy: 0.6438 - val_loss: 11.7851 - val_accuracy: 0.1070\n","Epoch 23/100\n","10/10 [==============================] - 2s 258ms/step - loss: 6.0101 - accuracy: 0.6219 - val_loss: 10.9849 - val_accuracy: 0.1623\n","Epoch 24/100\n","10/10 [==============================] - 3s 289ms/step - loss: 6.1774 - accuracy: 0.5938 - val_loss: 11.3168 - val_accuracy: 0.0527\n","Epoch 25/100\n","10/10 [==============================] - 2s 254ms/step - loss: 6.2864 - accuracy: 0.5938 - val_loss: 12.3156 - val_accuracy: 0.0445\n","Epoch 26/100\n","10/10 [==============================] - 3s 290ms/step - loss: 5.9082 - accuracy: 0.6687 - val_loss: 12.4268 - val_accuracy: 0.0437\n","Epoch 27/100\n","10/10 [==============================] - 2s 256ms/step - loss: 5.5970 - accuracy: 0.6781 - val_loss: 9.7108 - val_accuracy: 0.0720\n","Epoch 28/100\n","10/10 [==============================] - 3s 290ms/step - loss: 5.6468 - accuracy: 0.6094 - val_loss: 10.0629 - val_accuracy: 0.0562\n","Epoch 29/100\n","10/10 [==============================] - 2s 260ms/step - loss: 5.8620 - accuracy: 0.6281 - val_loss: 9.8109 - val_accuracy: 0.0867\n","Epoch 30/100\n","10/10 [==============================] - 2s 252ms/step - loss: 5.7360 - accuracy: 0.6062 - val_loss: 8.7098 - val_accuracy: 0.0764\n","Epoch 31/100\n","10/10 [==============================] - 3s 290ms/step - loss: 5.5321 - accuracy: 0.6469 - val_loss: 8.4208 - val_accuracy: 0.0926\n","Epoch 32/100\n","10/10 [==============================] - 3s 290ms/step - loss: 5.3958 - accuracy: 0.6250 - val_loss: 8.4931 - val_accuracy: 0.0603\n","Epoch 33/100\n","10/10 [==============================] - 2s 259ms/step - loss: 5.5554 - accuracy: 0.6406 - val_loss: 8.5786 - val_accuracy: 0.0849\n","Epoch 34/100\n","10/10 [==============================] - 2s 257ms/step - loss: 5.7379 - accuracy: 0.6094 - val_loss: 7.7967 - val_accuracy: 0.1310\n","Epoch 35/100\n","10/10 [==============================] - 3s 290ms/step - loss: 5.5461 - accuracy: 0.6156 - val_loss: 8.4648 - val_accuracy: 0.1303\n","Epoch 36/100\n","10/10 [==============================] - 2s 250ms/step - loss: 5.4737 - accuracy: 0.6438 - val_loss: 8.8323 - val_accuracy: 0.0732\n","Epoch 37/100\n","10/10 [==============================] - 3s 290ms/step - loss: 5.1556 - accuracy: 0.6781 - val_loss: 7.8519 - val_accuracy: 0.1230\n","Epoch 38/100\n","10/10 [==============================] - 3s 290ms/step - loss: 5.0118 - accuracy: 0.6531 - val_loss: 7.2875 - val_accuracy: 0.1055\n","Epoch 39/100\n","10/10 [==============================] - 3s 290ms/step - loss: 5.0568 - accuracy: 0.6531 - val_loss: 7.1291 - val_accuracy: 0.1352\n","Epoch 40/100\n","10/10 [==============================] - 2s 250ms/step - loss: 5.0514 - accuracy: 0.6500 - val_loss: 6.7902 - val_accuracy: 0.2424\n","Epoch 41/100\n","10/10 [==============================] - 3s 291ms/step - loss: 5.1123 - accuracy: 0.6625 - val_loss: 6.7503 - val_accuracy: 0.2021\n","Epoch 42/100\n","10/10 [==============================] - 3s 302ms/step - loss: 4.9342 - accuracy: 0.6938 - val_loss: 6.3681 - val_accuracy: 0.2651\n","Epoch 43/100\n","10/10 [==============================] - 2s 259ms/step - loss: 4.9801 - accuracy: 0.6156 - val_loss: 6.6141 - val_accuracy: 0.2211\n","Epoch 44/100\n","10/10 [==============================] - 2s 258ms/step - loss: 4.9302 - accuracy: 0.6531 - val_loss: 6.2186 - val_accuracy: 0.3179\n","Epoch 45/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.9626 - accuracy: 0.6469 - val_loss: 6.2761 - val_accuracy: 0.3089\n","Epoch 46/100\n","10/10 [==============================] - 2s 259ms/step - loss: 4.8299 - accuracy: 0.6781 - val_loss: 6.2838 - val_accuracy: 0.2677\n","Epoch 47/100\n","10/10 [==============================] - 5s 574ms/step - loss: 4.9542 - accuracy: 0.6406 - val_loss: 6.4767 - val_accuracy: 0.2676\n","Epoch 48/100\n","10/10 [==============================] - 3s 315ms/step - loss: 4.9754 - accuracy: 0.6375 - val_loss: 6.5272 - val_accuracy: 0.2771\n","Epoch 49/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.8999 - accuracy: 0.7000 - val_loss: 6.8466 - val_accuracy: 0.2252\n","Epoch 50/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.8551 - accuracy: 0.6344 - val_loss: 6.3946 - val_accuracy: 0.2795\n","Epoch 51/100\n","10/10 [==============================] - 2s 254ms/step - loss: 4.7020 - accuracy: 0.6750 - val_loss: 6.1722 - val_accuracy: 0.3019\n","Epoch 52/100\n","10/10 [==============================] - 2s 255ms/step - loss: 4.5550 - accuracy: 0.7094 - val_loss: 6.0830 - val_accuracy: 0.2793\n","Epoch 53/100\n","10/10 [==============================] - 2s 255ms/step - loss: 4.6560 - accuracy: 0.6969 - val_loss: 6.2602 - val_accuracy: 0.2707\n","Epoch 54/100\n","10/10 [==============================] - 2s 254ms/step - loss: 4.5343 - accuracy: 0.6938 - val_loss: 5.9992 - val_accuracy: 0.3119\n","Epoch 55/100\n","10/10 [==============================] - 3s 289ms/step - loss: 4.6884 - accuracy: 0.6406 - val_loss: 6.3789 - val_accuracy: 0.2531\n","Epoch 56/100\n","10/10 [==============================] - 2s 256ms/step - loss: 4.5879 - accuracy: 0.6844 - val_loss: 6.0177 - val_accuracy: 0.3321\n","Epoch 57/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.2654 - accuracy: 0.7375 - val_loss: 5.8855 - val_accuracy: 0.2897\n","Epoch 58/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.4109 - accuracy: 0.6969 - val_loss: 6.1522 - val_accuracy: 0.2559\n","Epoch 59/100\n","10/10 [==============================] - 2s 252ms/step - loss: 4.5518 - accuracy: 0.6438 - val_loss: 6.6065 - val_accuracy: 0.2294\n","Epoch 60/100\n","10/10 [==============================] - 2s 254ms/step - loss: 4.6571 - accuracy: 0.6594 - val_loss: 6.1314 - val_accuracy: 0.3671\n","Epoch 61/100\n","10/10 [==============================] - 2s 251ms/step - loss: 4.6626 - accuracy: 0.6438 - val_loss: 6.2721 - val_accuracy: 0.2889\n","Epoch 62/100\n","10/10 [==============================] - 2s 259ms/step - loss: 4.4724 - accuracy: 0.7063 - val_loss: 6.1895 - val_accuracy: 0.3028\n","Epoch 63/100\n","10/10 [==============================] - 3s 289ms/step - loss: 4.4501 - accuracy: 0.6562 - val_loss: 6.3913 - val_accuracy: 0.2363\n","Epoch 64/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.3049 - accuracy: 0.7219 - val_loss: 6.2164 - val_accuracy: 0.2996\n","Epoch 65/100\n","10/10 [==============================] - 3s 289ms/step - loss: 4.5269 - accuracy: 0.6406 - val_loss: 6.1240 - val_accuracy: 0.2956\n","Epoch 66/100\n","10/10 [==============================] - 2s 251ms/step - loss: 4.2689 - accuracy: 0.7094 - val_loss: 6.2691 - val_accuracy: 0.2543\n","Epoch 67/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.2807 - accuracy: 0.7094 - val_loss: 6.0773 - val_accuracy: 0.2910\n","Epoch 68/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.2586 - accuracy: 0.6781 - val_loss: 6.1942 - val_accuracy: 0.2948\n","Epoch 69/100\n","10/10 [==============================] - 2s 255ms/step - loss: 4.2983 - accuracy: 0.6781 - val_loss: 6.0212 - val_accuracy: 0.3035\n","Epoch 70/100\n","10/10 [==============================] - 2s 256ms/step - loss: 4.1026 - accuracy: 0.7312 - val_loss: 5.9796 - val_accuracy: 0.2642\n","Epoch 71/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.0375 - accuracy: 0.7250 - val_loss: 5.7885 - val_accuracy: 0.3276\n","Epoch 72/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.2385 - accuracy: 0.6812 - val_loss: 5.9762 - val_accuracy: 0.2956\n","Epoch 73/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.1901 - accuracy: 0.6875 - val_loss: 6.1111 - val_accuracy: 0.2675\n","Epoch 74/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.3112 - accuracy: 0.6781 - val_loss: 6.2957 - val_accuracy: 0.2738\n","Epoch 75/100\n","10/10 [==============================] - 2s 252ms/step - loss: 4.0566 - accuracy: 0.7719 - val_loss: 5.9381 - val_accuracy: 0.3093\n","Epoch 76/100\n","10/10 [==============================] - 2s 263ms/step - loss: 3.8605 - accuracy: 0.7594 - val_loss: 5.8877 - val_accuracy: 0.2705\n","Epoch 77/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.7767 - accuracy: 0.7219 - val_loss: 5.7443 - val_accuracy: 0.2705\n","Epoch 78/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.7590 - accuracy: 0.7344 - val_loss: 5.8760 - val_accuracy: 0.2720\n","Epoch 79/100\n","10/10 [==============================] - 2s 255ms/step - loss: 3.9648 - accuracy: 0.7094 - val_loss: 5.9786 - val_accuracy: 0.3114\n","Epoch 80/100\n","10/10 [==============================] - 3s 289ms/step - loss: 4.1451 - accuracy: 0.6781 - val_loss: 6.3309 - val_accuracy: 0.2349\n","Epoch 81/100\n","10/10 [==============================] - 2s 256ms/step - loss: 4.0920 - accuracy: 0.7156 - val_loss: 6.0785 - val_accuracy: 0.2796\n","Epoch 82/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.7597 - accuracy: 0.7594 - val_loss: 5.6238 - val_accuracy: 0.3151\n","Epoch 83/100\n","10/10 [==============================] - 2s 252ms/step - loss: 3.6574 - accuracy: 0.7469 - val_loss: 5.9822 - val_accuracy: 0.2394\n","Epoch 84/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.8214 - accuracy: 0.6969 - val_loss: 5.7688 - val_accuracy: 0.3004\n","Epoch 85/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.9029 - accuracy: 0.7031 - val_loss: 6.3368 - val_accuracy: 0.2152\n","Epoch 86/100\n","10/10 [==============================] - 3s 289ms/step - loss: 4.0626 - accuracy: 0.6656 - val_loss: 5.9876 - val_accuracy: 0.3565\n","Epoch 87/100\n","10/10 [==============================] - 2s 256ms/step - loss: 4.2064 - accuracy: 0.6656 - val_loss: 6.7758 - val_accuracy: 0.2071\n","Epoch 88/100\n","10/10 [==============================] - 2s 262ms/step - loss: 4.1563 - accuracy: 0.7063 - val_loss: 5.8928 - val_accuracy: 0.3658\n","Epoch 89/100\n","10/10 [==============================] - 2s 257ms/step - loss: 3.9844 - accuracy: 0.7406 - val_loss: 6.2704 - val_accuracy: 0.2295\n","Epoch 90/100\n","10/10 [==============================] - 2s 255ms/step - loss: 3.8654 - accuracy: 0.7125 - val_loss: 5.6840 - val_accuracy: 0.3401\n","Epoch 91/100\n","10/10 [==============================] - 3s 304ms/step - loss: 3.9120 - accuracy: 0.7312 - val_loss: 6.0225 - val_accuracy: 0.2470\n","Epoch 92/100\n","10/10 [==============================] - 3s 289ms/step - loss: 3.8733 - accuracy: 0.6906 - val_loss: 5.9209 - val_accuracy: 0.2892\n","Epoch 93/100\n","10/10 [==============================] - 2s 262ms/step - loss: 3.9304 - accuracy: 0.6844 - val_loss: 6.3026 - val_accuracy: 0.2134\n","Epoch 94/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.8167 - accuracy: 0.7344 - val_loss: 5.7743 - val_accuracy: 0.3169\n","Epoch 95/100\n","10/10 [==============================] - 2s 255ms/step - loss: 3.6972 - accuracy: 0.7563 - val_loss: 5.9293 - val_accuracy: 0.2422\n","Epoch 96/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.7799 - accuracy: 0.7000 - val_loss: 5.7530 - val_accuracy: 0.3414\n","Epoch 97/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.6967 - accuracy: 0.7656 - val_loss: 5.8374 - val_accuracy: 0.2731\n","Epoch 98/100\n","10/10 [==============================] - 2s 260ms/step - loss: 3.7528 - accuracy: 0.7219 - val_loss: 5.8464 - val_accuracy: 0.2899\n","Epoch 99/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.7273 - accuracy: 0.7406 - val_loss: 5.9650 - val_accuracy: 0.2633\n","Epoch 100/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.6252 - accuracy: 0.7531 - val_loss: 6.0763 - val_accuracy: 0.2457\n"]}]},{"cell_type":"code","source":["# maybe dropout makes a difference\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          layers.Dropout(0.4),\n","          layers.Dense(520,kernel_initializer='lecun_normal',kernel_regularizer='l1',bias_regularizer='l1'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(4,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=100, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kVkeQuhq6Ish","executionInfo":{"status":"ok","timestamp":1652034626284,"user_tz":240,"elapsed":262509,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"f5c07382-f123-4c19-80a2-57b7eaffcf54"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","10/10 [==============================] - 4s 328ms/step - loss: 90.6921 - accuracy: 0.0750 - val_loss: 133.5139 - val_accuracy: 8.1182e-05\n","Epoch 2/100\n","10/10 [==============================] - 2s 265ms/step - loss: 70.8027 - accuracy: 0.1562 - val_loss: 89.8773 - val_accuracy: 8.1182e-05\n","Epoch 3/100\n","10/10 [==============================] - 2s 268ms/step - loss: 53.9776 - accuracy: 0.1437 - val_loss: 64.3433 - val_accuracy: 8.1182e-05\n","Epoch 4/100\n","10/10 [==============================] - 3s 290ms/step - loss: 40.2068 - accuracy: 0.1813 - val_loss: 48.5809 - val_accuracy: 8.1182e-05\n","Epoch 5/100\n","10/10 [==============================] - 3s 290ms/step - loss: 29.5256 - accuracy: 0.2031 - val_loss: 35.2770 - val_accuracy: 8.1182e-05\n","Epoch 6/100\n","10/10 [==============================] - 2s 270ms/step - loss: 21.4615 - accuracy: 0.2031 - val_loss: 22.4706 - val_accuracy: 0.0614\n","Epoch 7/100\n","10/10 [==============================] - 3s 290ms/step - loss: 15.6559 - accuracy: 0.1813 - val_loss: 19.4678 - val_accuracy: 1.2177e-04\n","Epoch 8/100\n","10/10 [==============================] - 2s 269ms/step - loss: 11.4278 - accuracy: 0.2250 - val_loss: 14.7105 - val_accuracy: 0.0015\n","Epoch 9/100\n","10/10 [==============================] - 3s 290ms/step - loss: 8.6398 - accuracy: 0.1750 - val_loss: 11.3884 - val_accuracy: 0.1826\n","Epoch 10/100\n","10/10 [==============================] - 2s 266ms/step - loss: 6.9124 - accuracy: 0.1906 - val_loss: 7.0641 - val_accuracy: 2.8414e-04\n","Epoch 11/100\n","10/10 [==============================] - 2s 267ms/step - loss: 5.6664 - accuracy: 0.1625 - val_loss: 6.1181 - val_accuracy: 0.0104\n","Epoch 12/100\n","10/10 [==============================] - 3s 291ms/step - loss: 5.1018 - accuracy: 0.1937 - val_loss: 5.6091 - val_accuracy: 1.6236e-04\n","Epoch 13/100\n","10/10 [==============================] - 2s 274ms/step - loss: 4.6711 - accuracy: 0.1906 - val_loss: 5.2644 - val_accuracy: 4.4650e-04\n","Epoch 14/100\n","10/10 [==============================] - 3s 293ms/step - loss: 4.6282 - accuracy: 0.1719 - val_loss: 5.2672 - val_accuracy: 0.0261\n","Epoch 15/100\n","10/10 [==============================] - 2s 270ms/step - loss: 4.3309 - accuracy: 0.1375 - val_loss: 5.0060 - val_accuracy: 0.0245\n","Epoch 16/100\n","10/10 [==============================] - 2s 266ms/step - loss: 4.3423 - accuracy: 0.2156 - val_loss: 4.4654 - val_accuracy: 0.0173\n","Epoch 17/100\n","10/10 [==============================] - 3s 293ms/step - loss: 4.2979 - accuracy: 0.1813 - val_loss: 4.4691 - val_accuracy: 0.0848\n","Epoch 18/100\n","10/10 [==============================] - 2s 271ms/step - loss: 4.2525 - accuracy: 0.1781 - val_loss: 4.4591 - val_accuracy: 0.0189\n","Epoch 19/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.2669 - accuracy: 0.1781 - val_loss: 4.4283 - val_accuracy: 0.0566\n","Epoch 20/100\n","10/10 [==============================] - 2s 266ms/step - loss: 4.2171 - accuracy: 0.1688 - val_loss: 4.4510 - val_accuracy: 0.0450\n","Epoch 21/100\n","10/10 [==============================] - 2s 268ms/step - loss: 4.1931 - accuracy: 0.1844 - val_loss: 4.4132 - val_accuracy: 0.0617\n","Epoch 22/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.1939 - accuracy: 0.2031 - val_loss: 4.3929 - val_accuracy: 0.1097\n","Epoch 23/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.1832 - accuracy: 0.1969 - val_loss: 4.3662 - val_accuracy: 0.0743\n","Epoch 24/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.1446 - accuracy: 0.1906 - val_loss: 4.2705 - val_accuracy: 0.0763\n","Epoch 25/100\n","10/10 [==============================] - 2s 275ms/step - loss: 4.0857 - accuracy: 0.1844 - val_loss: 4.3554 - val_accuracy: 0.1256\n","Epoch 26/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.0670 - accuracy: 0.2469 - val_loss: 4.3987 - val_accuracy: 0.0267\n","Epoch 27/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.0067 - accuracy: 0.2219 - val_loss: 4.2445 - val_accuracy: 0.0985\n","Epoch 28/100\n","10/10 [==============================] - 3s 277ms/step - loss: 3.9496 - accuracy: 0.2281 - val_loss: 4.4050 - val_accuracy: 0.0284\n","Epoch 29/100\n","10/10 [==============================] - 2s 268ms/step - loss: 4.0739 - accuracy: 0.2062 - val_loss: 4.2481 - val_accuracy: 0.1717\n","Epoch 30/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.9379 - accuracy: 0.2219 - val_loss: 4.2231 - val_accuracy: 0.1012\n","Epoch 31/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.0322 - accuracy: 0.1969 - val_loss: 4.1931 - val_accuracy: 0.1689\n","Epoch 32/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.8547 - accuracy: 0.2656 - val_loss: 4.1619 - val_accuracy: 0.1464\n","Epoch 33/100\n","10/10 [==============================] - 2s 265ms/step - loss: 3.9773 - accuracy: 0.2656 - val_loss: 4.1605 - val_accuracy: 0.1633\n","Epoch 34/100\n","10/10 [==============================] - 2s 270ms/step - loss: 3.9306 - accuracy: 0.2531 - val_loss: 4.2293 - val_accuracy: 0.1779\n","Epoch 35/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.9093 - accuracy: 0.2313 - val_loss: 4.1138 - val_accuracy: 0.2301\n","Epoch 36/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.9093 - accuracy: 0.2531 - val_loss: 4.1716 - val_accuracy: 0.1414\n","Epoch 37/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.8754 - accuracy: 0.2219 - val_loss: 4.0960 - val_accuracy: 0.1346\n","Epoch 38/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.8799 - accuracy: 0.2469 - val_loss: 4.1197 - val_accuracy: 0.0686\n","Epoch 39/100\n","10/10 [==============================] - 2s 268ms/step - loss: 3.8570 - accuracy: 0.2219 - val_loss: 4.1974 - val_accuracy: 0.1434\n","Epoch 40/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.8355 - accuracy: 0.2344 - val_loss: 4.0852 - val_accuracy: 0.1134\n","Epoch 41/100\n","10/10 [==============================] - 2s 270ms/step - loss: 3.9814 - accuracy: 0.2250 - val_loss: 4.2669 - val_accuracy: 0.1137\n","Epoch 42/100\n","10/10 [==============================] - 3s 293ms/step - loss: 3.9536 - accuracy: 0.2156 - val_loss: 4.1404 - val_accuracy: 0.1709\n","Epoch 43/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.8855 - accuracy: 0.2344 - val_loss: 4.1376 - val_accuracy: 0.2305\n","Epoch 44/100\n","10/10 [==============================] - 2s 269ms/step - loss: 3.8560 - accuracy: 0.2188 - val_loss: 4.1311 - val_accuracy: 0.1611\n","Epoch 45/100\n","10/10 [==============================] - 2s 275ms/step - loss: 3.7895 - accuracy: 0.2531 - val_loss: 4.0505 - val_accuracy: 0.1772\n","Epoch 46/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.8084 - accuracy: 0.2188 - val_loss: 3.9842 - val_accuracy: 0.2080\n","Epoch 47/100\n","10/10 [==============================] - 2s 269ms/step - loss: 3.7837 - accuracy: 0.2531 - val_loss: 4.0430 - val_accuracy: 0.2449\n","Epoch 48/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.7706 - accuracy: 0.2562 - val_loss: 3.9834 - val_accuracy: 0.2286\n","Epoch 49/100\n","10/10 [==============================] - 2s 276ms/step - loss: 3.7697 - accuracy: 0.2406 - val_loss: 4.1671 - val_accuracy: 0.2425\n","Epoch 50/100\n","10/10 [==============================] - 2s 274ms/step - loss: 3.8401 - accuracy: 0.2344 - val_loss: 3.8857 - val_accuracy: 0.2858\n","Epoch 51/100\n","10/10 [==============================] - 2s 269ms/step - loss: 3.7911 - accuracy: 0.2531 - val_loss: 4.0873 - val_accuracy: 0.1813\n","Epoch 52/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.8479 - accuracy: 0.2562 - val_loss: 3.9617 - val_accuracy: 0.2603\n","Epoch 53/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.7608 - accuracy: 0.2562 - val_loss: 3.9038 - val_accuracy: 0.2876\n","Epoch 54/100\n","10/10 [==============================] - 2s 265ms/step - loss: 3.7304 - accuracy: 0.2625 - val_loss: 4.0107 - val_accuracy: 0.2568\n","Epoch 55/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.7960 - accuracy: 0.2250 - val_loss: 3.9322 - val_accuracy: 0.2506\n","Epoch 56/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.6856 - accuracy: 0.2469 - val_loss: 4.0266 - val_accuracy: 0.2114\n","Epoch 57/100\n","10/10 [==============================] - 2s 268ms/step - loss: 3.7740 - accuracy: 0.2625 - val_loss: 4.0594 - val_accuracy: 0.1905\n","Epoch 58/100\n","10/10 [==============================] - 2s 269ms/step - loss: 3.7052 - accuracy: 0.2656 - val_loss: 3.9886 - val_accuracy: 0.1639\n","Epoch 59/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.7897 - accuracy: 0.2500 - val_loss: 4.0079 - val_accuracy: 0.2563\n","Epoch 60/100\n","10/10 [==============================] - 2s 271ms/step - loss: 3.7395 - accuracy: 0.2250 - val_loss: 4.0361 - val_accuracy: 0.2717\n","Epoch 61/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.8206 - accuracy: 0.3063 - val_loss: 3.9090 - val_accuracy: 0.2647\n","Epoch 62/100\n","10/10 [==============================] - 2s 262ms/step - loss: 3.6471 - accuracy: 0.2562 - val_loss: 4.0054 - val_accuracy: 0.2241\n","Epoch 63/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.7059 - accuracy: 0.2812 - val_loss: 3.8792 - val_accuracy: 0.2372\n","Epoch 64/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.6669 - accuracy: 0.2500 - val_loss: 4.0023 - val_accuracy: 0.2466\n","Epoch 65/100\n","10/10 [==============================] - 2s 268ms/step - loss: 3.7205 - accuracy: 0.2906 - val_loss: 3.8256 - val_accuracy: 0.2503\n","Epoch 66/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.6006 - accuracy: 0.2469 - val_loss: 3.9326 - val_accuracy: 0.2523\n","Epoch 67/100\n","10/10 [==============================] - 2s 265ms/step - loss: 3.6578 - accuracy: 0.2656 - val_loss: 3.8464 - val_accuracy: 0.2336\n","Epoch 68/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.6094 - accuracy: 0.2625 - val_loss: 3.8650 - val_accuracy: 0.2852\n","Epoch 69/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.6680 - accuracy: 0.2750 - val_loss: 3.9341 - val_accuracy: 0.2084\n","Epoch 70/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.5241 - accuracy: 0.2875 - val_loss: 3.7908 - val_accuracy: 0.2619\n","Epoch 71/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.5380 - accuracy: 0.2875 - val_loss: 3.9296 - val_accuracy: 0.2061\n","Epoch 72/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.6679 - accuracy: 0.2531 - val_loss: 3.8099 - val_accuracy: 0.2787\n","Epoch 73/100\n","10/10 [==============================] - 2s 260ms/step - loss: 3.4824 - accuracy: 0.3031 - val_loss: 3.9156 - val_accuracy: 0.2103\n","Epoch 74/100\n","10/10 [==============================] - 2s 251ms/step - loss: 3.5768 - accuracy: 0.2688 - val_loss: 3.7994 - val_accuracy: 0.2758\n","Epoch 75/100\n","10/10 [==============================] - 2s 256ms/step - loss: 3.5270 - accuracy: 0.2937 - val_loss: 3.8687 - val_accuracy: 0.2032\n","Epoch 76/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.5322 - accuracy: 0.2906 - val_loss: 3.8272 - val_accuracy: 0.2409\n","Epoch 77/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.5428 - accuracy: 0.2781 - val_loss: 3.7759 - val_accuracy: 0.2721\n","Epoch 78/100\n","10/10 [==============================] - 2s 256ms/step - loss: 3.4258 - accuracy: 0.3000 - val_loss: 3.7984 - val_accuracy: 0.2375\n","Epoch 79/100\n","10/10 [==============================] - 2s 258ms/step - loss: 3.5326 - accuracy: 0.2969 - val_loss: 3.8702 - val_accuracy: 0.2338\n","Epoch 80/100\n","10/10 [==============================] - 2s 256ms/step - loss: 3.4842 - accuracy: 0.3219 - val_loss: 3.8629 - val_accuracy: 0.1974\n","Epoch 81/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.4118 - accuracy: 0.3438 - val_loss: 3.7132 - val_accuracy: 0.2688\n","Epoch 82/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.3924 - accuracy: 0.2844 - val_loss: 3.7543 - val_accuracy: 0.2688\n","Epoch 83/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.4544 - accuracy: 0.2844 - val_loss: 3.8077 - val_accuracy: 0.2547\n","Epoch 84/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.4418 - accuracy: 0.3125 - val_loss: 3.8621 - val_accuracy: 0.1846\n","Epoch 85/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.4006 - accuracy: 0.3250 - val_loss: 3.7283 - val_accuracy: 0.2285\n","Epoch 86/100\n","10/10 [==============================] - 2s 263ms/step - loss: 3.3539 - accuracy: 0.3344 - val_loss: 3.7727 - val_accuracy: 0.1874\n","Epoch 87/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.3205 - accuracy: 0.2906 - val_loss: 3.7420 - val_accuracy: 0.2408\n","Epoch 88/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.4370 - accuracy: 0.3094 - val_loss: 3.8186 - val_accuracy: 0.2267\n","Epoch 89/100\n","10/10 [==============================] - 5s 574ms/step - loss: 3.3711 - accuracy: 0.3375 - val_loss: 3.6580 - val_accuracy: 0.2384\n","Epoch 90/100\n","10/10 [==============================] - 5s 578ms/step - loss: 3.2824 - accuracy: 0.3125 - val_loss: 3.7513 - val_accuracy: 0.2299\n","Epoch 91/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.3954 - accuracy: 0.3094 - val_loss: 3.7447 - val_accuracy: 0.2261\n","Epoch 92/100\n","10/10 [==============================] - 2s 263ms/step - loss: 3.3487 - accuracy: 0.3531 - val_loss: 3.7473 - val_accuracy: 0.2414\n","Epoch 93/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.3495 - accuracy: 0.3063 - val_loss: 3.6832 - val_accuracy: 0.2791\n","Epoch 94/100\n","10/10 [==============================] - 5s 574ms/step - loss: 3.3070 - accuracy: 0.3187 - val_loss: 3.6749 - val_accuracy: 0.2509\n","Epoch 95/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.3124 - accuracy: 0.3344 - val_loss: 3.7929 - val_accuracy: 0.1840\n","Epoch 96/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.2852 - accuracy: 0.3250 - val_loss: 3.6681 - val_accuracy: 0.2577\n","Epoch 97/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.2595 - accuracy: 0.3250 - val_loss: 3.6843 - val_accuracy: 0.2590\n","Epoch 98/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.2585 - accuracy: 0.3438 - val_loss: 3.6938 - val_accuracy: 0.2381\n","Epoch 99/100\n","10/10 [==============================] - 2s 261ms/step - loss: 3.2059 - accuracy: 0.3750 - val_loss: 3.6205 - val_accuracy: 0.2555\n","Epoch 100/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.1722 - accuracy: 0.3625 - val_loss: 3.6395 - val_accuracy: 0.2381\n"]}]},{"cell_type":"code","source":["# val loss and train loss were pretty similar, can we add just a little more regularized complexity?\n","# maybe dropout makes a difference\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          layers.Dropout(0.4),\n","          layers.Dense(520,kernel_initializer='lecun_normal',kernel_regularizer='l1',bias_regularizer='l1'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(4,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dropout(0.25),\n","          layers.Dense(16,kernel_initializer='lecun_normal'), \n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=100, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6oYV31x8LG-","executionInfo":{"status":"ok","timestamp":1652035071055,"user_tz":240,"elapsed":263527,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"ec2252c6-8ea7-40db-b187-a81a0f527c50"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","10/10 [==============================] - 4s 331ms/step - loss: 90.6362 - accuracy: 0.0906 - val_loss: 80.1869 - val_accuracy: 0.0278\n","Epoch 2/100\n","10/10 [==============================] - 3s 279ms/step - loss: 71.1149 - accuracy: 0.1500 - val_loss: 62.4445 - val_accuracy: 0.0278\n","Epoch 3/100\n","10/10 [==============================] - 3s 291ms/step - loss: 54.7207 - accuracy: 0.1656 - val_loss: 47.5613 - val_accuracy: 0.0278\n","Epoch 4/100\n","10/10 [==============================] - 3s 292ms/step - loss: 41.1156 - accuracy: 0.1844 - val_loss: 35.5227 - val_accuracy: 0.0278\n","Epoch 5/100\n","10/10 [==============================] - 2s 272ms/step - loss: 30.3464 - accuracy: 0.1937 - val_loss: 26.2058 - val_accuracy: 0.0278\n","Epoch 6/100\n","10/10 [==============================] - 3s 291ms/step - loss: 22.0985 - accuracy: 0.1969 - val_loss: 19.1514 - val_accuracy: 0.0280\n","Epoch 7/100\n","10/10 [==============================] - 2s 271ms/step - loss: 15.9239 - accuracy: 0.2219 - val_loss: 13.7507 - val_accuracy: 0.0656\n","Epoch 8/100\n","10/10 [==============================] - 3s 292ms/step - loss: 11.7169 - accuracy: 0.1937 - val_loss: 10.5097 - val_accuracy: 0.0283\n","Epoch 9/100\n","10/10 [==============================] - 3s 277ms/step - loss: 8.6799 - accuracy: 0.2094 - val_loss: 7.8082 - val_accuracy: 0.1877\n","Epoch 10/100\n","10/10 [==============================] - 3s 281ms/step - loss: 6.8109 - accuracy: 0.2031 - val_loss: 6.3456 - val_accuracy: 0.2147\n","Epoch 11/100\n","10/10 [==============================] - 3s 292ms/step - loss: 5.6664 - accuracy: 0.2281 - val_loss: 5.4792 - val_accuracy: 0.2139\n","Epoch 12/100\n","10/10 [==============================] - 2s 268ms/step - loss: 5.0476 - accuracy: 0.1813 - val_loss: 5.5829 - val_accuracy: 0.0654\n","Epoch 13/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.6142 - accuracy: 0.1875 - val_loss: 4.6921 - val_accuracy: 0.2105\n","Epoch 14/100\n","10/10 [==============================] - 2s 273ms/step - loss: 4.4559 - accuracy: 0.1437 - val_loss: 4.6830 - val_accuracy: 0.0321\n","Epoch 15/100\n","10/10 [==============================] - 2s 272ms/step - loss: 4.5513 - accuracy: 0.1969 - val_loss: 4.6953 - val_accuracy: 0.0616\n","Epoch 16/100\n","10/10 [==============================] - 2s 274ms/step - loss: 4.2358 - accuracy: 0.1719 - val_loss: 4.7466 - val_accuracy: 0.0451\n","Epoch 17/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.2841 - accuracy: 0.1875 - val_loss: 4.3708 - val_accuracy: 0.0098\n","Epoch 18/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.2467 - accuracy: 0.1844 - val_loss: 4.7664 - val_accuracy: 0.0565\n","Epoch 19/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.3006 - accuracy: 0.1969 - val_loss: 4.8621 - val_accuracy: 0.0431\n","Epoch 20/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.2201 - accuracy: 0.2000 - val_loss: 4.4714 - val_accuracy: 0.1428\n","Epoch 21/100\n","10/10 [==============================] - 3s 293ms/step - loss: 4.1836 - accuracy: 0.2062 - val_loss: 4.6069 - val_accuracy: 0.2008\n","Epoch 22/100\n","10/10 [==============================] - 2s 270ms/step - loss: 4.1429 - accuracy: 0.2313 - val_loss: 4.3704 - val_accuracy: 0.1855\n","Epoch 23/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.1250 - accuracy: 0.1875 - val_loss: 4.4441 - val_accuracy: 0.1590\n","Epoch 24/100\n","10/10 [==============================] - 2s 269ms/step - loss: 4.1203 - accuracy: 0.2000 - val_loss: 4.3697 - val_accuracy: 0.1744\n","Epoch 25/100\n","10/10 [==============================] - 2s 272ms/step - loss: 4.1523 - accuracy: 0.2094 - val_loss: 4.4524 - val_accuracy: 0.2021\n","Epoch 26/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.1514 - accuracy: 0.2000 - val_loss: 4.2737 - val_accuracy: 0.2070\n","Epoch 27/100\n","10/10 [==============================] - 3s 293ms/step - loss: 4.1176 - accuracy: 0.2031 - val_loss: 4.6239 - val_accuracy: 0.0616\n","Epoch 28/100\n","10/10 [==============================] - 3s 301ms/step - loss: 4.1157 - accuracy: 0.1906 - val_loss: 4.4096 - val_accuracy: 0.1348\n","Epoch 29/100\n","10/10 [==============================] - 2s 269ms/step - loss: 4.1295 - accuracy: 0.2094 - val_loss: 4.2834 - val_accuracy: 0.0679\n","Epoch 30/100\n","10/10 [==============================] - 3s 278ms/step - loss: 3.9610 - accuracy: 0.2250 - val_loss: 4.4400 - val_accuracy: 0.1149\n","Epoch 31/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.1048 - accuracy: 0.1937 - val_loss: 4.1351 - val_accuracy: 0.1924\n","Epoch 32/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.9964 - accuracy: 0.1906 - val_loss: 4.0572 - val_accuracy: 0.2675\n","Epoch 33/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.8841 - accuracy: 0.2125 - val_loss: 4.1477 - val_accuracy: 0.0762\n","Epoch 34/100\n","10/10 [==============================] - 2s 275ms/step - loss: 3.9993 - accuracy: 0.2031 - val_loss: 4.1909 - val_accuracy: 0.0735\n","Epoch 35/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.9394 - accuracy: 0.2031 - val_loss: 4.2005 - val_accuracy: 0.1148\n","Epoch 36/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.1254 - accuracy: 0.2125 - val_loss: 4.2201 - val_accuracy: 0.1867\n","Epoch 37/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.1024 - accuracy: 0.2188 - val_loss: 4.2004 - val_accuracy: 0.2323\n","Epoch 38/100\n","10/10 [==============================] - 2s 273ms/step - loss: 3.9941 - accuracy: 0.2250 - val_loss: 4.0740 - val_accuracy: 0.2250\n","Epoch 39/100\n","10/10 [==============================] - 3s 278ms/step - loss: 3.9767 - accuracy: 0.2000 - val_loss: 4.1221 - val_accuracy: 0.2404\n","Epoch 40/100\n","10/10 [==============================] - 3s 293ms/step - loss: 3.9052 - accuracy: 0.1906 - val_loss: 3.9459 - val_accuracy: 0.2918\n","Epoch 41/100\n","10/10 [==============================] - 3s 277ms/step - loss: 3.8947 - accuracy: 0.2125 - val_loss: 4.1377 - val_accuracy: 0.1853\n","Epoch 42/100\n","10/10 [==============================] - 3s 279ms/step - loss: 3.9803 - accuracy: 0.2188 - val_loss: 4.0500 - val_accuracy: 0.2990\n","Epoch 43/100\n","10/10 [==============================] - 2s 271ms/step - loss: 3.8912 - accuracy: 0.2313 - val_loss: 4.1158 - val_accuracy: 0.1963\n","Epoch 44/100\n","10/10 [==============================] - 2s 269ms/step - loss: 3.8884 - accuracy: 0.2125 - val_loss: 3.9677 - val_accuracy: 0.1994\n","Epoch 45/100\n","10/10 [==============================] - 2s 271ms/step - loss: 3.9625 - accuracy: 0.1937 - val_loss: 4.1320 - val_accuracy: 0.2373\n","Epoch 46/100\n","10/10 [==============================] - 3s 277ms/step - loss: 3.9028 - accuracy: 0.2281 - val_loss: 3.9316 - val_accuracy: 0.2772\n","Epoch 47/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.9497 - accuracy: 0.2313 - val_loss: 3.9913 - val_accuracy: 0.3225\n","Epoch 48/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.8400 - accuracy: 0.2250 - val_loss: 4.0580 - val_accuracy: 0.1810\n","Epoch 49/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.0161 - accuracy: 0.2375 - val_loss: 3.9933 - val_accuracy: 0.3013\n","Epoch 50/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.9260 - accuracy: 0.2031 - val_loss: 4.0661 - val_accuracy: 0.2418\n","Epoch 51/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.9015 - accuracy: 0.2031 - val_loss: 3.8607 - val_accuracy: 0.2938\n","Epoch 52/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.8891 - accuracy: 0.2125 - val_loss: 4.1280 - val_accuracy: 0.2737\n","Epoch 53/100\n","10/10 [==============================] - 3s 300ms/step - loss: 3.9999 - accuracy: 0.2219 - val_loss: 3.9131 - val_accuracy: 0.3108\n","Epoch 54/100\n","10/10 [==============================] - 5s 583ms/step - loss: 3.8902 - accuracy: 0.2313 - val_loss: 3.9892 - val_accuracy: 0.3595\n","Epoch 55/100\n","10/10 [==============================] - 2s 273ms/step - loss: 3.8877 - accuracy: 0.2313 - val_loss: 3.8320 - val_accuracy: 0.3407\n","Epoch 56/100\n","10/10 [==============================] - 3s 280ms/step - loss: 3.8699 - accuracy: 0.2062 - val_loss: 3.9803 - val_accuracy: 0.2271\n","Epoch 57/100\n","10/10 [==============================] - 3s 357ms/step - loss: 3.7728 - accuracy: 0.2656 - val_loss: 3.9250 - val_accuracy: 0.2643\n","Epoch 58/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.8393 - accuracy: 0.2281 - val_loss: 3.9559 - val_accuracy: 0.3255\n","Epoch 59/100\n","10/10 [==============================] - 3s 290ms/step - loss: 3.9374 - accuracy: 0.2219 - val_loss: 3.8259 - val_accuracy: 0.3118\n","Epoch 60/100\n","10/10 [==============================] - 3s 293ms/step - loss: 3.8161 - accuracy: 0.2031 - val_loss: 3.9833 - val_accuracy: 0.3121\n","Epoch 61/100\n","10/10 [==============================] - 2s 271ms/step - loss: 3.9424 - accuracy: 0.2156 - val_loss: 3.8402 - val_accuracy: 0.3277\n","Epoch 62/100\n","10/10 [==============================] - 2s 273ms/step - loss: 3.8179 - accuracy: 0.2031 - val_loss: 3.8912 - val_accuracy: 0.3043\n","Epoch 63/100\n","10/10 [==============================] - 2s 268ms/step - loss: 3.8813 - accuracy: 0.2156 - val_loss: 3.8564 - val_accuracy: 0.3124\n","Epoch 64/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.7676 - accuracy: 0.2219 - val_loss: 3.7553 - val_accuracy: 0.2947\n","Epoch 65/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.6634 - accuracy: 0.2844 - val_loss: 3.8912 - val_accuracy: 0.3110\n","Epoch 66/100\n","10/10 [==============================] - 2s 268ms/step - loss: 3.8430 - accuracy: 0.2219 - val_loss: 3.8718 - val_accuracy: 0.2699\n","Epoch 67/100\n","10/10 [==============================] - 2s 269ms/step - loss: 3.6191 - accuracy: 0.2562 - val_loss: 3.7270 - val_accuracy: 0.2177\n","Epoch 68/100\n","10/10 [==============================] - 2s 270ms/step - loss: 3.7284 - accuracy: 0.2094 - val_loss: 3.8361 - val_accuracy: 0.3009\n","Epoch 69/100\n","10/10 [==============================] - 2s 265ms/step - loss: 3.7243 - accuracy: 0.2531 - val_loss: 3.8034 - val_accuracy: 0.3248\n","Epoch 70/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.7225 - accuracy: 0.2750 - val_loss: 3.7550 - val_accuracy: 0.3389\n","Epoch 71/100\n","10/10 [==============================] - 2s 266ms/step - loss: 3.8041 - accuracy: 0.1969 - val_loss: 3.8894 - val_accuracy: 0.3462\n","Epoch 72/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.7466 - accuracy: 0.2688 - val_loss: 3.7758 - val_accuracy: 0.2920\n","Epoch 73/100\n","10/10 [==============================] - 2s 268ms/step - loss: 3.6829 - accuracy: 0.2625 - val_loss: 3.7950 - val_accuracy: 0.3296\n","Epoch 74/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.7436 - accuracy: 0.2438 - val_loss: 3.9549 - val_accuracy: 0.2818\n","Epoch 75/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.7278 - accuracy: 0.2406 - val_loss: 3.8179 - val_accuracy: 0.2431\n","Epoch 76/100\n","10/10 [==============================] - 2s 271ms/step - loss: 3.7838 - accuracy: 0.2438 - val_loss: 3.8705 - val_accuracy: 0.3278\n","Epoch 77/100\n","10/10 [==============================] - 2s 268ms/step - loss: 3.7263 - accuracy: 0.2844 - val_loss: 3.9301 - val_accuracy: 0.2154\n","Epoch 78/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.7272 - accuracy: 0.2250 - val_loss: 3.6827 - val_accuracy: 0.3665\n","Epoch 79/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.6494 - accuracy: 0.2406 - val_loss: 3.9020 - val_accuracy: 0.2436\n","Epoch 80/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.7252 - accuracy: 0.2469 - val_loss: 3.8441 - val_accuracy: 0.3035\n","Epoch 81/100\n","10/10 [==============================] - 2s 269ms/step - loss: 3.7646 - accuracy: 0.2219 - val_loss: 3.8807 - val_accuracy: 0.2256\n","Epoch 82/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.7273 - accuracy: 0.2250 - val_loss: 3.7686 - val_accuracy: 0.3357\n","Epoch 83/100\n","10/10 [==============================] - 2s 267ms/step - loss: 3.6103 - accuracy: 0.2656 - val_loss: 3.7324 - val_accuracy: 0.3164\n","Epoch 84/100\n","10/10 [==============================] - 3s 293ms/step - loss: 3.6660 - accuracy: 0.2469 - val_loss: 3.7704 - val_accuracy: 0.3198\n","Epoch 85/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.6159 - accuracy: 0.2469 - val_loss: 3.7465 - val_accuracy: 0.2739\n","Epoch 86/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.5713 - accuracy: 0.2219 - val_loss: 3.7168 - val_accuracy: 0.2837\n","Epoch 87/100\n","10/10 [==============================] - 2s 271ms/step - loss: 3.6524 - accuracy: 0.2531 - val_loss: 3.7690 - val_accuracy: 0.3391\n","Epoch 88/100\n","10/10 [==============================] - 3s 280ms/step - loss: 3.7281 - accuracy: 0.2562 - val_loss: 3.8722 - val_accuracy: 0.2701\n","Epoch 89/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.5908 - accuracy: 0.2875 - val_loss: 3.6687 - val_accuracy: 0.3346\n","Epoch 90/100\n","10/10 [==============================] - 2s 275ms/step - loss: 3.5959 - accuracy: 0.2625 - val_loss: 3.7109 - val_accuracy: 0.3153\n","Epoch 91/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.6645 - accuracy: 0.2344 - val_loss: 3.7309 - val_accuracy: 0.3480\n","Epoch 92/100\n","10/10 [==============================] - 2s 272ms/step - loss: 3.5980 - accuracy: 0.2344 - val_loss: 3.6836 - val_accuracy: 0.3097\n","Epoch 93/100\n","10/10 [==============================] - 2s 275ms/step - loss: 3.5286 - accuracy: 0.2625 - val_loss: 3.7248 - val_accuracy: 0.2884\n","Epoch 94/100\n","10/10 [==============================] - 2s 275ms/step - loss: 3.5502 - accuracy: 0.2281 - val_loss: 3.6919 - val_accuracy: 0.2966\n","Epoch 95/100\n","10/10 [==============================] - 3s 280ms/step - loss: 3.5448 - accuracy: 0.2531 - val_loss: 3.7017 - val_accuracy: 0.3526\n","Epoch 96/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.5134 - accuracy: 0.2719 - val_loss: 3.7355 - val_accuracy: 0.2735\n","Epoch 97/100\n","10/10 [==============================] - 2s 276ms/step - loss: 3.5250 - accuracy: 0.2875 - val_loss: 3.6636 - val_accuracy: 0.3097\n","Epoch 98/100\n","10/10 [==============================] - 2s 273ms/step - loss: 3.4499 - accuracy: 0.2906 - val_loss: 3.6479 - val_accuracy: 0.2675\n","Epoch 99/100\n","10/10 [==============================] - 2s 276ms/step - loss: 3.5705 - accuracy: 0.2313 - val_loss: 3.6966 - val_accuracy: 0.2931\n","Epoch 100/100\n","10/10 [==============================] - 3s 277ms/step - loss: 3.4832 - accuracy: 0.2531 - val_loss: 3.6011 - val_accuracy: 0.2819\n"]}]},{"cell_type":"code","source":["# val loss and train loss were pretty similar, can we add just a little more regularized complexity?\n","# maybe dropout makes a difference\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          layers.Dropout(0.4),\n","          layers.Dense(520,kernel_initializer='lecun_normal',kernel_regularizer='l1',bias_regularizer='l1'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(8,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dropout(0.25),\n","          layers.Dense(16,kernel_initializer='lecun_normal'), \n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=100, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OqjzYVbC95HO","executionInfo":{"status":"ok","timestamp":1652035583461,"user_tz":240,"elapsed":263551,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"51f1269a-7619-45de-87d2-6b953e896432"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","10/10 [==============================] - 4s 333ms/step - loss: 91.1723 - accuracy: 0.0938 - val_loss: 88.4207 - val_accuracy: 7.3064e-04\n","Epoch 2/100\n","10/10 [==============================] - 2s 273ms/step - loss: 72.0327 - accuracy: 0.1688 - val_loss: 65.7303 - val_accuracy: 0.2081\n","Epoch 3/100\n","10/10 [==============================] - 2s 272ms/step - loss: 55.5954 - accuracy: 0.2313 - val_loss: 50.2828 - val_accuracy: 0.0078\n","Epoch 4/100\n","10/10 [==============================] - 3s 291ms/step - loss: 42.1046 - accuracy: 0.2219 - val_loss: 37.7902 - val_accuracy: 0.2148\n","Epoch 5/100\n","10/10 [==============================] - 3s 292ms/step - loss: 31.4439 - accuracy: 0.2344 - val_loss: 28.2855 - val_accuracy: 0.2148\n","Epoch 6/100\n","10/10 [==============================] - 3s 290ms/step - loss: 23.1820 - accuracy: 0.2500 - val_loss: 21.3509 - val_accuracy: 0.2148\n","Epoch 7/100\n","10/10 [==============================] - 3s 291ms/step - loss: 17.1382 - accuracy: 0.2656 - val_loss: 16.0098 - val_accuracy: 0.0282\n","Epoch 8/100\n","10/10 [==============================] - 3s 291ms/step - loss: 12.7835 - accuracy: 0.2688 - val_loss: 12.0787 - val_accuracy: 0.2000\n","Epoch 9/100\n","10/10 [==============================] - 3s 291ms/step - loss: 9.8258 - accuracy: 0.2562 - val_loss: 9.6238 - val_accuracy: 0.1898\n","Epoch 10/100\n","10/10 [==============================] - 2s 270ms/step - loss: 7.7605 - accuracy: 0.2750 - val_loss: 7.8591 - val_accuracy: 0.0423\n","Epoch 11/100\n","10/10 [==============================] - 3s 292ms/step - loss: 6.4953 - accuracy: 0.2531 - val_loss: 7.1390 - val_accuracy: 0.2033\n","Epoch 12/100\n","10/10 [==============================] - 3s 291ms/step - loss: 5.8050 - accuracy: 0.2594 - val_loss: 6.5828 - val_accuracy: 0.2144\n","Epoch 13/100\n","10/10 [==============================] - 3s 292ms/step - loss: 5.2910 - accuracy: 0.2406 - val_loss: 5.7380 - val_accuracy: 0.2069\n","Epoch 14/100\n","10/10 [==============================] - 3s 292ms/step - loss: 5.0462 - accuracy: 0.2313 - val_loss: 5.6221 - val_accuracy: 0.1896\n","Epoch 15/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.9384 - accuracy: 0.2125 - val_loss: 5.5384 - val_accuracy: 0.2317\n","Epoch 16/100\n","10/10 [==============================] - 2s 274ms/step - loss: 4.6970 - accuracy: 0.2406 - val_loss: 5.8519 - val_accuracy: 0.0355\n","Epoch 17/100\n","10/10 [==============================] - 2s 271ms/step - loss: 4.6367 - accuracy: 0.2812 - val_loss: 5.3256 - val_accuracy: 0.2255\n","Epoch 18/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.6291 - accuracy: 0.2531 - val_loss: 5.6009 - val_accuracy: 0.0424\n","Epoch 19/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.6044 - accuracy: 0.2562 - val_loss: 5.3668 - val_accuracy: 0.0702\n","Epoch 20/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.4891 - accuracy: 0.2375 - val_loss: 5.1806 - val_accuracy: 0.1823\n","Epoch 21/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.6855 - accuracy: 0.2562 - val_loss: 5.4913 - val_accuracy: 0.0699\n","Epoch 22/100\n","10/10 [==============================] - 2s 275ms/step - loss: 4.4247 - accuracy: 0.2375 - val_loss: 5.1354 - val_accuracy: 0.1811\n","Epoch 23/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.7248 - accuracy: 0.2250 - val_loss: 5.1357 - val_accuracy: 0.2322\n","Epoch 24/100\n","10/10 [==============================] - 2s 271ms/step - loss: 4.5180 - accuracy: 0.2313 - val_loss: 5.3059 - val_accuracy: 0.0312\n","Epoch 25/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.6182 - accuracy: 0.2344 - val_loss: 5.3392 - val_accuracy: 0.0746\n","Epoch 26/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.4393 - accuracy: 0.2844 - val_loss: 4.9083 - val_accuracy: 0.1911\n","Epoch 27/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.4705 - accuracy: 0.2500 - val_loss: 5.1335 - val_accuracy: 0.1063\n","Epoch 28/100\n","10/10 [==============================] - 2s 276ms/step - loss: 4.5057 - accuracy: 0.2812 - val_loss: 4.9030 - val_accuracy: 0.2168\n","Epoch 29/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.5244 - accuracy: 0.2281 - val_loss: 4.9113 - val_accuracy: 0.2113\n","Epoch 30/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.3359 - accuracy: 0.2500 - val_loss: 4.7090 - val_accuracy: 0.2159\n","Epoch 31/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.3219 - accuracy: 0.2781 - val_loss: 4.9015 - val_accuracy: 0.1860\n","Epoch 32/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.4067 - accuracy: 0.2688 - val_loss: 4.9438 - val_accuracy: 0.2149\n","Epoch 33/100\n","10/10 [==============================] - 3s 294ms/step - loss: 4.3831 - accuracy: 0.2812 - val_loss: 4.7342 - val_accuracy: 0.2060\n","Epoch 34/100\n","10/10 [==============================] - 2s 275ms/step - loss: 4.3683 - accuracy: 0.2906 - val_loss: 4.8640 - val_accuracy: 0.1843\n","Epoch 35/100\n","10/10 [==============================] - 2s 271ms/step - loss: 4.3751 - accuracy: 0.2562 - val_loss: 4.8614 - val_accuracy: 0.1721\n","Epoch 36/100\n","10/10 [==============================] - 2s 268ms/step - loss: 4.2871 - accuracy: 0.2844 - val_loss: 4.7676 - val_accuracy: 0.1684\n","Epoch 37/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.2266 - accuracy: 0.2625 - val_loss: 4.7374 - val_accuracy: 0.1678\n","Epoch 38/100\n","10/10 [==============================] - 2s 271ms/step - loss: 4.2336 - accuracy: 0.3344 - val_loss: 4.6944 - val_accuracy: 0.1852\n","Epoch 39/100\n","10/10 [==============================] - 2s 270ms/step - loss: 4.3915 - accuracy: 0.2812 - val_loss: 4.8156 - val_accuracy: 0.1625\n","Epoch 40/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.3414 - accuracy: 0.2937 - val_loss: 4.7854 - val_accuracy: 0.2033\n","Epoch 41/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.5011 - accuracy: 0.2500 - val_loss: 4.6533 - val_accuracy: 0.2119\n","Epoch 42/100\n","10/10 [==============================] - 2s 270ms/step - loss: 4.1787 - accuracy: 0.3031 - val_loss: 4.5875 - val_accuracy: 0.2004\n","Epoch 43/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.3252 - accuracy: 0.2375 - val_loss: 4.7412 - val_accuracy: 0.1882\n","Epoch 44/100\n","10/10 [==============================] - 3s 278ms/step - loss: 4.3451 - accuracy: 0.2969 - val_loss: 4.5717 - val_accuracy: 0.2088\n","Epoch 45/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.2792 - accuracy: 0.3000 - val_loss: 4.7651 - val_accuracy: 0.2337\n","Epoch 46/100\n","10/10 [==============================] - 2s 267ms/step - loss: 4.5525 - accuracy: 0.2875 - val_loss: 4.5818 - val_accuracy: 0.2526\n","Epoch 47/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.1819 - accuracy: 0.3156 - val_loss: 4.5379 - val_accuracy: 0.2393\n","Epoch 48/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.3731 - accuracy: 0.2438 - val_loss: 4.6332 - val_accuracy: 0.2304\n","Epoch 49/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.2883 - accuracy: 0.3000 - val_loss: 4.4046 - val_accuracy: 0.3195\n","Epoch 50/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.2556 - accuracy: 0.3000 - val_loss: 4.4660 - val_accuracy: 0.2302\n","Epoch 51/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.2823 - accuracy: 0.2719 - val_loss: 4.5826 - val_accuracy: 0.2193\n","Epoch 52/100\n","10/10 [==============================] - 3s 290ms/step - loss: 4.3069 - accuracy: 0.2906 - val_loss: 4.4657 - val_accuracy: 0.2697\n","Epoch 53/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.1904 - accuracy: 0.3031 - val_loss: 4.4837 - val_accuracy: 0.2526\n","Epoch 54/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.2375 - accuracy: 0.2781 - val_loss: 4.4621 - val_accuracy: 0.2120\n","Epoch 55/100\n","10/10 [==============================] - 2s 272ms/step - loss: 4.2155 - accuracy: 0.2906 - val_loss: 4.4456 - val_accuracy: 0.3051\n","Epoch 56/100\n","10/10 [==============================] - 2s 268ms/step - loss: 4.2191 - accuracy: 0.3531 - val_loss: 4.4643 - val_accuracy: 0.2330\n","Epoch 57/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.1173 - accuracy: 0.3250 - val_loss: 4.3706 - val_accuracy: 0.2765\n","Epoch 58/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.1830 - accuracy: 0.2844 - val_loss: 4.3385 - val_accuracy: 0.3241\n","Epoch 59/100\n","10/10 [==============================] - 2s 268ms/step - loss: 4.1512 - accuracy: 0.3438 - val_loss: 4.4540 - val_accuracy: 0.2276\n","Epoch 60/100\n","10/10 [==============================] - 2s 263ms/step - loss: 4.0912 - accuracy: 0.3375 - val_loss: 4.3617 - val_accuracy: 0.2615\n","Epoch 61/100\n","10/10 [==============================] - 2s 273ms/step - loss: 4.1601 - accuracy: 0.3375 - val_loss: 4.3838 - val_accuracy: 0.2830\n","Epoch 62/100\n","10/10 [==============================] - 2s 274ms/step - loss: 4.0679 - accuracy: 0.3469 - val_loss: 4.2901 - val_accuracy: 0.3279\n","Epoch 63/100\n","10/10 [==============================] - 3s 293ms/step - loss: 4.1304 - accuracy: 0.3250 - val_loss: 4.3618 - val_accuracy: 0.3173\n","Epoch 64/100\n","10/10 [==============================] - 2s 274ms/step - loss: 4.1171 - accuracy: 0.3281 - val_loss: 4.3989 - val_accuracy: 0.2610\n","Epoch 65/100\n","10/10 [==============================] - 2s 276ms/step - loss: 4.0600 - accuracy: 0.3156 - val_loss: 4.2070 - val_accuracy: 0.3219\n","Epoch 66/100\n","10/10 [==============================] - 2s 270ms/step - loss: 4.2284 - accuracy: 0.3125 - val_loss: 4.6067 - val_accuracy: 0.2487\n","Epoch 67/100\n","10/10 [==============================] - 3s 279ms/step - loss: 4.1238 - accuracy: 0.3313 - val_loss: 4.2650 - val_accuracy: 0.2686\n","Epoch 68/100\n","10/10 [==============================] - 2s 274ms/step - loss: 4.0351 - accuracy: 0.2937 - val_loss: 4.4458 - val_accuracy: 0.2918\n","Epoch 69/100\n","10/10 [==============================] - 2s 274ms/step - loss: 4.1276 - accuracy: 0.3219 - val_loss: 4.3107 - val_accuracy: 0.2885\n","Epoch 70/100\n","10/10 [==============================] - 3s 282ms/step - loss: 3.9877 - accuracy: 0.3187 - val_loss: 4.2820 - val_accuracy: 0.2564\n","Epoch 71/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.9326 - accuracy: 0.3562 - val_loss: 4.3328 - val_accuracy: 0.2455\n","Epoch 72/100\n","10/10 [==============================] - 3s 291ms/step - loss: 4.0919 - accuracy: 0.2969 - val_loss: 4.3553 - val_accuracy: 0.3350\n","Epoch 73/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.1520 - accuracy: 0.3438 - val_loss: 4.2070 - val_accuracy: 0.3167\n","Epoch 74/100\n","10/10 [==============================] - 3s 281ms/step - loss: 3.9105 - accuracy: 0.3344 - val_loss: 4.3371 - val_accuracy: 0.2110\n","Epoch 75/100\n","10/10 [==============================] - 3s 293ms/step - loss: 4.0188 - accuracy: 0.3500 - val_loss: 4.1709 - val_accuracy: 0.3350\n","Epoch 76/100\n","10/10 [==============================] - 3s 292ms/step - loss: 4.0155 - accuracy: 0.2969 - val_loss: 4.3066 - val_accuracy: 0.2469\n","Epoch 77/100\n","10/10 [==============================] - 3s 279ms/step - loss: 3.9037 - accuracy: 0.3750 - val_loss: 4.1965 - val_accuracy: 0.2835\n","Epoch 78/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.9107 - accuracy: 0.3406 - val_loss: 4.1685 - val_accuracy: 0.3454\n","Epoch 79/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.9233 - accuracy: 0.3750 - val_loss: 4.3830 - val_accuracy: 0.2114\n","Epoch 80/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.9699 - accuracy: 0.3656 - val_loss: 4.2457 - val_accuracy: 0.2955\n","Epoch 81/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.9184 - accuracy: 0.3281 - val_loss: 4.2215 - val_accuracy: 0.2837\n","Epoch 82/100\n","10/10 [==============================] - 3s 293ms/step - loss: 3.8304 - accuracy: 0.3500 - val_loss: 4.3865 - val_accuracy: 0.1989\n","Epoch 83/100\n","10/10 [==============================] - 2s 274ms/step - loss: 3.9605 - accuracy: 0.3438 - val_loss: 4.2867 - val_accuracy: 0.2925\n","Epoch 84/100\n","10/10 [==============================] - 2s 274ms/step - loss: 3.9631 - accuracy: 0.3250 - val_loss: 4.2382 - val_accuracy: 0.2632\n","Epoch 85/100\n","10/10 [==============================] - 2s 272ms/step - loss: 3.9025 - accuracy: 0.3438 - val_loss: 4.1820 - val_accuracy: 0.3269\n","Epoch 86/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.9011 - accuracy: 0.3688 - val_loss: 4.4292 - val_accuracy: 0.2014\n","Epoch 87/100\n","10/10 [==============================] - 2s 270ms/step - loss: 4.0258 - accuracy: 0.3375 - val_loss: 4.2553 - val_accuracy: 0.2888\n","Epoch 88/100\n","10/10 [==============================] - 2s 276ms/step - loss: 3.8830 - accuracy: 0.4000 - val_loss: 4.1352 - val_accuracy: 0.3311\n","Epoch 89/100\n","10/10 [==============================] - 3s 279ms/step - loss: 3.8660 - accuracy: 0.3438 - val_loss: 4.3930 - val_accuracy: 0.2544\n","Epoch 90/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.9164 - accuracy: 0.3938 - val_loss: 4.1140 - val_accuracy: 0.3348\n","Epoch 91/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.8763 - accuracy: 0.3031 - val_loss: 4.2239 - val_accuracy: 0.2862\n","Epoch 92/100\n","10/10 [==============================] - 3s 293ms/step - loss: 3.8746 - accuracy: 0.3219 - val_loss: 4.2563 - val_accuracy: 0.2803\n","Epoch 93/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.8411 - accuracy: 0.3688 - val_loss: 4.2058 - val_accuracy: 0.3056\n","Epoch 94/100\n","10/10 [==============================] - 3s 293ms/step - loss: 3.9174 - accuracy: 0.3250 - val_loss: 4.2766 - val_accuracy: 0.2795\n","Epoch 95/100\n","10/10 [==============================] - 3s 282ms/step - loss: 3.7442 - accuracy: 0.4000 - val_loss: 4.1919 - val_accuracy: 0.2517\n","Epoch 96/100\n","10/10 [==============================] - 2s 275ms/step - loss: 3.8764 - accuracy: 0.3594 - val_loss: 4.2806 - val_accuracy: 0.3050\n","Epoch 97/100\n","10/10 [==============================] - 2s 276ms/step - loss: 3.8588 - accuracy: 0.3688 - val_loss: 4.2164 - val_accuracy: 0.2922\n","Epoch 98/100\n","10/10 [==============================] - 3s 291ms/step - loss: 3.7713 - accuracy: 0.4000 - val_loss: 4.3081 - val_accuracy: 0.2330\n","Epoch 99/100\n","10/10 [==============================] - 3s 279ms/step - loss: 3.7604 - accuracy: 0.4062 - val_loss: 4.1724 - val_accuracy: 0.2918\n","Epoch 100/100\n","10/10 [==============================] - 3s 292ms/step - loss: 3.8199 - accuracy: 0.3781 - val_loss: 4.1836 - val_accuracy: 0.3262\n"]}]},{"cell_type":"code","source":["'''\n","# val loss and train loss were pretty similar, can we add just a little more regularized complexity?\n","# maybe dropout makes a difference\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          layers.Dropout(0.4),\n","          layers.Dense(520,kernel_initializer='lecun_normal',kernel_regularizer='l1',bias_regularizer='l1'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(4,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,kernel_initializer='lecun_normal'), \n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=100, validation_data=(x_val_small, y_val_small_1hot))\n","'''"],"metadata":{"id":"TyA80-Y-9L-o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# further modifying the previous one that had the lowest validation loss\n","# clearly we need some strong regularization with this small training set\n","layer_list = [ #520 parameters in input\n","          layers.BatchNormalization(),\n","          layers.Dropout(0.4),\n","          layers.Dense(10,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=400, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S7Q1HLt23-YY","executionInfo":{"status":"ok","timestamp":1652037653635,"user_tz":240,"elapsed":982917,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"04365d88-6efe-4923-f5fe-df607b853abe"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","10/10 [==============================] - 3s 293ms/step - loss: 3.0775 - accuracy: 0.0781 - val_loss: 68.0999 - val_accuracy: 0.0285\n","Epoch 2/400\n","10/10 [==============================] - 2s 226ms/step - loss: 2.7480 - accuracy: 0.1344 - val_loss: 48.1763 - val_accuracy: 0.0326\n","Epoch 3/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.5762 - accuracy: 0.1750 - val_loss: 36.7923 - val_accuracy: 0.0283\n","Epoch 4/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.4501 - accuracy: 0.2313 - val_loss: 27.5479 - val_accuracy: 0.0276\n","Epoch 5/400\n","10/10 [==============================] - 2s 231ms/step - loss: 2.3886 - accuracy: 0.2469 - val_loss: 21.6546 - val_accuracy: 0.0224\n","Epoch 6/400\n","10/10 [==============================] - 2s 228ms/step - loss: 2.2769 - accuracy: 0.2781 - val_loss: 17.3950 - val_accuracy: 0.0085\n","Epoch 7/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.2218 - accuracy: 0.3313 - val_loss: 14.2242 - val_accuracy: 0.0093\n","Epoch 8/400\n","10/10 [==============================] - 2s 230ms/step - loss: 2.1973 - accuracy: 0.3313 - val_loss: 11.6420 - val_accuracy: 0.0103\n","Epoch 9/400\n","10/10 [==============================] - 2s 226ms/step - loss: 2.1401 - accuracy: 0.3344 - val_loss: 10.2218 - val_accuracy: 0.0067\n","Epoch 10/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.0913 - accuracy: 0.3156 - val_loss: 8.7754 - val_accuracy: 0.0071\n","Epoch 11/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.0381 - accuracy: 0.3625 - val_loss: 7.5916 - val_accuracy: 0.0074\n","Epoch 12/400\n","10/10 [==============================] - 2s 232ms/step - loss: 2.0173 - accuracy: 0.3875 - val_loss: 6.6130 - val_accuracy: 0.0086\n","Epoch 13/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9447 - accuracy: 0.4187 - val_loss: 5.7509 - val_accuracy: 0.0162\n","Epoch 14/400\n","10/10 [==============================] - 2s 230ms/step - loss: 1.9401 - accuracy: 0.4469 - val_loss: 5.2408 - val_accuracy: 0.0264\n","Epoch 15/400\n","10/10 [==============================] - 2s 236ms/step - loss: 1.9070 - accuracy: 0.4250 - val_loss: 4.8150 - val_accuracy: 0.0403\n","Epoch 16/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8913 - accuracy: 0.4219 - val_loss: 4.6527 - val_accuracy: 0.0514\n","Epoch 17/400\n","10/10 [==============================] - 2s 236ms/step - loss: 1.8090 - accuracy: 0.4625 - val_loss: 4.4632 - val_accuracy: 0.0509\n","Epoch 18/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.7876 - accuracy: 0.4938 - val_loss: 4.2797 - val_accuracy: 0.0516\n","Epoch 19/400\n","10/10 [==============================] - 2s 238ms/step - loss: 1.7676 - accuracy: 0.4844 - val_loss: 4.1967 - val_accuracy: 0.0520\n","Epoch 20/400\n","10/10 [==============================] - 2s 238ms/step - loss: 1.7545 - accuracy: 0.4938 - val_loss: 4.0872 - val_accuracy: 0.0528\n","Epoch 21/400\n","10/10 [==============================] - 2s 232ms/step - loss: 1.7058 - accuracy: 0.5562 - val_loss: 4.0053 - val_accuracy: 0.0514\n","Epoch 22/400\n","10/10 [==============================] - 2s 237ms/step - loss: 1.6786 - accuracy: 0.5281 - val_loss: 3.8780 - val_accuracy: 0.0507\n","Epoch 23/400\n","10/10 [==============================] - 2s 233ms/step - loss: 1.6323 - accuracy: 0.5437 - val_loss: 3.8417 - val_accuracy: 0.0510\n","Epoch 24/400\n","10/10 [==============================] - 2s 237ms/step - loss: 1.6176 - accuracy: 0.5500 - val_loss: 3.7797 - val_accuracy: 0.0505\n","Epoch 25/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.5523 - accuracy: 0.5688 - val_loss: 3.6870 - val_accuracy: 0.0523\n","Epoch 26/400\n","10/10 [==============================] - 2s 231ms/step - loss: 1.5915 - accuracy: 0.5250 - val_loss: 3.5383 - val_accuracy: 0.0528\n","Epoch 27/400\n","10/10 [==============================] - 2s 226ms/step - loss: 1.5350 - accuracy: 0.6062 - val_loss: 3.4156 - val_accuracy: 0.0552\n","Epoch 28/400\n","10/10 [==============================] - 2s 231ms/step - loss: 1.4920 - accuracy: 0.5813 - val_loss: 3.3034 - val_accuracy: 0.0585\n","Epoch 29/400\n","10/10 [==============================] - 2s 230ms/step - loss: 1.5141 - accuracy: 0.5719 - val_loss: 3.2279 - val_accuracy: 0.0616\n","Epoch 30/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.4606 - accuracy: 0.6125 - val_loss: 3.1190 - val_accuracy: 0.0664\n","Epoch 31/400\n","10/10 [==============================] - 2s 230ms/step - loss: 1.4717 - accuracy: 0.5906 - val_loss: 3.0009 - val_accuracy: 0.0733\n","Epoch 32/400\n","10/10 [==============================] - 2s 226ms/step - loss: 1.3901 - accuracy: 0.6438 - val_loss: 2.8916 - val_accuracy: 0.0801\n","Epoch 33/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.4072 - accuracy: 0.6500 - val_loss: 2.8158 - val_accuracy: 0.0869\n","Epoch 34/400\n","10/10 [==============================] - 2s 237ms/step - loss: 1.3493 - accuracy: 0.6562 - val_loss: 2.6849 - val_accuracy: 0.1029\n","Epoch 35/400\n","10/10 [==============================] - 2s 231ms/step - loss: 1.3438 - accuracy: 0.6812 - val_loss: 2.6071 - val_accuracy: 0.1169\n","Epoch 36/400\n","10/10 [==============================] - 2s 227ms/step - loss: 1.3051 - accuracy: 0.6687 - val_loss: 2.5627 - val_accuracy: 0.1304\n","Epoch 37/400\n","10/10 [==============================] - 2s 231ms/step - loss: 1.2955 - accuracy: 0.6531 - val_loss: 2.5112 - val_accuracy: 0.1500\n","Epoch 38/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.2322 - accuracy: 0.7125 - val_loss: 2.4858 - val_accuracy: 0.1639\n","Epoch 39/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.2363 - accuracy: 0.6906 - val_loss: 2.4574 - val_accuracy: 0.1784\n","Epoch 40/400\n","10/10 [==============================] - 2s 229ms/step - loss: 1.2759 - accuracy: 0.6781 - val_loss: 2.4373 - val_accuracy: 0.1890\n","Epoch 41/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.1962 - accuracy: 0.7063 - val_loss: 2.4082 - val_accuracy: 0.2107\n","Epoch 42/400\n","10/10 [==============================] - 2s 225ms/step - loss: 1.2137 - accuracy: 0.6938 - val_loss: 2.3912 - val_accuracy: 0.2264\n","Epoch 43/400\n","10/10 [==============================] - 2s 229ms/step - loss: 1.1585 - accuracy: 0.7250 - val_loss: 2.3706 - val_accuracy: 0.2446\n","Epoch 44/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.1865 - accuracy: 0.7063 - val_loss: 2.3467 - val_accuracy: 0.2596\n","Epoch 45/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.1438 - accuracy: 0.7094 - val_loss: 2.3280 - val_accuracy: 0.2791\n","Epoch 46/400\n","10/10 [==============================] - 2s 225ms/step - loss: 1.1517 - accuracy: 0.7469 - val_loss: 2.3233 - val_accuracy: 0.2914\n","Epoch 47/400\n","10/10 [==============================] - 2s 227ms/step - loss: 1.0931 - accuracy: 0.7312 - val_loss: 2.3411 - val_accuracy: 0.2829\n","Epoch 48/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.0915 - accuracy: 0.7344 - val_loss: 2.3267 - val_accuracy: 0.2955\n","Epoch 49/400\n","10/10 [==============================] - 2s 227ms/step - loss: 1.0973 - accuracy: 0.7375 - val_loss: 2.3164 - val_accuracy: 0.3081\n","Epoch 50/400\n","10/10 [==============================] - 2s 227ms/step - loss: 1.0660 - accuracy: 0.7156 - val_loss: 2.3325 - val_accuracy: 0.3034\n","Epoch 51/400\n","10/10 [==============================] - 2s 224ms/step - loss: 1.0911 - accuracy: 0.7188 - val_loss: 2.3256 - val_accuracy: 0.3099\n","Epoch 52/400\n","10/10 [==============================] - 2s 223ms/step - loss: 1.0685 - accuracy: 0.7250 - val_loss: 2.3406 - val_accuracy: 0.3076\n","Epoch 53/400\n","10/10 [==============================] - 2s 223ms/step - loss: 1.0543 - accuracy: 0.7312 - val_loss: 2.3439 - val_accuracy: 0.3078\n","Epoch 54/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.0886 - accuracy: 0.7063 - val_loss: 2.3624 - val_accuracy: 0.3020\n","Epoch 55/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.0413 - accuracy: 0.7188 - val_loss: 2.3843 - val_accuracy: 0.2981\n","Epoch 56/400\n","10/10 [==============================] - 2s 228ms/step - loss: 1.0521 - accuracy: 0.7125 - val_loss: 2.3840 - val_accuracy: 0.3059\n","Epoch 57/400\n","10/10 [==============================] - 3s 288ms/step - loss: 1.0107 - accuracy: 0.7531 - val_loss: 2.3648 - val_accuracy: 0.3233\n","Epoch 58/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.0097 - accuracy: 0.7375 - val_loss: 2.3692 - val_accuracy: 0.3203\n","Epoch 59/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.9464 - accuracy: 0.7500 - val_loss: 2.3977 - val_accuracy: 0.3054\n","Epoch 60/400\n","10/10 [==============================] - 2s 232ms/step - loss: 1.0116 - accuracy: 0.7250 - val_loss: 2.4261 - val_accuracy: 0.2964\n","Epoch 61/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.9714 - accuracy: 0.7437 - val_loss: 2.4301 - val_accuracy: 0.2995\n","Epoch 62/400\n","10/10 [==============================] - 2s 240ms/step - loss: 0.9875 - accuracy: 0.7437 - val_loss: 2.4184 - val_accuracy: 0.3090\n","Epoch 63/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.9561 - accuracy: 0.7625 - val_loss: 2.4186 - val_accuracy: 0.3137\n","Epoch 64/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.9629 - accuracy: 0.7531 - val_loss: 2.4422 - val_accuracy: 0.3048\n","Epoch 65/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.9935 - accuracy: 0.7500 - val_loss: 2.4691 - val_accuracy: 0.3001\n","Epoch 66/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.8451 - accuracy: 0.8094 - val_loss: 2.4869 - val_accuracy: 0.2984\n","Epoch 67/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.8819 - accuracy: 0.7531 - val_loss: 2.4983 - val_accuracy: 0.3011\n","Epoch 68/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.8733 - accuracy: 0.8062 - val_loss: 2.5004 - val_accuracy: 0.2996\n","Epoch 69/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.8413 - accuracy: 0.8094 - val_loss: 2.5027 - val_accuracy: 0.3018\n","Epoch 70/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.8899 - accuracy: 0.7812 - val_loss: 2.5455 - val_accuracy: 0.2873\n","Epoch 71/400\n","10/10 [==============================] - 2s 226ms/step - loss: 0.8226 - accuracy: 0.7906 - val_loss: 2.5792 - val_accuracy: 0.2796\n","Epoch 72/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.8267 - accuracy: 0.7875 - val_loss: 2.5612 - val_accuracy: 0.2879\n","Epoch 73/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.7895 - accuracy: 0.8406 - val_loss: 2.5485 - val_accuracy: 0.2937\n","Epoch 74/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7960 - accuracy: 0.7969 - val_loss: 2.5611 - val_accuracy: 0.2917\n","Epoch 75/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.8080 - accuracy: 0.8000 - val_loss: 2.5895 - val_accuracy: 0.2852\n","Epoch 76/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.8387 - accuracy: 0.7688 - val_loss: 2.6244 - val_accuracy: 0.2790\n","Epoch 77/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.8033 - accuracy: 0.8000 - val_loss: 2.6313 - val_accuracy: 0.2792\n","Epoch 78/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.7494 - accuracy: 0.8219 - val_loss: 2.6158 - val_accuracy: 0.2873\n","Epoch 79/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.8104 - accuracy: 0.7875 - val_loss: 2.6162 - val_accuracy: 0.2871\n","Epoch 80/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.7527 - accuracy: 0.8250 - val_loss: 2.6459 - val_accuracy: 0.2801\n","Epoch 81/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7282 - accuracy: 0.8188 - val_loss: 2.6472 - val_accuracy: 0.2830\n","Epoch 82/400\n","10/10 [==============================] - 2s 236ms/step - loss: 0.8476 - accuracy: 0.7656 - val_loss: 2.6470 - val_accuracy: 0.2892\n","Epoch 83/400\n","10/10 [==============================] - 2s 234ms/step - loss: 0.7610 - accuracy: 0.8156 - val_loss: 2.7005 - val_accuracy: 0.2745\n","Epoch 84/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.7916 - accuracy: 0.7812 - val_loss: 2.7508 - val_accuracy: 0.2631\n","Epoch 85/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.7538 - accuracy: 0.8156 - val_loss: 2.7423 - val_accuracy: 0.2633\n","Epoch 86/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7168 - accuracy: 0.8062 - val_loss: 2.7259 - val_accuracy: 0.2699\n","Epoch 87/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7033 - accuracy: 0.8125 - val_loss: 2.7364 - val_accuracy: 0.2701\n","Epoch 88/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.7304 - accuracy: 0.8094 - val_loss: 2.7378 - val_accuracy: 0.2750\n","Epoch 89/400\n","10/10 [==============================] - 2s 233ms/step - loss: 0.7832 - accuracy: 0.8031 - val_loss: 2.7105 - val_accuracy: 0.2877\n","Epoch 90/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7190 - accuracy: 0.8125 - val_loss: 2.7327 - val_accuracy: 0.2791\n","Epoch 91/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.7232 - accuracy: 0.7906 - val_loss: 2.7671 - val_accuracy: 0.2728\n","Epoch 92/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6846 - accuracy: 0.8281 - val_loss: 2.7846 - val_accuracy: 0.2708\n","Epoch 93/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7343 - accuracy: 0.7781 - val_loss: 2.7970 - val_accuracy: 0.2683\n","Epoch 94/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.7073 - accuracy: 0.8281 - val_loss: 2.8132 - val_accuracy: 0.2637\n","Epoch 95/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.7295 - accuracy: 0.7719 - val_loss: 2.8026 - val_accuracy: 0.2682\n","Epoch 96/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.6814 - accuracy: 0.8344 - val_loss: 2.8007 - val_accuracy: 0.2715\n","Epoch 97/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.6949 - accuracy: 0.8094 - val_loss: 2.8121 - val_accuracy: 0.2750\n","Epoch 98/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.7477 - accuracy: 0.7781 - val_loss: 2.8490 - val_accuracy: 0.2693\n","Epoch 99/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.7593 - accuracy: 0.7719 - val_loss: 2.8485 - val_accuracy: 0.2695\n","Epoch 100/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6562 - accuracy: 0.8219 - val_loss: 2.8183 - val_accuracy: 0.2796\n","Epoch 101/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.7330 - accuracy: 0.7781 - val_loss: 2.8022 - val_accuracy: 0.2846\n","Epoch 102/400\n","10/10 [==============================] - 2s 225ms/step - loss: 0.6596 - accuracy: 0.8094 - val_loss: 2.7951 - val_accuracy: 0.2889\n","Epoch 103/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.6561 - accuracy: 0.8281 - val_loss: 2.8237 - val_accuracy: 0.2826\n","Epoch 104/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.6529 - accuracy: 0.8188 - val_loss: 2.8959 - val_accuracy: 0.2620\n","Epoch 105/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.6997 - accuracy: 0.8031 - val_loss: 2.8812 - val_accuracy: 0.2675\n","Epoch 106/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.6930 - accuracy: 0.8125 - val_loss: 2.8739 - val_accuracy: 0.2727\n","Epoch 107/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6668 - accuracy: 0.8219 - val_loss: 2.8652 - val_accuracy: 0.2750\n","Epoch 108/400\n","10/10 [==============================] - 2s 234ms/step - loss: 0.6234 - accuracy: 0.8313 - val_loss: 2.8595 - val_accuracy: 0.2766\n","Epoch 109/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.6746 - accuracy: 0.8031 - val_loss: 2.8686 - val_accuracy: 0.2785\n","Epoch 110/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.6191 - accuracy: 0.8469 - val_loss: 2.8815 - val_accuracy: 0.2767\n","Epoch 111/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5736 - accuracy: 0.8750 - val_loss: 2.8832 - val_accuracy: 0.2788\n","Epoch 112/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5845 - accuracy: 0.8438 - val_loss: 2.9095 - val_accuracy: 0.2736\n","Epoch 113/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6311 - accuracy: 0.8344 - val_loss: 2.9118 - val_accuracy: 0.2725\n","Epoch 114/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6289 - accuracy: 0.8281 - val_loss: 2.9135 - val_accuracy: 0.2751\n","Epoch 115/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6035 - accuracy: 0.8156 - val_loss: 2.9190 - val_accuracy: 0.2759\n","Epoch 116/400\n","10/10 [==============================] - 2s 235ms/step - loss: 0.5982 - accuracy: 0.8344 - val_loss: 2.8912 - val_accuracy: 0.2849\n","Epoch 117/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6246 - accuracy: 0.8313 - val_loss: 2.8992 - val_accuracy: 0.2838\n","Epoch 118/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5988 - accuracy: 0.8188 - val_loss: 2.9200 - val_accuracy: 0.2821\n","Epoch 119/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.6656 - accuracy: 0.8156 - val_loss: 2.9495 - val_accuracy: 0.2748\n","Epoch 120/400\n","10/10 [==============================] - 2s 235ms/step - loss: 0.6796 - accuracy: 0.8188 - val_loss: 3.0001 - val_accuracy: 0.2658\n","Epoch 121/400\n","10/10 [==============================] - 2s 235ms/step - loss: 0.6076 - accuracy: 0.8094 - val_loss: 3.0214 - val_accuracy: 0.2590\n","Epoch 122/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.5423 - accuracy: 0.8594 - val_loss: 2.9972 - val_accuracy: 0.2668\n","Epoch 123/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.6301 - accuracy: 0.8281 - val_loss: 2.9574 - val_accuracy: 0.2769\n","Epoch 124/400\n","10/10 [==============================] - 2s 225ms/step - loss: 0.6035 - accuracy: 0.8313 - val_loss: 2.9719 - val_accuracy: 0.2767\n","Epoch 125/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5845 - accuracy: 0.8625 - val_loss: 3.0043 - val_accuracy: 0.2711\n","Epoch 126/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5831 - accuracy: 0.8344 - val_loss: 3.0077 - val_accuracy: 0.2741\n","Epoch 127/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.5725 - accuracy: 0.8375 - val_loss: 3.0121 - val_accuracy: 0.2703\n","Epoch 128/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5703 - accuracy: 0.8438 - val_loss: 3.0081 - val_accuracy: 0.2723\n","Epoch 129/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.6056 - accuracy: 0.8313 - val_loss: 3.0286 - val_accuracy: 0.2679\n","Epoch 130/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5451 - accuracy: 0.8719 - val_loss: 3.0339 - val_accuracy: 0.2668\n","Epoch 131/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.5695 - accuracy: 0.8594 - val_loss: 3.0426 - val_accuracy: 0.2691\n","Epoch 132/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5767 - accuracy: 0.8281 - val_loss: 3.0530 - val_accuracy: 0.2673\n","Epoch 133/400\n","10/10 [==============================] - 2s 225ms/step - loss: 0.5630 - accuracy: 0.8469 - val_loss: 3.0359 - val_accuracy: 0.2739\n","Epoch 134/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.4963 - accuracy: 0.8656 - val_loss: 3.0642 - val_accuracy: 0.2690\n","Epoch 135/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5928 - accuracy: 0.8031 - val_loss: 3.0759 - val_accuracy: 0.2661\n","Epoch 136/400\n","10/10 [==============================] - 2s 225ms/step - loss: 0.6324 - accuracy: 0.8313 - val_loss: 3.0620 - val_accuracy: 0.2731\n","Epoch 137/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5313 - accuracy: 0.8438 - val_loss: 3.0499 - val_accuracy: 0.2758\n","Epoch 138/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.5809 - accuracy: 0.8062 - val_loss: 3.0882 - val_accuracy: 0.2680\n","Epoch 139/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5908 - accuracy: 0.8188 - val_loss: 3.1370 - val_accuracy: 0.2601\n","Epoch 140/400\n","10/10 [==============================] - 3s 291ms/step - loss: 0.5978 - accuracy: 0.8250 - val_loss: 3.1409 - val_accuracy: 0.2659\n","Epoch 141/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.5092 - accuracy: 0.8687 - val_loss: 3.1282 - val_accuracy: 0.2695\n","Epoch 142/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.5190 - accuracy: 0.8438 - val_loss: 3.1809 - val_accuracy: 0.2568\n","Epoch 143/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.5716 - accuracy: 0.8313 - val_loss: 3.1629 - val_accuracy: 0.2598\n","Epoch 144/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5589 - accuracy: 0.8250 - val_loss: 3.1544 - val_accuracy: 0.2642\n","Epoch 145/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.5985 - accuracy: 0.8188 - val_loss: 3.1642 - val_accuracy: 0.2599\n","Epoch 146/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5986 - accuracy: 0.8250 - val_loss: 3.1660 - val_accuracy: 0.2595\n","Epoch 147/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.6569 - accuracy: 0.7656 - val_loss: 3.1212 - val_accuracy: 0.2711\n","Epoch 148/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5976 - accuracy: 0.8000 - val_loss: 3.1357 - val_accuracy: 0.2725\n","Epoch 149/400\n","10/10 [==============================] - 2s 234ms/step - loss: 0.5457 - accuracy: 0.8438 - val_loss: 3.1652 - val_accuracy: 0.2672\n","Epoch 150/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.5140 - accuracy: 0.8594 - val_loss: 3.1900 - val_accuracy: 0.2618\n","Epoch 151/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5046 - accuracy: 0.8406 - val_loss: 3.1872 - val_accuracy: 0.2653\n","Epoch 152/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.5856 - accuracy: 0.8250 - val_loss: 3.1844 - val_accuracy: 0.2705\n","Epoch 153/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.5378 - accuracy: 0.8344 - val_loss: 3.1891 - val_accuracy: 0.2702\n","Epoch 154/400\n","10/10 [==============================] - 2s 234ms/step - loss: 0.5257 - accuracy: 0.8313 - val_loss: 3.1704 - val_accuracy: 0.2728\n","Epoch 155/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.5673 - accuracy: 0.8250 - val_loss: 3.1901 - val_accuracy: 0.2720\n","Epoch 156/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.5423 - accuracy: 0.8375 - val_loss: 3.1838 - val_accuracy: 0.2756\n","Epoch 157/400\n","10/10 [==============================] - 2s 233ms/step - loss: 0.5405 - accuracy: 0.8656 - val_loss: 3.1929 - val_accuracy: 0.2746\n","Epoch 158/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.4922 - accuracy: 0.8687 - val_loss: 3.1681 - val_accuracy: 0.2813\n","Epoch 159/400\n","10/10 [==============================] - 2s 235ms/step - loss: 0.5074 - accuracy: 0.8750 - val_loss: 3.2055 - val_accuracy: 0.2705\n","Epoch 160/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.4499 - accuracy: 0.9031 - val_loss: 3.2275 - val_accuracy: 0.2638\n","Epoch 161/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5316 - accuracy: 0.8375 - val_loss: 3.2623 - val_accuracy: 0.2585\n","Epoch 162/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.5219 - accuracy: 0.8562 - val_loss: 3.2616 - val_accuracy: 0.2617\n","Epoch 163/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5673 - accuracy: 0.8219 - val_loss: 3.2250 - val_accuracy: 0.2702\n","Epoch 164/400\n","10/10 [==============================] - 3s 291ms/step - loss: 0.5692 - accuracy: 0.8250 - val_loss: 3.2415 - val_accuracy: 0.2623\n","Epoch 165/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.5778 - accuracy: 0.8125 - val_loss: 3.2351 - val_accuracy: 0.2627\n","Epoch 166/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4500 - accuracy: 0.8719 - val_loss: 3.2242 - val_accuracy: 0.2657\n","Epoch 167/400\n","10/10 [==============================] - 2s 234ms/step - loss: 0.4894 - accuracy: 0.8406 - val_loss: 3.2258 - val_accuracy: 0.2635\n","Epoch 168/400\n","10/10 [==============================] - 2s 238ms/step - loss: 0.5153 - accuracy: 0.8469 - val_loss: 3.2506 - val_accuracy: 0.2572\n","Epoch 169/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5005 - accuracy: 0.8656 - val_loss: 3.2799 - val_accuracy: 0.2561\n","Epoch 170/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4563 - accuracy: 0.8969 - val_loss: 3.2822 - val_accuracy: 0.2586\n","Epoch 171/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4107 - accuracy: 0.8813 - val_loss: 3.2930 - val_accuracy: 0.2584\n","Epoch 172/400\n","10/10 [==============================] - 2s 239ms/step - loss: 0.5215 - accuracy: 0.8344 - val_loss: 3.3045 - val_accuracy: 0.2601\n","Epoch 173/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5007 - accuracy: 0.8656 - val_loss: 3.2925 - val_accuracy: 0.2646\n","Epoch 174/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4755 - accuracy: 0.8562 - val_loss: 3.2874 - val_accuracy: 0.2647\n","Epoch 175/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.4525 - accuracy: 0.8656 - val_loss: 3.2797 - val_accuracy: 0.2686\n","Epoch 176/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4629 - accuracy: 0.8813 - val_loss: 3.3119 - val_accuracy: 0.2644\n","Epoch 177/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5102 - accuracy: 0.8469 - val_loss: 3.3293 - val_accuracy: 0.2608\n","Epoch 178/400\n","10/10 [==============================] - 2s 234ms/step - loss: 0.4647 - accuracy: 0.8469 - val_loss: 3.3732 - val_accuracy: 0.2507\n","Epoch 179/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.5288 - accuracy: 0.8438 - val_loss: 3.3606 - val_accuracy: 0.2514\n","Epoch 180/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.5039 - accuracy: 0.8531 - val_loss: 3.3535 - val_accuracy: 0.2575\n","Epoch 181/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.4852 - accuracy: 0.8438 - val_loss: 3.3597 - val_accuracy: 0.2616\n","Epoch 182/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.5069 - accuracy: 0.8375 - val_loss: 3.3991 - val_accuracy: 0.2563\n","Epoch 183/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.5435 - accuracy: 0.8219 - val_loss: 3.3446 - val_accuracy: 0.2667\n","Epoch 184/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.5046 - accuracy: 0.8562 - val_loss: 3.3267 - val_accuracy: 0.2757\n","Epoch 185/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.5337 - accuracy: 0.8125 - val_loss: 3.3519 - val_accuracy: 0.2662\n","Epoch 186/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.5173 - accuracy: 0.8250 - val_loss: 3.3600 - val_accuracy: 0.2626\n","Epoch 187/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.4574 - accuracy: 0.8719 - val_loss: 3.3779 - val_accuracy: 0.2608\n","Epoch 188/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5051 - accuracy: 0.8719 - val_loss: 3.3679 - val_accuracy: 0.2640\n","Epoch 189/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4089 - accuracy: 0.8750 - val_loss: 3.3206 - val_accuracy: 0.2718\n","Epoch 190/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4813 - accuracy: 0.8687 - val_loss: 3.3009 - val_accuracy: 0.2778\n","Epoch 191/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4406 - accuracy: 0.8625 - val_loss: 3.3204 - val_accuracy: 0.2761\n","Epoch 192/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4182 - accuracy: 0.8687 - val_loss: 3.3539 - val_accuracy: 0.2705\n","Epoch 193/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4747 - accuracy: 0.8438 - val_loss: 3.3773 - val_accuracy: 0.2722\n","Epoch 194/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.4445 - accuracy: 0.8750 - val_loss: 3.3950 - val_accuracy: 0.2729\n","Epoch 195/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5462 - accuracy: 0.8531 - val_loss: 3.3991 - val_accuracy: 0.2683\n","Epoch 196/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4858 - accuracy: 0.8625 - val_loss: 3.4136 - val_accuracy: 0.2633\n","Epoch 197/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.4258 - accuracy: 0.8656 - val_loss: 3.4439 - val_accuracy: 0.2595\n","Epoch 198/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.4137 - accuracy: 0.8875 - val_loss: 3.4412 - val_accuracy: 0.2591\n","Epoch 199/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5425 - accuracy: 0.8219 - val_loss: 3.4319 - val_accuracy: 0.2592\n","Epoch 200/400\n","10/10 [==============================] - 2s 233ms/step - loss: 0.4956 - accuracy: 0.8594 - val_loss: 3.4359 - val_accuracy: 0.2572\n","Epoch 201/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4551 - accuracy: 0.8906 - val_loss: 3.4128 - val_accuracy: 0.2627\n","Epoch 202/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4341 - accuracy: 0.8906 - val_loss: 3.4160 - val_accuracy: 0.2617\n","Epoch 203/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.4721 - accuracy: 0.8500 - val_loss: 3.4346 - val_accuracy: 0.2579\n","Epoch 204/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.4668 - accuracy: 0.8781 - val_loss: 3.4500 - val_accuracy: 0.2597\n","Epoch 205/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.4537 - accuracy: 0.8594 - val_loss: 3.4772 - val_accuracy: 0.2594\n","Epoch 206/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.4931 - accuracy: 0.8313 - val_loss: 3.4828 - val_accuracy: 0.2576\n","Epoch 207/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.5221 - accuracy: 0.8406 - val_loss: 3.4391 - val_accuracy: 0.2692\n","Epoch 208/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.4576 - accuracy: 0.8719 - val_loss: 3.4313 - val_accuracy: 0.2711\n","Epoch 209/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4672 - accuracy: 0.8594 - val_loss: 3.4707 - val_accuracy: 0.2606\n","Epoch 210/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4641 - accuracy: 0.8469 - val_loss: 3.4646 - val_accuracy: 0.2605\n","Epoch 211/400\n","10/10 [==============================] - 2s 235ms/step - loss: 0.4296 - accuracy: 0.8813 - val_loss: 3.4255 - val_accuracy: 0.2685\n","Epoch 212/400\n","10/10 [==============================] - 3s 291ms/step - loss: 0.4243 - accuracy: 0.8781 - val_loss: 3.4103 - val_accuracy: 0.2742\n","Epoch 213/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.4221 - accuracy: 0.8781 - val_loss: 3.4278 - val_accuracy: 0.2724\n","Epoch 214/400\n","10/10 [==============================] - 2s 233ms/step - loss: 0.4439 - accuracy: 0.8687 - val_loss: 3.4759 - val_accuracy: 0.2632\n","Epoch 215/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.4541 - accuracy: 0.8562 - val_loss: 3.5049 - val_accuracy: 0.2566\n","Epoch 216/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4968 - accuracy: 0.8531 - val_loss: 3.5356 - val_accuracy: 0.2511\n","Epoch 217/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4827 - accuracy: 0.8531 - val_loss: 3.5252 - val_accuracy: 0.2563\n","Epoch 218/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.4125 - accuracy: 0.8625 - val_loss: 3.4911 - val_accuracy: 0.2676\n","Epoch 219/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4661 - accuracy: 0.8469 - val_loss: 3.4693 - val_accuracy: 0.2709\n","Epoch 220/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.3983 - accuracy: 0.8719 - val_loss: 3.4735 - val_accuracy: 0.2677\n","Epoch 221/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4262 - accuracy: 0.8719 - val_loss: 3.4673 - val_accuracy: 0.2672\n","Epoch 222/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4529 - accuracy: 0.8656 - val_loss: 3.4747 - val_accuracy: 0.2675\n","Epoch 223/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5362 - accuracy: 0.8531 - val_loss: 3.5055 - val_accuracy: 0.2642\n","Epoch 224/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5140 - accuracy: 0.8562 - val_loss: 3.5196 - val_accuracy: 0.2624\n","Epoch 225/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4562 - accuracy: 0.8719 - val_loss: 3.5432 - val_accuracy: 0.2608\n","Epoch 226/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.5570 - accuracy: 0.8125 - val_loss: 3.5689 - val_accuracy: 0.2586\n","Epoch 227/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4580 - accuracy: 0.8531 - val_loss: 3.5596 - val_accuracy: 0.2625\n","Epoch 228/400\n","10/10 [==============================] - 2s 224ms/step - loss: 0.4803 - accuracy: 0.8500 - val_loss: 3.5786 - val_accuracy: 0.2604\n","Epoch 229/400\n","10/10 [==============================] - 2s 222ms/step - loss: 0.3995 - accuracy: 0.8750 - val_loss: 3.6071 - val_accuracy: 0.2549\n","Epoch 230/400\n","10/10 [==============================] - 3s 291ms/step - loss: 0.4590 - accuracy: 0.8562 - val_loss: 3.5671 - val_accuracy: 0.2596\n","Epoch 231/400\n","10/10 [==============================] - 2s 226ms/step - loss: 0.4146 - accuracy: 0.8656 - val_loss: 3.5508 - val_accuracy: 0.2612\n","Epoch 232/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4123 - accuracy: 0.8875 - val_loss: 3.5697 - val_accuracy: 0.2575\n","Epoch 233/400\n","10/10 [==============================] - 2s 225ms/step - loss: 0.4028 - accuracy: 0.8781 - val_loss: 3.5911 - val_accuracy: 0.2561\n","Epoch 234/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.3658 - accuracy: 0.8969 - val_loss: 3.5822 - val_accuracy: 0.2578\n","Epoch 235/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4820 - accuracy: 0.8594 - val_loss: 3.5481 - val_accuracy: 0.2646\n","Epoch 236/400\n","10/10 [==============================] - 2s 223ms/step - loss: 0.4137 - accuracy: 0.8625 - val_loss: 3.5480 - val_accuracy: 0.2626\n","Epoch 237/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4596 - accuracy: 0.8656 - val_loss: 3.5811 - val_accuracy: 0.2557\n","Epoch 238/400\n","10/10 [==============================] - 2s 224ms/step - loss: 0.4146 - accuracy: 0.8594 - val_loss: 3.5934 - val_accuracy: 0.2547\n","Epoch 239/400\n","10/10 [==============================] - 2s 226ms/step - loss: 0.4194 - accuracy: 0.8531 - val_loss: 3.5752 - val_accuracy: 0.2560\n","Epoch 240/400\n","10/10 [==============================] - 2s 224ms/step - loss: 0.4149 - accuracy: 0.8844 - val_loss: 3.5650 - val_accuracy: 0.2578\n","Epoch 241/400\n","10/10 [==============================] - 2s 223ms/step - loss: 0.4394 - accuracy: 0.8656 - val_loss: 3.5541 - val_accuracy: 0.2621\n","Epoch 242/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.5333 - accuracy: 0.8031 - val_loss: 3.5460 - val_accuracy: 0.2662\n","Epoch 243/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4437 - accuracy: 0.8594 - val_loss: 3.5162 - val_accuracy: 0.2702\n","Epoch 244/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.5080 - accuracy: 0.8438 - val_loss: 3.5098 - val_accuracy: 0.2729\n","Epoch 245/400\n","10/10 [==============================] - 2s 226ms/step - loss: 0.4430 - accuracy: 0.8719 - val_loss: 3.5142 - val_accuracy: 0.2762\n","Epoch 246/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4251 - accuracy: 0.8844 - val_loss: 3.5572 - val_accuracy: 0.2672\n","Epoch 247/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4789 - accuracy: 0.8594 - val_loss: 3.6127 - val_accuracy: 0.2574\n","Epoch 248/400\n","10/10 [==============================] - 2s 238ms/step - loss: 0.5355 - accuracy: 0.8125 - val_loss: 3.5948 - val_accuracy: 0.2600\n","Epoch 249/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.4161 - accuracy: 0.8906 - val_loss: 3.5797 - val_accuracy: 0.2631\n","Epoch 250/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4611 - accuracy: 0.8531 - val_loss: 3.5671 - val_accuracy: 0.2636\n","Epoch 251/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4342 - accuracy: 0.8750 - val_loss: 3.5354 - val_accuracy: 0.2707\n","Epoch 252/400\n","10/10 [==============================] - 2s 233ms/step - loss: 0.4260 - accuracy: 0.8656 - val_loss: 3.5344 - val_accuracy: 0.2730\n","Epoch 253/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.6016 - accuracy: 0.7969 - val_loss: 3.5786 - val_accuracy: 0.2669\n","Epoch 254/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3916 - accuracy: 0.8938 - val_loss: 3.5864 - val_accuracy: 0.2675\n","Epoch 255/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4190 - accuracy: 0.8719 - val_loss: 3.5926 - val_accuracy: 0.2690\n","Epoch 256/400\n","10/10 [==============================] - 2s 235ms/step - loss: 0.4481 - accuracy: 0.8531 - val_loss: 3.5894 - val_accuracy: 0.2693\n","Epoch 257/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4705 - accuracy: 0.8469 - val_loss: 3.5699 - val_accuracy: 0.2730\n","Epoch 258/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4273 - accuracy: 0.8875 - val_loss: 3.5873 - val_accuracy: 0.2698\n","Epoch 259/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.4959 - accuracy: 0.8281 - val_loss: 3.6063 - val_accuracy: 0.2689\n","Epoch 260/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.4940 - accuracy: 0.8469 - val_loss: 3.6431 - val_accuracy: 0.2647\n","Epoch 261/400\n","10/10 [==============================] - 2s 235ms/step - loss: 0.4063 - accuracy: 0.8813 - val_loss: 3.6648 - val_accuracy: 0.2619\n","Epoch 262/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4004 - accuracy: 0.8781 - val_loss: 3.6643 - val_accuracy: 0.2629\n","Epoch 263/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4128 - accuracy: 0.8687 - val_loss: 3.6363 - val_accuracy: 0.2668\n","Epoch 264/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.4185 - accuracy: 0.8562 - val_loss: 3.6527 - val_accuracy: 0.2638\n","Epoch 265/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4185 - accuracy: 0.8687 - val_loss: 3.6755 - val_accuracy: 0.2585\n","Epoch 266/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.5322 - accuracy: 0.8438 - val_loss: 3.6925 - val_accuracy: 0.2563\n","Epoch 267/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.4234 - accuracy: 0.8844 - val_loss: 3.7204 - val_accuracy: 0.2536\n","Epoch 268/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4317 - accuracy: 0.8656 - val_loss: 3.6741 - val_accuracy: 0.2621\n","Epoch 269/400\n","10/10 [==============================] - 2s 233ms/step - loss: 0.4521 - accuracy: 0.8750 - val_loss: 3.6306 - val_accuracy: 0.2667\n","Epoch 270/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.3694 - accuracy: 0.8844 - val_loss: 3.6197 - val_accuracy: 0.2652\n","Epoch 271/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.3639 - accuracy: 0.8781 - val_loss: 3.6142 - val_accuracy: 0.2668\n","Epoch 272/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4560 - accuracy: 0.8781 - val_loss: 3.6175 - val_accuracy: 0.2701\n","Epoch 273/400\n","10/10 [==============================] - 3s 293ms/step - loss: 0.3342 - accuracy: 0.9062 - val_loss: 3.6278 - val_accuracy: 0.2683\n","Epoch 274/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4825 - accuracy: 0.8438 - val_loss: 3.6328 - val_accuracy: 0.2683\n","Epoch 275/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4972 - accuracy: 0.8469 - val_loss: 3.6238 - val_accuracy: 0.2729\n","Epoch 276/400\n","10/10 [==============================] - 2s 237ms/step - loss: 0.4184 - accuracy: 0.8594 - val_loss: 3.6317 - val_accuracy: 0.2738\n","Epoch 277/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.3993 - accuracy: 0.8719 - val_loss: 3.6520 - val_accuracy: 0.2707\n","Epoch 278/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3442 - accuracy: 0.8938 - val_loss: 3.6661 - val_accuracy: 0.2693\n","Epoch 279/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.3840 - accuracy: 0.8969 - val_loss: 3.6415 - val_accuracy: 0.2759\n","Epoch 280/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.3892 - accuracy: 0.8906 - val_loss: 3.6161 - val_accuracy: 0.2832\n","Epoch 281/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4079 - accuracy: 0.8813 - val_loss: 3.6305 - val_accuracy: 0.2784\n","Epoch 282/400\n","10/10 [==============================] - 3s 292ms/step - loss: 0.3966 - accuracy: 0.8906 - val_loss: 3.6867 - val_accuracy: 0.2681\n","Epoch 283/400\n","10/10 [==============================] - 2s 226ms/step - loss: 0.4325 - accuracy: 0.8656 - val_loss: 3.7319 - val_accuracy: 0.2563\n","Epoch 284/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4409 - accuracy: 0.8813 - val_loss: 3.7398 - val_accuracy: 0.2567\n","Epoch 285/400\n","10/10 [==============================] - 2s 237ms/step - loss: 0.4209 - accuracy: 0.8750 - val_loss: 3.7096 - val_accuracy: 0.2653\n","Epoch 286/400\n","10/10 [==============================] - 3s 291ms/step - loss: 0.4095 - accuracy: 0.8781 - val_loss: 3.6734 - val_accuracy: 0.2740\n","Epoch 287/400\n","10/10 [==============================] - 2s 235ms/step - loss: 0.3940 - accuracy: 0.8813 - val_loss: 3.6564 - val_accuracy: 0.2813\n","Epoch 288/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.4919 - accuracy: 0.8500 - val_loss: 3.6475 - val_accuracy: 0.2796\n","Epoch 289/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.3530 - accuracy: 0.8969 - val_loss: 3.6450 - val_accuracy: 0.2768\n","Epoch 290/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4273 - accuracy: 0.8375 - val_loss: 3.7023 - val_accuracy: 0.2677\n","Epoch 291/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3638 - accuracy: 0.8906 - val_loss: 3.7351 - val_accuracy: 0.2666\n","Epoch 292/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4125 - accuracy: 0.8531 - val_loss: 3.7570 - val_accuracy: 0.2621\n","Epoch 293/400\n","10/10 [==============================] - 2s 236ms/step - loss: 0.4003 - accuracy: 0.8719 - val_loss: 3.7495 - val_accuracy: 0.2599\n","Epoch 294/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.3904 - accuracy: 0.8594 - val_loss: 3.7424 - val_accuracy: 0.2600\n","Epoch 295/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.3728 - accuracy: 0.8781 - val_loss: 3.7577 - val_accuracy: 0.2611\n","Epoch 296/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4512 - accuracy: 0.8656 - val_loss: 3.7331 - val_accuracy: 0.2707\n","Epoch 297/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4860 - accuracy: 0.8344 - val_loss: 3.7737 - val_accuracy: 0.2626\n","Epoch 298/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4176 - accuracy: 0.8594 - val_loss: 3.7714 - val_accuracy: 0.2625\n","Epoch 299/400\n","10/10 [==============================] - 2s 239ms/step - loss: 0.3949 - accuracy: 0.8656 - val_loss: 3.7392 - val_accuracy: 0.2693\n","Epoch 300/400\n","10/10 [==============================] - 2s 234ms/step - loss: 0.4015 - accuracy: 0.8656 - val_loss: 3.6986 - val_accuracy: 0.2777\n","Epoch 301/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.3824 - accuracy: 0.8719 - val_loss: 3.7383 - val_accuracy: 0.2746\n","Epoch 302/400\n","10/10 [==============================] - 3s 292ms/step - loss: 0.4314 - accuracy: 0.8531 - val_loss: 3.7749 - val_accuracy: 0.2702\n","Epoch 303/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4349 - accuracy: 0.8625 - val_loss: 3.7953 - val_accuracy: 0.2621\n","Epoch 304/400\n","10/10 [==============================] - 2s 235ms/step - loss: 0.3684 - accuracy: 0.8844 - val_loss: 3.7889 - val_accuracy: 0.2604\n","Epoch 305/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4272 - accuracy: 0.8594 - val_loss: 3.8005 - val_accuracy: 0.2598\n","Epoch 306/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.3826 - accuracy: 0.8906 - val_loss: 3.7994 - val_accuracy: 0.2585\n","Epoch 307/400\n","10/10 [==============================] - 2s 237ms/step - loss: 0.3970 - accuracy: 0.8750 - val_loss: 3.7801 - val_accuracy: 0.2619\n","Epoch 308/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4908 - accuracy: 0.8281 - val_loss: 3.7652 - val_accuracy: 0.2657\n","Epoch 309/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4396 - accuracy: 0.8469 - val_loss: 3.7690 - val_accuracy: 0.2640\n","Epoch 310/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.3882 - accuracy: 0.8687 - val_loss: 3.7989 - val_accuracy: 0.2596\n","Epoch 311/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.3895 - accuracy: 0.8562 - val_loss: 3.7936 - val_accuracy: 0.2612\n","Epoch 312/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4289 - accuracy: 0.8875 - val_loss: 3.8016 - val_accuracy: 0.2632\n","Epoch 313/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4184 - accuracy: 0.8625 - val_loss: 3.7827 - val_accuracy: 0.2669\n","Epoch 314/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3935 - accuracy: 0.8875 - val_loss: 3.7909 - val_accuracy: 0.2656\n","Epoch 315/400\n","10/10 [==============================] - 3s 292ms/step - loss: 0.3576 - accuracy: 0.8875 - val_loss: 3.8136 - val_accuracy: 0.2640\n","Epoch 316/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4548 - accuracy: 0.8562 - val_loss: 3.8153 - val_accuracy: 0.2665\n","Epoch 317/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.4073 - accuracy: 0.8719 - val_loss: 3.8280 - val_accuracy: 0.2664\n","Epoch 318/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.4216 - accuracy: 0.8625 - val_loss: 3.8842 - val_accuracy: 0.2569\n","Epoch 319/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4361 - accuracy: 0.8781 - val_loss: 3.9053 - val_accuracy: 0.2504\n","Epoch 320/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3807 - accuracy: 0.8875 - val_loss: 3.9469 - val_accuracy: 0.2445\n","Epoch 321/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3947 - accuracy: 0.8687 - val_loss: 3.9227 - val_accuracy: 0.2506\n","Epoch 322/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.4342 - accuracy: 0.8531 - val_loss: 3.8522 - val_accuracy: 0.2630\n","Epoch 323/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3742 - accuracy: 0.8906 - val_loss: 3.8557 - val_accuracy: 0.2613\n","Epoch 324/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4045 - accuracy: 0.8750 - val_loss: 3.8290 - val_accuracy: 0.2649\n","Epoch 325/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3501 - accuracy: 0.8813 - val_loss: 3.7853 - val_accuracy: 0.2742\n","Epoch 326/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.3344 - accuracy: 0.9094 - val_loss: 3.7714 - val_accuracy: 0.2783\n","Epoch 327/400\n","10/10 [==============================] - 2s 226ms/step - loss: 0.4037 - accuracy: 0.8781 - val_loss: 3.7939 - val_accuracy: 0.2745\n","Epoch 328/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4327 - accuracy: 0.8531 - val_loss: 3.8214 - val_accuracy: 0.2674\n","Epoch 329/400\n","10/10 [==============================] - 2s 233ms/step - loss: 0.3729 - accuracy: 0.8781 - val_loss: 3.8257 - val_accuracy: 0.2666\n","Epoch 330/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4506 - accuracy: 0.8438 - val_loss: 3.8454 - val_accuracy: 0.2668\n","Epoch 331/400\n","10/10 [==============================] - 2s 237ms/step - loss: 0.4212 - accuracy: 0.8531 - val_loss: 3.8625 - val_accuracy: 0.2654\n","Epoch 332/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.4474 - accuracy: 0.8594 - val_loss: 3.8996 - val_accuracy: 0.2562\n","Epoch 333/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4422 - accuracy: 0.8531 - val_loss: 3.9301 - val_accuracy: 0.2497\n","Epoch 334/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.4533 - accuracy: 0.8531 - val_loss: 3.9290 - val_accuracy: 0.2519\n","Epoch 335/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3794 - accuracy: 0.8844 - val_loss: 3.9334 - val_accuracy: 0.2543\n","Epoch 336/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4015 - accuracy: 0.8719 - val_loss: 3.9109 - val_accuracy: 0.2580\n","Epoch 337/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.3212 - accuracy: 0.9094 - val_loss: 3.8861 - val_accuracy: 0.2631\n","Epoch 338/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.4163 - accuracy: 0.8813 - val_loss: 3.8701 - val_accuracy: 0.2653\n","Epoch 339/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.4736 - accuracy: 0.8406 - val_loss: 3.8788 - val_accuracy: 0.2650\n","Epoch 340/400\n","10/10 [==============================] - 3s 292ms/step - loss: 0.4118 - accuracy: 0.8625 - val_loss: 3.9308 - val_accuracy: 0.2580\n","Epoch 341/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4060 - accuracy: 0.8594 - val_loss: 3.9872 - val_accuracy: 0.2529\n","Epoch 342/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.3516 - accuracy: 0.8813 - val_loss: 3.9646 - val_accuracy: 0.2588\n","Epoch 343/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3542 - accuracy: 0.8938 - val_loss: 3.9406 - val_accuracy: 0.2661\n","Epoch 344/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.2695 - accuracy: 0.9281 - val_loss: 3.9390 - val_accuracy: 0.2658\n","Epoch 345/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4021 - accuracy: 0.8562 - val_loss: 3.9414 - val_accuracy: 0.2631\n","Epoch 346/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.3918 - accuracy: 0.8781 - val_loss: 3.9401 - val_accuracy: 0.2598\n","Epoch 347/400\n","10/10 [==============================] - 2s 226ms/step - loss: 0.4088 - accuracy: 0.8656 - val_loss: 3.9075 - val_accuracy: 0.2670\n","Epoch 348/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3748 - accuracy: 0.8969 - val_loss: 3.9591 - val_accuracy: 0.2629\n","Epoch 349/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3805 - accuracy: 0.8813 - val_loss: 4.0376 - val_accuracy: 0.2528\n","Epoch 350/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4090 - accuracy: 0.8719 - val_loss: 4.0116 - val_accuracy: 0.2545\n","Epoch 351/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4038 - accuracy: 0.8750 - val_loss: 3.9424 - val_accuracy: 0.2609\n","Epoch 352/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.3093 - accuracy: 0.9094 - val_loss: 3.9320 - val_accuracy: 0.2655\n","Epoch 353/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.3884 - accuracy: 0.8750 - val_loss: 3.9365 - val_accuracy: 0.2662\n","Epoch 354/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3784 - accuracy: 0.8875 - val_loss: 3.9501 - val_accuracy: 0.2643\n","Epoch 355/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.4223 - accuracy: 0.8781 - val_loss: 3.9509 - val_accuracy: 0.2611\n","Epoch 356/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.3914 - accuracy: 0.8719 - val_loss: 3.9524 - val_accuracy: 0.2599\n","Epoch 357/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4139 - accuracy: 0.8687 - val_loss: 3.9719 - val_accuracy: 0.2577\n","Epoch 358/400\n","10/10 [==============================] - 3s 292ms/step - loss: 0.4541 - accuracy: 0.8531 - val_loss: 3.9740 - val_accuracy: 0.2580\n","Epoch 359/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.3470 - accuracy: 0.9062 - val_loss: 3.9933 - val_accuracy: 0.2548\n","Epoch 360/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.4711 - accuracy: 0.8562 - val_loss: 4.0704 - val_accuracy: 0.2422\n","Epoch 361/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4584 - accuracy: 0.8438 - val_loss: 4.0887 - val_accuracy: 0.2415\n","Epoch 362/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4549 - accuracy: 0.8469 - val_loss: 4.1076 - val_accuracy: 0.2415\n","Epoch 363/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3585 - accuracy: 0.8875 - val_loss: 4.1301 - val_accuracy: 0.2399\n","Epoch 364/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.4252 - accuracy: 0.8625 - val_loss: 4.1239 - val_accuracy: 0.2428\n","Epoch 365/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3672 - accuracy: 0.8750 - val_loss: 4.0938 - val_accuracy: 0.2481\n","Epoch 366/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.3401 - accuracy: 0.8875 - val_loss: 4.0472 - val_accuracy: 0.2541\n","Epoch 367/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4039 - accuracy: 0.8875 - val_loss: 4.0205 - val_accuracy: 0.2593\n","Epoch 368/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4373 - accuracy: 0.8406 - val_loss: 4.0682 - val_accuracy: 0.2546\n","Epoch 369/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3909 - accuracy: 0.8625 - val_loss: 4.0670 - val_accuracy: 0.2530\n","Epoch 370/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.4173 - accuracy: 0.8625 - val_loss: 4.0924 - val_accuracy: 0.2444\n","Epoch 371/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.4547 - accuracy: 0.8656 - val_loss: 4.0926 - val_accuracy: 0.2427\n","Epoch 372/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4233 - accuracy: 0.8500 - val_loss: 4.0662 - val_accuracy: 0.2476\n","Epoch 373/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.3869 - accuracy: 0.8906 - val_loss: 4.0431 - val_accuracy: 0.2567\n","Epoch 374/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3815 - accuracy: 0.8750 - val_loss: 4.0276 - val_accuracy: 0.2622\n","Epoch 375/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4922 - accuracy: 0.8313 - val_loss: 4.0482 - val_accuracy: 0.2589\n","Epoch 376/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3127 - accuracy: 0.9031 - val_loss: 4.0550 - val_accuracy: 0.2570\n","Epoch 377/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4866 - accuracy: 0.8344 - val_loss: 4.0299 - val_accuracy: 0.2595\n","Epoch 378/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3957 - accuracy: 0.8687 - val_loss: 4.0306 - val_accuracy: 0.2560\n","Epoch 379/400\n","10/10 [==============================] - 2s 233ms/step - loss: 0.4499 - accuracy: 0.8750 - val_loss: 4.0320 - val_accuracy: 0.2562\n","Epoch 380/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4318 - accuracy: 0.8531 - val_loss: 4.0418 - val_accuracy: 0.2603\n","Epoch 381/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.4355 - accuracy: 0.8594 - val_loss: 4.0096 - val_accuracy: 0.2629\n","Epoch 382/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.3734 - accuracy: 0.8906 - val_loss: 4.0205 - val_accuracy: 0.2595\n","Epoch 383/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4676 - accuracy: 0.8344 - val_loss: 4.0144 - val_accuracy: 0.2611\n","Epoch 384/400\n","10/10 [==============================] - 2s 227ms/step - loss: 0.4201 - accuracy: 0.8500 - val_loss: 3.9531 - val_accuracy: 0.2690\n","Epoch 385/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.4275 - accuracy: 0.8500 - val_loss: 3.9290 - val_accuracy: 0.2759\n","Epoch 386/400\n","10/10 [==============================] - 2s 230ms/step - loss: 0.5067 - accuracy: 0.8500 - val_loss: 3.9951 - val_accuracy: 0.2679\n","Epoch 387/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4165 - accuracy: 0.8469 - val_loss: 4.0949 - val_accuracy: 0.2543\n","Epoch 388/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.4380 - accuracy: 0.8438 - val_loss: 4.1415 - val_accuracy: 0.2480\n","Epoch 389/400\n","10/10 [==============================] - 2s 225ms/step - loss: 0.3998 - accuracy: 0.8719 - val_loss: 4.1310 - val_accuracy: 0.2491\n","Epoch 390/400\n","10/10 [==============================] - 3s 289ms/step - loss: 0.3111 - accuracy: 0.8969 - val_loss: 4.1003 - val_accuracy: 0.2510\n","Epoch 391/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3670 - accuracy: 0.8875 - val_loss: 4.0929 - val_accuracy: 0.2522\n","Epoch 392/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4094 - accuracy: 0.8844 - val_loss: 4.0920 - val_accuracy: 0.2534\n","Epoch 393/400\n","10/10 [==============================] - 2s 228ms/step - loss: 0.4384 - accuracy: 0.8531 - val_loss: 4.0766 - val_accuracy: 0.2557\n","Epoch 394/400\n","10/10 [==============================] - 2s 231ms/step - loss: 0.4400 - accuracy: 0.8406 - val_loss: 4.0328 - val_accuracy: 0.2620\n","Epoch 395/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.3360 - accuracy: 0.8813 - val_loss: 4.0462 - val_accuracy: 0.2611\n","Epoch 396/400\n","10/10 [==============================] - 2s 232ms/step - loss: 0.4259 - accuracy: 0.8594 - val_loss: 4.0893 - val_accuracy: 0.2545\n","Epoch 397/400\n","10/10 [==============================] - 3s 290ms/step - loss: 0.4308 - accuracy: 0.8375 - val_loss: 4.0799 - val_accuracy: 0.2549\n","Epoch 398/400\n","10/10 [==============================] - 2s 229ms/step - loss: 0.3844 - accuracy: 0.8781 - val_loss: 4.0195 - val_accuracy: 0.2629\n","Epoch 399/400\n","10/10 [==============================] - 2s 235ms/step - loss: 0.3839 - accuracy: 0.8844 - val_loss: 3.9960 - val_accuracy: 0.2693\n","Epoch 400/400\n","10/10 [==============================] - 2s 236ms/step - loss: 0.3868 - accuracy: 0.8750 - val_loss: 4.0109 - val_accuracy: 0.2671\n"]}]},{"cell_type":"code","source":["# further modifying the previous one that had the lowest validation loss\n","# clearly we need some strong regularization with this small training set\n","layer_list = [ #520 parameters in input\n","          layers.Dropout(0.6),\n","          layers.BatchNormalization(),\n","          #layers.Dropout(0.4),\n","          layers.Dense(10,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=400, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"qwvTXjekJK21","executionInfo":{"status":"error","timestamp":1652038556365,"user_tz":240,"elapsed":208856,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"f30decc4-0d92-4777-f611-517a53cb90d4"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","10/10 [==============================] - 4s 320ms/step - loss: 3.1920 - accuracy: 0.0906 - val_loss: 3.3433 - val_accuracy: 0.0606\n","Epoch 2/400\n","10/10 [==============================] - 3s 289ms/step - loss: 3.1685 - accuracy: 0.0781 - val_loss: 3.1523 - val_accuracy: 0.0585\n","Epoch 3/400\n","10/10 [==============================] - 2s 234ms/step - loss: 2.9601 - accuracy: 0.1156 - val_loss: 3.0727 - val_accuracy: 0.0617\n","Epoch 4/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.9290 - accuracy: 0.1094 - val_loss: 3.0011 - val_accuracy: 0.0696\n","Epoch 5/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.8302 - accuracy: 0.1219 - val_loss: 2.9387 - val_accuracy: 0.0809\n","Epoch 6/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.7886 - accuracy: 0.1437 - val_loss: 2.8875 - val_accuracy: 0.0989\n","Epoch 7/400\n","10/10 [==============================] - 2s 227ms/step - loss: 2.7031 - accuracy: 0.1437 - val_loss: 2.8468 - val_accuracy: 0.1124\n","Epoch 8/400\n","10/10 [==============================] - 2s 225ms/step - loss: 2.6508 - accuracy: 0.1594 - val_loss: 2.8169 - val_accuracy: 0.1253\n","Epoch 9/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.6815 - accuracy: 0.1656 - val_loss: 2.7853 - val_accuracy: 0.1417\n","Epoch 10/400\n","10/10 [==============================] - 2s 229ms/step - loss: 2.5517 - accuracy: 0.1781 - val_loss: 2.7548 - val_accuracy: 0.1527\n","Epoch 11/400\n","10/10 [==============================] - 2s 226ms/step - loss: 2.5771 - accuracy: 0.1750 - val_loss: 2.7208 - val_accuracy: 0.1665\n","Epoch 12/400\n","10/10 [==============================] - 2s 230ms/step - loss: 2.5269 - accuracy: 0.2000 - val_loss: 2.6975 - val_accuracy: 0.1764\n","Epoch 13/400\n","10/10 [==============================] - 2s 236ms/step - loss: 2.5383 - accuracy: 0.2062 - val_loss: 2.6710 - val_accuracy: 0.1907\n","Epoch 14/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4893 - accuracy: 0.2062 - val_loss: 2.6537 - val_accuracy: 0.1991\n","Epoch 15/400\n","10/10 [==============================] - 2s 236ms/step - loss: 2.5270 - accuracy: 0.2188 - val_loss: 2.6289 - val_accuracy: 0.2125\n","Epoch 16/400\n","10/10 [==============================] - 2s 237ms/step - loss: 2.4952 - accuracy: 0.2188 - val_loss: 2.6070 - val_accuracy: 0.2222\n","Epoch 17/400\n","10/10 [==============================] - 2s 239ms/step - loss: 2.4451 - accuracy: 0.2531 - val_loss: 2.5870 - val_accuracy: 0.2312\n","Epoch 18/400\n","10/10 [==============================] - 2s 237ms/step - loss: 2.3940 - accuracy: 0.2250 - val_loss: 2.5671 - val_accuracy: 0.2380\n","Epoch 19/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.4282 - accuracy: 0.2188 - val_loss: 2.5598 - val_accuracy: 0.2422\n","Epoch 20/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.3651 - accuracy: 0.2406 - val_loss: 2.5484 - val_accuracy: 0.2479\n","Epoch 21/400\n","10/10 [==============================] - 2s 236ms/step - loss: 2.3463 - accuracy: 0.2656 - val_loss: 2.5388 - val_accuracy: 0.2522\n","Epoch 22/400\n","10/10 [==============================] - 2s 233ms/step - loss: 2.3507 - accuracy: 0.2750 - val_loss: 2.5295 - val_accuracy: 0.2553\n","Epoch 23/400\n","10/10 [==============================] - 2s 235ms/step - loss: 2.2862 - accuracy: 0.3125 - val_loss: 2.5239 - val_accuracy: 0.2581\n","Epoch 24/400\n","10/10 [==============================] - 2s 234ms/step - loss: 2.2539 - accuracy: 0.2937 - val_loss: 2.5136 - val_accuracy: 0.2639\n","Epoch 25/400\n","10/10 [==============================] - 2s 238ms/step - loss: 2.2706 - accuracy: 0.2500 - val_loss: 2.5061 - val_accuracy: 0.2668\n","Epoch 26/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.2257 - accuracy: 0.2875 - val_loss: 2.4973 - val_accuracy: 0.2709\n","Epoch 27/400\n","10/10 [==============================] - 2s 235ms/step - loss: 2.2277 - accuracy: 0.3219 - val_loss: 2.4890 - val_accuracy: 0.2749\n","Epoch 28/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.2366 - accuracy: 0.3187 - val_loss: 2.4775 - val_accuracy: 0.2799\n","Epoch 29/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.1969 - accuracy: 0.3125 - val_loss: 2.4681 - val_accuracy: 0.2849\n","Epoch 30/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.2018 - accuracy: 0.3031 - val_loss: 2.4570 - val_accuracy: 0.2910\n","Epoch 31/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1734 - accuracy: 0.3094 - val_loss: 2.4473 - val_accuracy: 0.2954\n","Epoch 32/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.1314 - accuracy: 0.3250 - val_loss: 2.4398 - val_accuracy: 0.2997\n","Epoch 33/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0864 - accuracy: 0.3688 - val_loss: 2.4360 - val_accuracy: 0.3013\n","Epoch 34/400\n","10/10 [==============================] - 2s 234ms/step - loss: 2.1469 - accuracy: 0.3281 - val_loss: 2.4281 - val_accuracy: 0.3051\n","Epoch 35/400\n","10/10 [==============================] - 2s 233ms/step - loss: 2.1428 - accuracy: 0.3250 - val_loss: 2.4266 - val_accuracy: 0.3045\n","Epoch 36/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.1232 - accuracy: 0.3438 - val_loss: 2.4201 - val_accuracy: 0.3076\n","Epoch 37/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.1332 - accuracy: 0.3375 - val_loss: 2.4191 - val_accuracy: 0.3070\n","Epoch 38/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.1054 - accuracy: 0.3469 - val_loss: 2.4156 - val_accuracy: 0.3072\n","Epoch 39/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.1212 - accuracy: 0.3375 - val_loss: 2.4094 - val_accuracy: 0.3089\n","Epoch 40/400\n","10/10 [==============================] - 2s 234ms/step - loss: 2.0694 - accuracy: 0.3656 - val_loss: 2.4089 - val_accuracy: 0.3069\n","Epoch 41/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.0167 - accuracy: 0.3844 - val_loss: 2.4101 - val_accuracy: 0.3032\n","Epoch 42/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.0576 - accuracy: 0.3531 - val_loss: 2.4077 - val_accuracy: 0.3017\n","Epoch 43/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0388 - accuracy: 0.3469 - val_loss: 2.3987 - val_accuracy: 0.3071\n","Epoch 44/400\n","10/10 [==============================] - 2s 232ms/step - loss: 2.0399 - accuracy: 0.3812 - val_loss: 2.3991 - val_accuracy: 0.3058\n","Epoch 45/400\n","10/10 [==============================] - 2s 231ms/step - loss: 2.0425 - accuracy: 0.3562 - val_loss: 2.3967 - val_accuracy: 0.3066\n","Epoch 46/400\n","10/10 [==============================] - 2s 228ms/step - loss: 1.9828 - accuracy: 0.3969 - val_loss: 2.3943 - val_accuracy: 0.3070\n","Epoch 47/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9709 - accuracy: 0.3906 - val_loss: 2.3907 - val_accuracy: 0.3084\n","Epoch 48/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.0096 - accuracy: 0.4031 - val_loss: 2.3894 - val_accuracy: 0.3086\n","Epoch 49/400\n","10/10 [==============================] - 2s 233ms/step - loss: 2.0042 - accuracy: 0.3656 - val_loss: 2.3925 - val_accuracy: 0.3051\n","Epoch 50/400\n","10/10 [==============================] - 2s 226ms/step - loss: 1.9175 - accuracy: 0.4344 - val_loss: 2.3922 - val_accuracy: 0.3052\n","Epoch 51/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9577 - accuracy: 0.3812 - val_loss: 2.3906 - val_accuracy: 0.3033\n","Epoch 52/400\n","10/10 [==============================] - 2s 228ms/step - loss: 1.9761 - accuracy: 0.3812 - val_loss: 2.3854 - val_accuracy: 0.3039\n","Epoch 53/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9260 - accuracy: 0.4344 - val_loss: 2.3864 - val_accuracy: 0.3013\n","Epoch 54/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9705 - accuracy: 0.4219 - val_loss: 2.3887 - val_accuracy: 0.2976\n","Epoch 55/400\n","10/10 [==============================] - 2s 239ms/step - loss: 1.9327 - accuracy: 0.3969 - val_loss: 2.3887 - val_accuracy: 0.2955\n","Epoch 56/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9652 - accuracy: 0.3688 - val_loss: 2.3853 - val_accuracy: 0.2967\n","Epoch 57/400\n","10/10 [==============================] - 2s 234ms/step - loss: 1.9166 - accuracy: 0.4156 - val_loss: 2.3841 - val_accuracy: 0.2970\n","Epoch 58/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8984 - accuracy: 0.4313 - val_loss: 2.3835 - val_accuracy: 0.2971\n","Epoch 59/400\n","10/10 [==============================] - 2s 228ms/step - loss: 1.8946 - accuracy: 0.4125 - val_loss: 2.3801 - val_accuracy: 0.2971\n","Epoch 60/400\n","10/10 [==============================] - 2s 232ms/step - loss: 1.9223 - accuracy: 0.4094 - val_loss: 2.3800 - val_accuracy: 0.2968\n","Epoch 61/400\n","10/10 [==============================] - 2s 231ms/step - loss: 1.9252 - accuracy: 0.3969 - val_loss: 2.3813 - val_accuracy: 0.2951\n","Epoch 62/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8762 - accuracy: 0.4250 - val_loss: 2.3828 - val_accuracy: 0.2939\n","Epoch 63/400\n","10/10 [==============================] - 3s 291ms/step - loss: 1.7945 - accuracy: 0.4688 - val_loss: 2.3876 - val_accuracy: 0.2894\n","Epoch 64/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8287 - accuracy: 0.4406 - val_loss: 2.3865 - val_accuracy: 0.2905\n","Epoch 65/400\n","10/10 [==============================] - 2s 235ms/step - loss: 1.8341 - accuracy: 0.4375 - val_loss: 2.3879 - val_accuracy: 0.2893\n","Epoch 66/400\n","10/10 [==============================] - 2s 231ms/step - loss: 1.7973 - accuracy: 0.4313 - val_loss: 2.3890 - val_accuracy: 0.2880\n","Epoch 67/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8863 - accuracy: 0.4250 - val_loss: 2.3893 - val_accuracy: 0.2888\n","Epoch 68/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8374 - accuracy: 0.4313 - val_loss: 2.3862 - val_accuracy: 0.2908\n","Epoch 69/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.7988 - accuracy: 0.4563 - val_loss: 2.3834 - val_accuracy: 0.2918\n","Epoch 70/400\n","10/10 [==============================] - 2s 227ms/step - loss: 1.9031 - accuracy: 0.4062 - val_loss: 2.3832 - val_accuracy: 0.2922\n","Epoch 71/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8139 - accuracy: 0.4531 - val_loss: 2.3890 - val_accuracy: 0.2895\n","Epoch 72/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8327 - accuracy: 0.4500 - val_loss: 2.3946 - val_accuracy: 0.2859\n","Epoch 73/400\n","10/10 [==============================] - 2s 232ms/step - loss: 1.8011 - accuracy: 0.4594 - val_loss: 2.3965 - val_accuracy: 0.2841\n","Epoch 74/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.7704 - accuracy: 0.4688 - val_loss: 2.4022 - val_accuracy: 0.2807\n","Epoch 75/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.7853 - accuracy: 0.4688 - val_loss: 2.4029 - val_accuracy: 0.2810\n","Epoch 76/400\n","10/10 [==============================] - 2s 228ms/step - loss: 1.7491 - accuracy: 0.4688 - val_loss: 2.4045 - val_accuracy: 0.2792\n","Epoch 77/400\n","10/10 [==============================] - 2s 234ms/step - loss: 1.7351 - accuracy: 0.4781 - val_loss: 2.4037 - val_accuracy: 0.2795\n","Epoch 78/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.7680 - accuracy: 0.4281 - val_loss: 2.4034 - val_accuracy: 0.2796\n","Epoch 79/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.7918 - accuracy: 0.4563 - val_loss: 2.4091 - val_accuracy: 0.2770\n","Epoch 80/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.6950 - accuracy: 0.4594 - val_loss: 2.4120 - val_accuracy: 0.2755\n","Epoch 81/400\n","10/10 [==============================] - 2s 235ms/step - loss: 1.7540 - accuracy: 0.4281 - val_loss: 2.4162 - val_accuracy: 0.2732\n","Epoch 82/400\n","10/10 [==============================] - 2s 232ms/step - loss: 1.7265 - accuracy: 0.4344 - val_loss: 2.4171 - val_accuracy: 0.2731\n","Epoch 83/400\n","10/10 [==============================] - 2s 235ms/step - loss: 1.7513 - accuracy: 0.4531 - val_loss: 2.4222 - val_accuracy: 0.2699\n","Epoch 84/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.6369 - accuracy: 0.5031 - val_loss: 2.4210 - val_accuracy: 0.2708\n","Epoch 85/400\n","10/10 [==============================] - 2s 235ms/step - loss: 1.6965 - accuracy: 0.4844 - val_loss: 2.4249 - val_accuracy: 0.2692\n","Epoch 86/400\n","10/10 [==============================] - 2s 233ms/step - loss: 1.6619 - accuracy: 0.4812 - val_loss: 2.4293 - val_accuracy: 0.2670\n","Epoch 87/400\n","10/10 [==============================] - 2s 238ms/step - loss: 1.6677 - accuracy: 0.4563 - val_loss: 2.4299 - val_accuracy: 0.2664\n","Epoch 88/400\n"," 1/10 [==>...........................] - ETA: 0s - loss: 1.8025 - accuracy: 0.2500"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-2196aac4eb49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n\u001b[1;32m     15\u001b[0m     loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_small_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_small_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["layer_list = [ #520 parameters in input\n","          layers.Dropout(0.6),\n","          layers.BatchNormalization(),\n","          #layers.Dropout(0.4),\n","          layers.Dense(10,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(100,kernel_initializer='lecun_normal'),\n","          \n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=400, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CHrDlGiELAfF","executionInfo":{"status":"error","timestamp":1652038763154,"user_tz":240,"elapsed":134595,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"ec2b24a4-54f7-4331-ca6e-283292be5c31"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","10/10 [==============================] - 3s 268ms/step - loss: 3.2490 - accuracy: 0.0562 - val_loss: 3.5669 - val_accuracy: 0.0160\n","Epoch 2/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.9732 - accuracy: 0.1063 - val_loss: 3.0500 - val_accuracy: 0.0371\n","Epoch 3/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.8457 - accuracy: 0.1031 - val_loss: 2.8315 - val_accuracy: 0.0602\n","Epoch 4/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.7110 - accuracy: 0.1156 - val_loss: 2.7341 - val_accuracy: 0.0802\n","Epoch 5/400\n","10/10 [==============================] - 2s 232ms/step - loss: 2.6301 - accuracy: 0.1469 - val_loss: 2.6498 - val_accuracy: 0.1249\n","Epoch 6/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.6288 - accuracy: 0.1437 - val_loss: 2.5894 - val_accuracy: 0.1523\n","Epoch 7/400\n","10/10 [==============================] - 2s 236ms/step - loss: 2.5633 - accuracy: 0.1750 - val_loss: 2.5497 - val_accuracy: 0.1683\n","Epoch 8/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.5390 - accuracy: 0.1781 - val_loss: 2.5270 - val_accuracy: 0.1608\n","Epoch 9/400\n","10/10 [==============================] - 2s 232ms/step - loss: 2.5050 - accuracy: 0.1781 - val_loss: 2.4985 - val_accuracy: 0.1832\n","Epoch 10/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.5299 - accuracy: 0.1969 - val_loss: 2.4766 - val_accuracy: 0.2191\n","Epoch 11/400\n","10/10 [==============================] - 2s 239ms/step - loss: 2.4103 - accuracy: 0.2062 - val_loss: 2.4537 - val_accuracy: 0.2189\n","Epoch 12/400\n","10/10 [==============================] - 2s 234ms/step - loss: 2.4734 - accuracy: 0.2000 - val_loss: 2.4343 - val_accuracy: 0.2287\n","Epoch 13/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.4271 - accuracy: 0.2281 - val_loss: 2.4319 - val_accuracy: 0.2534\n","Epoch 14/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.3946 - accuracy: 0.2219 - val_loss: 2.4305 - val_accuracy: 0.2492\n","Epoch 15/400\n","10/10 [==============================] - 2s 239ms/step - loss: 2.3512 - accuracy: 0.2250 - val_loss: 2.4173 - val_accuracy: 0.2680\n","Epoch 16/400\n","10/10 [==============================] - 2s 237ms/step - loss: 2.3084 - accuracy: 0.2594 - val_loss: 2.4227 - val_accuracy: 0.2577\n","Epoch 17/400\n","10/10 [==============================] - 2s 235ms/step - loss: 2.3490 - accuracy: 0.2406 - val_loss: 2.4066 - val_accuracy: 0.2763\n","Epoch 18/400\n","10/10 [==============================] - 2s 239ms/step - loss: 2.2997 - accuracy: 0.2625 - val_loss: 2.3865 - val_accuracy: 0.2877\n","Epoch 19/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.2558 - accuracy: 0.2562 - val_loss: 2.3654 - val_accuracy: 0.2945\n","Epoch 20/400\n","10/10 [==============================] - 2s 234ms/step - loss: 2.2227 - accuracy: 0.2656 - val_loss: 2.3609 - val_accuracy: 0.3004\n","Epoch 21/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.2094 - accuracy: 0.2781 - val_loss: 2.3848 - val_accuracy: 0.2755\n","Epoch 22/400\n","10/10 [==============================] - 2s 232ms/step - loss: 2.2368 - accuracy: 0.3031 - val_loss: 2.3834 - val_accuracy: 0.2832\n","Epoch 23/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.1503 - accuracy: 0.3187 - val_loss: 2.3646 - val_accuracy: 0.3109\n","Epoch 24/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.1487 - accuracy: 0.2875 - val_loss: 2.3512 - val_accuracy: 0.3191\n","Epoch 25/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0594 - accuracy: 0.3344 - val_loss: 2.3496 - val_accuracy: 0.3108\n","Epoch 26/400\n","10/10 [==============================] - 2s 231ms/step - loss: 2.1543 - accuracy: 0.3313 - val_loss: 2.3319 - val_accuracy: 0.3225\n","Epoch 27/400\n","10/10 [==============================] - 2s 237ms/step - loss: 2.1075 - accuracy: 0.3562 - val_loss: 2.3304 - val_accuracy: 0.3170\n","Epoch 28/400\n","10/10 [==============================] - 2s 232ms/step - loss: 2.0538 - accuracy: 0.3344 - val_loss: 2.3246 - val_accuracy: 0.3179\n","Epoch 29/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.0592 - accuracy: 0.3531 - val_loss: 2.3254 - val_accuracy: 0.3152\n","Epoch 30/400\n","10/10 [==============================] - 3s 301ms/step - loss: 1.9514 - accuracy: 0.3812 - val_loss: 2.3363 - val_accuracy: 0.3061\n","Epoch 31/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.0372 - accuracy: 0.3500 - val_loss: 2.3130 - val_accuracy: 0.3220\n","Epoch 32/400\n","10/10 [==============================] - 2s 237ms/step - loss: 1.9995 - accuracy: 0.3688 - val_loss: 2.3040 - val_accuracy: 0.3277\n","Epoch 33/400\n","10/10 [==============================] - 2s 230ms/step - loss: 1.9520 - accuracy: 0.3656 - val_loss: 2.2801 - val_accuracy: 0.3365\n","Epoch 34/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9927 - accuracy: 0.3906 - val_loss: 2.2951 - val_accuracy: 0.3238\n","Epoch 35/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9368 - accuracy: 0.3750 - val_loss: 2.2899 - val_accuracy: 0.3279\n","Epoch 36/400\n","10/10 [==============================] - 2s 237ms/step - loss: 1.8911 - accuracy: 0.3719 - val_loss: 2.3121 - val_accuracy: 0.3128\n","Epoch 37/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8502 - accuracy: 0.3906 - val_loss: 2.3106 - val_accuracy: 0.3166\n","Epoch 38/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8888 - accuracy: 0.4000 - val_loss: 2.3087 - val_accuracy: 0.3179\n","Epoch 39/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8686 - accuracy: 0.3938 - val_loss: 2.3104 - val_accuracy: 0.3155\n","Epoch 40/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9121 - accuracy: 0.3719 - val_loss: 2.3063 - val_accuracy: 0.3175\n","Epoch 41/400\n","10/10 [==============================] - 2s 238ms/step - loss: 1.9065 - accuracy: 0.3781 - val_loss: 2.3033 - val_accuracy: 0.3197\n","Epoch 42/400\n","10/10 [==============================] - 2s 235ms/step - loss: 1.8232 - accuracy: 0.4531 - val_loss: 2.3255 - val_accuracy: 0.3069\n","Epoch 43/400\n","10/10 [==============================] - 2s 236ms/step - loss: 1.8925 - accuracy: 0.3750 - val_loss: 2.3200 - val_accuracy: 0.3072\n","Epoch 44/400\n","10/10 [==============================] - 2s 231ms/step - loss: 1.8385 - accuracy: 0.4187 - val_loss: 2.3224 - val_accuracy: 0.3062\n","Epoch 45/400\n","10/10 [==============================] - 2s 239ms/step - loss: 1.8257 - accuracy: 0.4281 - val_loss: 2.3123 - val_accuracy: 0.3104\n","Epoch 46/400\n","10/10 [==============================] - 2s 237ms/step - loss: 1.7734 - accuracy: 0.4469 - val_loss: 2.3065 - val_accuracy: 0.3130\n","Epoch 47/400\n","10/10 [==============================] - 2s 229ms/step - loss: 1.7724 - accuracy: 0.4281 - val_loss: 2.3068 - val_accuracy: 0.3121\n","Epoch 48/400\n","10/10 [==============================] - 2s 235ms/step - loss: 1.7900 - accuracy: 0.3875 - val_loss: 2.3249 - val_accuracy: 0.3028\n","Epoch 49/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.7710 - accuracy: 0.4031 - val_loss: 2.3346 - val_accuracy: 0.2928\n","Epoch 50/400\n","10/10 [==============================] - 3s 291ms/step - loss: 1.7477 - accuracy: 0.4531 - val_loss: 2.3328 - val_accuracy: 0.2990\n","Epoch 51/400\n","10/10 [==============================] - 2s 240ms/step - loss: 1.6922 - accuracy: 0.4719 - val_loss: 2.3725 - val_accuracy: 0.2820\n","Epoch 52/400\n","10/10 [==============================] - 2s 244ms/step - loss: 1.7113 - accuracy: 0.4531 - val_loss: 2.3828 - val_accuracy: 0.2792\n","Epoch 53/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.7062 - accuracy: 0.4594 - val_loss: 2.3670 - val_accuracy: 0.2920\n","Epoch 54/400\n","10/10 [==============================] - 2s 238ms/step - loss: 1.6568 - accuracy: 0.4875 - val_loss: 2.3668 - val_accuracy: 0.2942\n","Epoch 55/400\n","10/10 [==============================] - 2s 242ms/step - loss: 1.6523 - accuracy: 0.4406 - val_loss: 2.3576 - val_accuracy: 0.3018\n","Epoch 56/400\n","10/10 [==============================] - 2s 241ms/step - loss: 1.7136 - accuracy: 0.4344 - val_loss: 2.3582 - val_accuracy: 0.3028\n","Epoch 57/400\n"," 1/10 [==>...........................] - ETA: 0s - loss: 1.6385 - accuracy: 0.3438"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-4fc1dff7335d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n\u001b[1;32m     15\u001b[0m     loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_small_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_small_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["layer_list = [ #520 parameters in input\n","          layers.Dropout(0.6),\n","          layers.BatchNormalization(),\n","          #layers.Dropout(0.4),\n","          layers.Dense(10,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(100,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=400, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hE6fi0aEMEtQ","executionInfo":{"status":"error","timestamp":1652038966931,"user_tz":240,"elapsed":106006,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"49f75d63-8f3a-4f4d-87ce-1ab4ad2ae894"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","10/10 [==============================] - 4s 273ms/step - loss: 3.1432 - accuracy: 0.0656 - val_loss: 2.6599 - val_accuracy: 0.2171\n","Epoch 2/400\n","10/10 [==============================] - 3s 289ms/step - loss: 3.0061 - accuracy: 0.0844 - val_loss: 2.6367 - val_accuracy: 0.1760\n","Epoch 3/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.8285 - accuracy: 0.0969 - val_loss: 2.6272 - val_accuracy: 0.1766\n","Epoch 4/400\n","10/10 [==============================] - 2s 251ms/step - loss: 2.7029 - accuracy: 0.1281 - val_loss: 2.6001 - val_accuracy: 0.1977\n","Epoch 5/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.6587 - accuracy: 0.1219 - val_loss: 2.5995 - val_accuracy: 0.2041\n","Epoch 6/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.5934 - accuracy: 0.1594 - val_loss: 2.5915 - val_accuracy: 0.2137\n","Epoch 7/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6117 - accuracy: 0.1781 - val_loss: 2.5873 - val_accuracy: 0.2131\n","Epoch 8/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.5244 - accuracy: 0.1656 - val_loss: 2.5950 - val_accuracy: 0.2011\n","Epoch 9/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4948 - accuracy: 0.1875 - val_loss: 2.5737 - val_accuracy: 0.2081\n","Epoch 10/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4234 - accuracy: 0.2469 - val_loss: 2.5636 - val_accuracy: 0.2129\n","Epoch 11/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4082 - accuracy: 0.2000 - val_loss: 2.5145 - val_accuracy: 0.2423\n","Epoch 12/400\n","10/10 [==============================] - 2s 237ms/step - loss: 2.3957 - accuracy: 0.2094 - val_loss: 2.4965 - val_accuracy: 0.2632\n","Epoch 13/400\n","10/10 [==============================] - 2s 238ms/step - loss: 2.3818 - accuracy: 0.2156 - val_loss: 2.4976 - val_accuracy: 0.2642\n","Epoch 14/400\n","10/10 [==============================] - 2s 242ms/step - loss: 2.3835 - accuracy: 0.2281 - val_loss: 2.4911 - val_accuracy: 0.2705\n","Epoch 15/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.3448 - accuracy: 0.2344 - val_loss: 2.4794 - val_accuracy: 0.2830\n","Epoch 16/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.2921 - accuracy: 0.2344 - val_loss: 2.4618 - val_accuracy: 0.2952\n","Epoch 17/400\n","10/10 [==============================] - 2s 241ms/step - loss: 2.2644 - accuracy: 0.2906 - val_loss: 2.4472 - val_accuracy: 0.3001\n","Epoch 18/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1802 - accuracy: 0.3250 - val_loss: 2.4451 - val_accuracy: 0.3001\n","Epoch 19/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.2066 - accuracy: 0.3094 - val_loss: 2.4411 - val_accuracy: 0.2944\n","Epoch 20/400\n","10/10 [==============================] - 2s 242ms/step - loss: 2.2053 - accuracy: 0.2781 - val_loss: 2.4442 - val_accuracy: 0.2905\n","Epoch 21/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.2528 - accuracy: 0.2969 - val_loss: 2.4222 - val_accuracy: 0.3026\n","Epoch 22/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1616 - accuracy: 0.3031 - val_loss: 2.4050 - val_accuracy: 0.3124\n","Epoch 23/400\n","10/10 [==============================] - 2s 246ms/step - loss: 2.1144 - accuracy: 0.2906 - val_loss: 2.4008 - val_accuracy: 0.3103\n","Epoch 24/400\n","10/10 [==============================] - 2s 253ms/step - loss: 2.1815 - accuracy: 0.2406 - val_loss: 2.4057 - val_accuracy: 0.3067\n","Epoch 25/400\n","10/10 [==============================] - 2s 248ms/step - loss: 2.1123 - accuracy: 0.3500 - val_loss: 2.3921 - val_accuracy: 0.3128\n","Epoch 26/400\n","10/10 [==============================] - 2s 255ms/step - loss: 2.0837 - accuracy: 0.3187 - val_loss: 2.3864 - val_accuracy: 0.3139\n","Epoch 27/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0215 - accuracy: 0.3500 - val_loss: 2.3905 - val_accuracy: 0.3129\n","Epoch 28/400\n","10/10 [==============================] - 2s 247ms/step - loss: 2.0433 - accuracy: 0.3469 - val_loss: 2.3982 - val_accuracy: 0.3092\n","Epoch 29/400\n","10/10 [==============================] - 2s 259ms/step - loss: 2.0241 - accuracy: 0.3406 - val_loss: 2.3944 - val_accuracy: 0.3093\n","Epoch 30/400\n","10/10 [==============================] - 3s 294ms/step - loss: 2.0389 - accuracy: 0.3250 - val_loss: 2.3935 - val_accuracy: 0.3099\n","Epoch 31/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.0622 - accuracy: 0.3250 - val_loss: 2.4027 - val_accuracy: 0.3025\n","Epoch 32/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9913 - accuracy: 0.3562 - val_loss: 2.4096 - val_accuracy: 0.2959\n","Epoch 33/400\n","10/10 [==============================] - 2s 242ms/step - loss: 1.9390 - accuracy: 0.3844 - val_loss: 2.4078 - val_accuracy: 0.2967\n","Epoch 34/400\n","10/10 [==============================] - 2s 240ms/step - loss: 1.9574 - accuracy: 0.3594 - val_loss: 2.3928 - val_accuracy: 0.3048\n","Epoch 35/400\n","10/10 [==============================] - 2s 242ms/step - loss: 1.8761 - accuracy: 0.4031 - val_loss: 2.4022 - val_accuracy: 0.3005\n","Epoch 36/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9369 - accuracy: 0.3781 - val_loss: 2.4202 - val_accuracy: 0.2899\n","Epoch 37/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9183 - accuracy: 0.3938 - val_loss: 2.4288 - val_accuracy: 0.2821\n","Epoch 38/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8851 - accuracy: 0.3875 - val_loss: 2.4467 - val_accuracy: 0.2717\n","Epoch 39/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8900 - accuracy: 0.4187 - val_loss: 2.4537 - val_accuracy: 0.2671\n","Epoch 40/400\n","10/10 [==============================] - 2s 241ms/step - loss: 1.8431 - accuracy: 0.3969 - val_loss: 2.4486 - val_accuracy: 0.2727\n","Epoch 41/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8793 - accuracy: 0.3938 - val_loss: 2.4573 - val_accuracy: 0.2707\n","Epoch 42/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.8766 - accuracy: 0.4187 - val_loss: 2.4650 - val_accuracy: 0.2673\n","Epoch 43/400\n"," 1/10 [==>...........................] - ETA: 0s - loss: 1.6162 - accuracy: 0.3750"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-0dc5f07da8b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n\u001b[1;32m     16\u001b[0m     loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_small_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_small_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["layer_list = [ #520 parameters in input\n","          layers.Dropout(0.6),\n","          layers.BatchNormalization(),\n","          #layers.Dropout(0.4),\n","          layers.Dense(10,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dropout(0.6),\n","          layers.Dense(400,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=400, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TnVj9sH8LxEh","executionInfo":{"status":"error","timestamp":1652039175139,"user_tz":240,"elapsed":182741,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"41ac19f5-33f0-469b-e4de-39630a6acf60"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","10/10 [==============================] - 4s 283ms/step - loss: 3.1426 - accuracy: 0.0594 - val_loss: 3.0280 - val_accuracy: 0.0669\n","Epoch 2/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.8878 - accuracy: 0.0656 - val_loss: 2.8016 - val_accuracy: 0.0908\n","Epoch 3/400\n","10/10 [==============================] - 2s 250ms/step - loss: 2.8074 - accuracy: 0.0750 - val_loss: 2.7517 - val_accuracy: 0.0898\n","Epoch 4/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.8508 - accuracy: 0.0812 - val_loss: 2.7287 - val_accuracy: 0.0645\n","Epoch 5/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.7985 - accuracy: 0.1031 - val_loss: 2.6880 - val_accuracy: 0.0813\n","Epoch 6/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.7599 - accuracy: 0.1094 - val_loss: 2.6184 - val_accuracy: 0.1076\n","Epoch 7/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.7240 - accuracy: 0.1250 - val_loss: 2.6207 - val_accuracy: 0.0761\n","Epoch 8/400\n","10/10 [==============================] - 2s 257ms/step - loss: 2.7093 - accuracy: 0.1094 - val_loss: 2.5841 - val_accuracy: 0.0710\n","Epoch 9/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6671 - accuracy: 0.1063 - val_loss: 2.5329 - val_accuracy: 0.1344\n","Epoch 10/400\n","10/10 [==============================] - 2s 248ms/step - loss: 2.6765 - accuracy: 0.1156 - val_loss: 2.5585 - val_accuracy: 0.1454\n","Epoch 11/400\n","10/10 [==============================] - 2s 245ms/step - loss: 2.7197 - accuracy: 0.1094 - val_loss: 2.5395 - val_accuracy: 0.1718\n","Epoch 12/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6804 - accuracy: 0.1281 - val_loss: 2.5111 - val_accuracy: 0.1952\n","Epoch 13/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6343 - accuracy: 0.1594 - val_loss: 2.5114 - val_accuracy: 0.2127\n","Epoch 14/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.6631 - accuracy: 0.1437 - val_loss: 2.5206 - val_accuracy: 0.2010\n","Epoch 15/400\n","10/10 [==============================] - 2s 250ms/step - loss: 2.5833 - accuracy: 0.1656 - val_loss: 2.5411 - val_accuracy: 0.1516\n","Epoch 16/400\n","10/10 [==============================] - 2s 245ms/step - loss: 2.6546 - accuracy: 0.1156 - val_loss: 2.5084 - val_accuracy: 0.2194\n","Epoch 17/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.5712 - accuracy: 0.1719 - val_loss: 2.5148 - val_accuracy: 0.2127\n","Epoch 18/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5945 - accuracy: 0.1312 - val_loss: 2.5165 - val_accuracy: 0.2277\n","Epoch 19/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6125 - accuracy: 0.1437 - val_loss: 2.5206 - val_accuracy: 0.2390\n","Epoch 20/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.6094 - accuracy: 0.1469 - val_loss: 2.5281 - val_accuracy: 0.1623\n","Epoch 21/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6056 - accuracy: 0.1187 - val_loss: 2.5111 - val_accuracy: 0.1725\n","Epoch 22/400\n","10/10 [==============================] - 2s 247ms/step - loss: 2.5382 - accuracy: 0.1625 - val_loss: 2.4894 - val_accuracy: 0.2748\n","Epoch 23/400\n","10/10 [==============================] - 2s 248ms/step - loss: 2.5709 - accuracy: 0.1500 - val_loss: 2.5043 - val_accuracy: 0.2721\n","Epoch 24/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.5614 - accuracy: 0.1625 - val_loss: 2.5525 - val_accuracy: 0.2181\n","Epoch 25/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5527 - accuracy: 0.1469 - val_loss: 2.5470 - val_accuracy: 0.2045\n","Epoch 26/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.5843 - accuracy: 0.1719 - val_loss: 2.4970 - val_accuracy: 0.2501\n","Epoch 27/400\n","10/10 [==============================] - 2s 246ms/step - loss: 2.5329 - accuracy: 0.1594 - val_loss: 2.4641 - val_accuracy: 0.2869\n","Epoch 28/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.5414 - accuracy: 0.1937 - val_loss: 2.5115 - val_accuracy: 0.2318\n","Epoch 29/400\n","10/10 [==============================] - 2s 249ms/step - loss: 2.5212 - accuracy: 0.1562 - val_loss: 2.4779 - val_accuracy: 0.2421\n","Epoch 30/400\n","10/10 [==============================] - 2s 245ms/step - loss: 2.5156 - accuracy: 0.2000 - val_loss: 2.4649 - val_accuracy: 0.2420\n","Epoch 31/400\n","10/10 [==============================] - 2s 242ms/step - loss: 2.5460 - accuracy: 0.1469 - val_loss: 2.4813 - val_accuracy: 0.2425\n","Epoch 32/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.5982 - accuracy: 0.1625 - val_loss: 2.4702 - val_accuracy: 0.2676\n","Epoch 33/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5265 - accuracy: 0.1531 - val_loss: 2.4947 - val_accuracy: 0.2306\n","Epoch 34/400\n","10/10 [==============================] - 2s 244ms/step - loss: 2.5562 - accuracy: 0.1375 - val_loss: 2.4956 - val_accuracy: 0.2398\n","Epoch 35/400\n","10/10 [==============================] - 2s 242ms/step - loss: 2.5212 - accuracy: 0.1688 - val_loss: 2.5037 - val_accuracy: 0.2387\n","Epoch 36/400\n","10/10 [==============================] - 2s 243ms/step - loss: 2.4693 - accuracy: 0.2000 - val_loss: 2.4710 - val_accuracy: 0.2796\n","Epoch 37/400\n","10/10 [==============================] - 2s 249ms/step - loss: 2.5548 - accuracy: 0.1719 - val_loss: 2.4629 - val_accuracy: 0.2855\n","Epoch 38/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.4794 - accuracy: 0.1688 - val_loss: 2.4425 - val_accuracy: 0.2918\n","Epoch 39/400\n","10/10 [==============================] - 2s 240ms/step - loss: 2.4630 - accuracy: 0.1750 - val_loss: 2.4549 - val_accuracy: 0.2814\n","Epoch 40/400\n","10/10 [==============================] - 2s 243ms/step - loss: 2.4235 - accuracy: 0.1875 - val_loss: 2.4447 - val_accuracy: 0.2810\n","Epoch 41/400\n","10/10 [==============================] - 2s 244ms/step - loss: 2.4708 - accuracy: 0.1813 - val_loss: 2.4483 - val_accuracy: 0.2847\n","Epoch 42/400\n","10/10 [==============================] - 2s 244ms/step - loss: 2.4780 - accuracy: 0.1813 - val_loss: 2.4896 - val_accuracy: 0.2399\n","Epoch 43/400\n","10/10 [==============================] - 2s 242ms/step - loss: 2.5288 - accuracy: 0.1562 - val_loss: 2.4687 - val_accuracy: 0.2629\n","Epoch 44/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5207 - accuracy: 0.1625 - val_loss: 2.4838 - val_accuracy: 0.2588\n","Epoch 45/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4875 - accuracy: 0.1906 - val_loss: 2.5162 - val_accuracy: 0.2468\n","Epoch 46/400\n","10/10 [==============================] - 2s 246ms/step - loss: 2.4721 - accuracy: 0.1688 - val_loss: 2.5242 - val_accuracy: 0.2150\n","Epoch 47/400\n","10/10 [==============================] - 2s 238ms/step - loss: 2.4968 - accuracy: 0.1813 - val_loss: 2.5007 - val_accuracy: 0.2117\n","Epoch 48/400\n","10/10 [==============================] - 2s 243ms/step - loss: 2.5002 - accuracy: 0.1688 - val_loss: 2.4848 - val_accuracy: 0.2392\n","Epoch 49/400\n","10/10 [==============================] - 2s 242ms/step - loss: 2.4516 - accuracy: 0.1813 - val_loss: 2.4574 - val_accuracy: 0.2674\n","Epoch 50/400\n","10/10 [==============================] - 2s 247ms/step - loss: 2.4604 - accuracy: 0.1906 - val_loss: 2.4302 - val_accuracy: 0.2810\n","Epoch 51/400\n","10/10 [==============================] - 2s 256ms/step - loss: 2.4060 - accuracy: 0.1750 - val_loss: 2.4212 - val_accuracy: 0.2856\n","Epoch 52/400\n","10/10 [==============================] - 2s 244ms/step - loss: 2.4905 - accuracy: 0.1688 - val_loss: 2.4381 - val_accuracy: 0.2791\n","Epoch 53/400\n","10/10 [==============================] - 2s 243ms/step - loss: 2.3867 - accuracy: 0.1969 - val_loss: 2.4681 - val_accuracy: 0.2281\n","Epoch 54/400\n","10/10 [==============================] - 2s 248ms/step - loss: 2.4429 - accuracy: 0.1937 - val_loss: 2.4483 - val_accuracy: 0.2507\n","Epoch 55/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.4871 - accuracy: 0.1531 - val_loss: 2.4441 - val_accuracy: 0.2763\n","Epoch 56/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4626 - accuracy: 0.1906 - val_loss: 2.4626 - val_accuracy: 0.2588\n","Epoch 57/400\n","10/10 [==============================] - 2s 248ms/step - loss: 2.4056 - accuracy: 0.1813 - val_loss: 2.4440 - val_accuracy: 0.2733\n","Epoch 58/400\n","10/10 [==============================] - 2s 241ms/step - loss: 2.4728 - accuracy: 0.1875 - val_loss: 2.4182 - val_accuracy: 0.2890\n","Epoch 59/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.3717 - accuracy: 0.2156 - val_loss: 2.3888 - val_accuracy: 0.3226\n","Epoch 60/400\n","10/10 [==============================] - 2s 243ms/step - loss: 2.3841 - accuracy: 0.1781 - val_loss: 2.3856 - val_accuracy: 0.2994\n","Epoch 61/400\n","10/10 [==============================] - 2s 245ms/step - loss: 2.4039 - accuracy: 0.2219 - val_loss: 2.4298 - val_accuracy: 0.2765\n","Epoch 62/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.3485 - accuracy: 0.2188 - val_loss: 2.4305 - val_accuracy: 0.2744\n","Epoch 63/400\n","10/10 [==============================] - 2s 246ms/step - loss: 2.4218 - accuracy: 0.1937 - val_loss: 2.4560 - val_accuracy: 0.2546\n","Epoch 64/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.3835 - accuracy: 0.2281 - val_loss: 2.4566 - val_accuracy: 0.2446\n","Epoch 65/400\n","10/10 [==============================] - 2s 243ms/step - loss: 2.3223 - accuracy: 0.2406 - val_loss: 2.4582 - val_accuracy: 0.2395\n","Epoch 66/400\n","10/10 [==============================] - 2s 243ms/step - loss: 2.3980 - accuracy: 0.2250 - val_loss: 2.4281 - val_accuracy: 0.2692\n","Epoch 67/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3835 - accuracy: 0.2250 - val_loss: 2.3945 - val_accuracy: 0.2874\n","Epoch 68/400\n","10/10 [==============================] - 2s 247ms/step - loss: 2.4158 - accuracy: 0.2062 - val_loss: 2.4261 - val_accuracy: 0.2815\n","Epoch 69/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3788 - accuracy: 0.2375 - val_loss: 2.4617 - val_accuracy: 0.2673\n","Epoch 70/400\n","10/10 [==============================] - 2s 243ms/step - loss: 2.4251 - accuracy: 0.1937 - val_loss: 2.4229 - val_accuracy: 0.3011\n","Epoch 71/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.3332 - accuracy: 0.2250 - val_loss: 2.4351 - val_accuracy: 0.2823\n","Epoch 72/400\n","10/10 [==============================] - 2s 247ms/step - loss: 2.2963 - accuracy: 0.2000 - val_loss: 2.4169 - val_accuracy: 0.2783\n","Epoch 73/400\n","10/10 [==============================] - 2s 244ms/step - loss: 2.3529 - accuracy: 0.2188 - val_loss: 2.4389 - val_accuracy: 0.2593\n","Epoch 74/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.3771 - accuracy: 0.2250 - val_loss: 2.4458 - val_accuracy: 0.2451\n","Epoch 75/400\n","10/10 [==============================] - 2s 251ms/step - loss: 2.4141 - accuracy: 0.1937 - val_loss: 2.4103 - val_accuracy: 0.2788\n","Epoch 76/400\n"," 1/10 [==>...........................] - ETA: 0s - loss: 2.7098 - accuracy: 0.2812"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-5c2cf64d6d50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n\u001b[1;32m     17\u001b[0m     loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_small_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_small_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# so I created a model that isn't learning the training set! let's add another layer\n","layer_list = [ #520 parameters in input\n","          layers.Dropout(0.6),\n","          layers.BatchNormalization(),\n","          #layers.Dropout(0.4),\n","          layers.Dense(10,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dropout(0.6),\n","          layers.Dense(400,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(100,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=400, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JEZbW4aWNYTI","executionInfo":{"status":"error","timestamp":1652039834252,"user_tz":240,"elapsed":347929,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"5af3db1c-16be-44e9-8702-f3bde7af8abb"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","10/10 [==============================] - 5s 344ms/step - loss: 3.0883 - accuracy: 0.0688 - val_loss: 2.9835 - val_accuracy: 0.1045\n","Epoch 2/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.9620 - accuracy: 0.0906 - val_loss: 2.7528 - val_accuracy: 0.1849\n","Epoch 3/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.9926 - accuracy: 0.0594 - val_loss: 2.7380 - val_accuracy: 0.1481\n","Epoch 4/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.8372 - accuracy: 0.0812 - val_loss: 2.7412 - val_accuracy: 0.1210\n","Epoch 5/400\n","10/10 [==============================] - 2s 260ms/step - loss: 2.7822 - accuracy: 0.1094 - val_loss: 2.7443 - val_accuracy: 0.0612\n","Epoch 6/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.7500 - accuracy: 0.0938 - val_loss: 2.5819 - val_accuracy: 0.1909\n","Epoch 7/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.7912 - accuracy: 0.1031 - val_loss: 2.5309 - val_accuracy: 0.2255\n","Epoch 8/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.7723 - accuracy: 0.1406 - val_loss: 2.5115 - val_accuracy: 0.2379\n","Epoch 9/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.7493 - accuracy: 0.1063 - val_loss: 2.4821 - val_accuracy: 0.2780\n","Epoch 10/400\n","10/10 [==============================] - 2s 269ms/step - loss: 2.7159 - accuracy: 0.1250 - val_loss: 2.5574 - val_accuracy: 0.1428\n","Epoch 11/400\n","10/10 [==============================] - 2s 259ms/step - loss: 2.7045 - accuracy: 0.1031 - val_loss: 2.5648 - val_accuracy: 0.1482\n","Epoch 12/400\n","10/10 [==============================] - 2s 263ms/step - loss: 2.6717 - accuracy: 0.1281 - val_loss: 2.5301 - val_accuracy: 0.1970\n","Epoch 13/400\n","10/10 [==============================] - 2s 261ms/step - loss: 2.6333 - accuracy: 0.1531 - val_loss: 2.4930 - val_accuracy: 0.1885\n","Epoch 14/400\n","10/10 [==============================] - 2s 259ms/step - loss: 2.6681 - accuracy: 0.1469 - val_loss: 2.5455 - val_accuracy: 0.0887\n","Epoch 15/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6564 - accuracy: 0.1531 - val_loss: 2.5864 - val_accuracy: 0.0567\n","Epoch 16/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5937 - accuracy: 0.1750 - val_loss: 2.5715 - val_accuracy: 0.0810\n","Epoch 17/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6183 - accuracy: 0.1375 - val_loss: 2.5260 - val_accuracy: 0.1735\n","Epoch 18/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.6903 - accuracy: 0.1156 - val_loss: 2.4611 - val_accuracy: 0.2636\n","Epoch 19/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.5281 - accuracy: 0.1750 - val_loss: 2.4607 - val_accuracy: 0.2638\n","Epoch 20/400\n","10/10 [==============================] - 2s 268ms/step - loss: 2.6198 - accuracy: 0.1469 - val_loss: 2.4730 - val_accuracy: 0.2732\n","Epoch 21/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6179 - accuracy: 0.1531 - val_loss: 2.4754 - val_accuracy: 0.2688\n","Epoch 22/400\n","10/10 [==============================] - 2s 264ms/step - loss: 2.6566 - accuracy: 0.1187 - val_loss: 2.5249 - val_accuracy: 0.1810\n","Epoch 23/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.5627 - accuracy: 0.1625 - val_loss: 2.5044 - val_accuracy: 0.2545\n","Epoch 24/400\n","10/10 [==============================] - 2s 270ms/step - loss: 2.5631 - accuracy: 0.1531 - val_loss: 2.5099 - val_accuracy: 0.2040\n","Epoch 25/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.5496 - accuracy: 0.1437 - val_loss: 2.4871 - val_accuracy: 0.2810\n","Epoch 26/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.5104 - accuracy: 0.1594 - val_loss: 2.4522 - val_accuracy: 0.2931\n","Epoch 27/400\n","10/10 [==============================] - 2s 264ms/step - loss: 2.5197 - accuracy: 0.1906 - val_loss: 2.4867 - val_accuracy: 0.1984\n","Epoch 28/400\n","10/10 [==============================] - 2s 263ms/step - loss: 2.5001 - accuracy: 0.1781 - val_loss: 2.4815 - val_accuracy: 0.2167\n","Epoch 29/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5551 - accuracy: 0.1375 - val_loss: 2.4818 - val_accuracy: 0.2458\n","Epoch 30/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5887 - accuracy: 0.1344 - val_loss: 2.4537 - val_accuracy: 0.2606\n","Epoch 31/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.5398 - accuracy: 0.1781 - val_loss: 2.4422 - val_accuracy: 0.2716\n","Epoch 32/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.5333 - accuracy: 0.1688 - val_loss: 2.4391 - val_accuracy: 0.2652\n","Epoch 33/400\n","10/10 [==============================] - 2s 259ms/step - loss: 2.4863 - accuracy: 0.1562 - val_loss: 2.4542 - val_accuracy: 0.2611\n","Epoch 34/400\n","10/10 [==============================] - 2s 260ms/step - loss: 2.4506 - accuracy: 0.2000 - val_loss: 2.4426 - val_accuracy: 0.2853\n","Epoch 35/400\n","10/10 [==============================] - 2s 261ms/step - loss: 2.5142 - accuracy: 0.1656 - val_loss: 2.4360 - val_accuracy: 0.2867\n","Epoch 36/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.3949 - accuracy: 0.2250 - val_loss: 2.4427 - val_accuracy: 0.2897\n","Epoch 37/400\n","10/10 [==============================] - 2s 257ms/step - loss: 2.5423 - accuracy: 0.1562 - val_loss: 2.4400 - val_accuracy: 0.2902\n","Epoch 38/400\n","10/10 [==============================] - 2s 260ms/step - loss: 2.5429 - accuracy: 0.1594 - val_loss: 2.4138 - val_accuracy: 0.2943\n","Epoch 39/400\n","10/10 [==============================] - 2s 259ms/step - loss: 2.5071 - accuracy: 0.1781 - val_loss: 2.4247 - val_accuracy: 0.2829\n","Epoch 40/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.4728 - accuracy: 0.1750 - val_loss: 2.3914 - val_accuracy: 0.3191\n","Epoch 41/400\n","10/10 [==============================] - 2s 265ms/step - loss: 2.4094 - accuracy: 0.1969 - val_loss: 2.3328 - val_accuracy: 0.3476\n","Epoch 42/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4168 - accuracy: 0.1844 - val_loss: 2.3511 - val_accuracy: 0.3352\n","Epoch 43/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4537 - accuracy: 0.2188 - val_loss: 2.3965 - val_accuracy: 0.2733\n","Epoch 44/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4604 - accuracy: 0.2000 - val_loss: 2.4385 - val_accuracy: 0.2462\n","Epoch 45/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.4224 - accuracy: 0.1781 - val_loss: 2.4586 - val_accuracy: 0.2073\n","Epoch 46/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.4428 - accuracy: 0.2062 - val_loss: 2.4636 - val_accuracy: 0.1806\n","Epoch 47/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.4172 - accuracy: 0.2250 - val_loss: 2.3978 - val_accuracy: 0.2880\n","Epoch 48/400\n","10/10 [==============================] - 2s 259ms/step - loss: 2.4408 - accuracy: 0.2062 - val_loss: 2.3719 - val_accuracy: 0.2970\n","Epoch 49/400\n","10/10 [==============================] - 2s 264ms/step - loss: 2.4476 - accuracy: 0.1781 - val_loss: 2.3918 - val_accuracy: 0.2886\n","Epoch 50/400\n","10/10 [==============================] - 2s 257ms/step - loss: 2.4059 - accuracy: 0.1937 - val_loss: 2.3750 - val_accuracy: 0.2818\n","Epoch 51/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3259 - accuracy: 0.2625 - val_loss: 2.3703 - val_accuracy: 0.3025\n","Epoch 52/400\n","10/10 [==============================] - 2s 255ms/step - loss: 2.4186 - accuracy: 0.2125 - val_loss: 2.3924 - val_accuracy: 0.3112\n","Epoch 53/400\n","10/10 [==============================] - 2s 263ms/step - loss: 2.3795 - accuracy: 0.2313 - val_loss: 2.4131 - val_accuracy: 0.2839\n","Epoch 54/400\n","10/10 [==============================] - 2s 260ms/step - loss: 2.4066 - accuracy: 0.2313 - val_loss: 2.3940 - val_accuracy: 0.2977\n","Epoch 55/400\n","10/10 [==============================] - 2s 259ms/step - loss: 2.3918 - accuracy: 0.1844 - val_loss: 2.4045 - val_accuracy: 0.2775\n","Epoch 56/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3615 - accuracy: 0.2062 - val_loss: 2.3813 - val_accuracy: 0.2858\n","Epoch 57/400\n","10/10 [==============================] - 2s 263ms/step - loss: 2.3316 - accuracy: 0.2219 - val_loss: 2.3581 - val_accuracy: 0.3107\n","Epoch 58/400\n","10/10 [==============================] - 2s 256ms/step - loss: 2.3400 - accuracy: 0.2406 - val_loss: 2.3787 - val_accuracy: 0.2733\n","Epoch 59/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3228 - accuracy: 0.2375 - val_loss: 2.4100 - val_accuracy: 0.2454\n","Epoch 60/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.3379 - accuracy: 0.2313 - val_loss: 2.4197 - val_accuracy: 0.2309\n","Epoch 61/400\n","10/10 [==============================] - 2s 266ms/step - loss: 2.3992 - accuracy: 0.2250 - val_loss: 2.4270 - val_accuracy: 0.2394\n","Epoch 62/400\n","10/10 [==============================] - 2s 258ms/step - loss: 2.3451 - accuracy: 0.2156 - val_loss: 2.4179 - val_accuracy: 0.2346\n","Epoch 63/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.3335 - accuracy: 0.2125 - val_loss: 2.3890 - val_accuracy: 0.2726\n","Epoch 64/400\n","10/10 [==============================] - 2s 261ms/step - loss: 2.3226 - accuracy: 0.2594 - val_loss: 2.3827 - val_accuracy: 0.2688\n","Epoch 65/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3495 - accuracy: 0.2469 - val_loss: 2.3982 - val_accuracy: 0.2550\n","Epoch 66/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.3496 - accuracy: 0.2125 - val_loss: 2.4102 - val_accuracy: 0.2603\n","Epoch 67/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.3610 - accuracy: 0.2188 - val_loss: 2.4314 - val_accuracy: 0.2549\n","Epoch 68/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.3887 - accuracy: 0.2062 - val_loss: 2.4251 - val_accuracy: 0.2526\n","Epoch 69/400\n","10/10 [==============================] - 2s 261ms/step - loss: 2.2758 - accuracy: 0.2656 - val_loss: 2.4250 - val_accuracy: 0.2618\n","Epoch 70/400\n","10/10 [==============================] - 2s 258ms/step - loss: 2.3035 - accuracy: 0.2375 - val_loss: 2.4168 - val_accuracy: 0.2565\n","Epoch 71/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3738 - accuracy: 0.2000 - val_loss: 2.4148 - val_accuracy: 0.2660\n","Epoch 72/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3399 - accuracy: 0.2375 - val_loss: 2.4318 - val_accuracy: 0.2638\n","Epoch 73/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.2692 - accuracy: 0.2594 - val_loss: 2.4072 - val_accuracy: 0.2815\n","Epoch 74/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2842 - accuracy: 0.2219 - val_loss: 2.3826 - val_accuracy: 0.2907\n","Epoch 75/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2962 - accuracy: 0.2812 - val_loss: 2.3901 - val_accuracy: 0.2707\n","Epoch 76/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3227 - accuracy: 0.2062 - val_loss: 2.4027 - val_accuracy: 0.2704\n","Epoch 77/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3747 - accuracy: 0.1937 - val_loss: 2.4111 - val_accuracy: 0.2740\n","Epoch 78/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.3027 - accuracy: 0.2281 - val_loss: 2.4046 - val_accuracy: 0.2875\n","Epoch 79/400\n","10/10 [==============================] - 2s 266ms/step - loss: 2.3320 - accuracy: 0.2219 - val_loss: 2.4136 - val_accuracy: 0.2729\n","Epoch 80/400\n","10/10 [==============================] - 2s 259ms/step - loss: 2.4041 - accuracy: 0.1813 - val_loss: 2.4093 - val_accuracy: 0.2630\n","Epoch 81/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2431 - accuracy: 0.2625 - val_loss: 2.4083 - val_accuracy: 0.2493\n","Epoch 82/400\n","10/10 [==============================] - 2s 265ms/step - loss: 2.2782 - accuracy: 0.2281 - val_loss: 2.3832 - val_accuracy: 0.2707\n","Epoch 83/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3028 - accuracy: 0.2313 - val_loss: 2.3500 - val_accuracy: 0.2916\n","Epoch 84/400\n","10/10 [==============================] - 2s 261ms/step - loss: 2.2907 - accuracy: 0.2438 - val_loss: 2.3799 - val_accuracy: 0.2806\n","Epoch 85/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.3698 - accuracy: 0.2500 - val_loss: 2.3914 - val_accuracy: 0.2834\n","Epoch 86/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.3499 - accuracy: 0.2062 - val_loss: 2.3969 - val_accuracy: 0.2822\n","Epoch 87/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2752 - accuracy: 0.2500 - val_loss: 2.3981 - val_accuracy: 0.2890\n","Epoch 88/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.2776 - accuracy: 0.2469 - val_loss: 2.4116 - val_accuracy: 0.2840\n","Epoch 89/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2922 - accuracy: 0.2313 - val_loss: 2.4253 - val_accuracy: 0.2793\n","Epoch 90/400\n","10/10 [==============================] - 2s 258ms/step - loss: 2.2726 - accuracy: 0.2375 - val_loss: 2.4309 - val_accuracy: 0.2731\n","Epoch 91/400\n","10/10 [==============================] - 2s 274ms/step - loss: 2.2775 - accuracy: 0.2531 - val_loss: 2.4398 - val_accuracy: 0.2614\n","Epoch 92/400\n","10/10 [==============================] - 2s 268ms/step - loss: 2.3402 - accuracy: 0.2219 - val_loss: 2.4139 - val_accuracy: 0.2726\n","Epoch 93/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.2825 - accuracy: 0.2313 - val_loss: 2.3846 - val_accuracy: 0.2856\n","Epoch 94/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.2523 - accuracy: 0.2719 - val_loss: 2.3817 - val_accuracy: 0.2833\n","Epoch 95/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3009 - accuracy: 0.2688 - val_loss: 2.3945 - val_accuracy: 0.2761\n","Epoch 96/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3012 - accuracy: 0.2531 - val_loss: 2.3663 - val_accuracy: 0.2965\n","Epoch 97/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1809 - accuracy: 0.2969 - val_loss: 2.3611 - val_accuracy: 0.2963\n","Epoch 98/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.2277 - accuracy: 0.2469 - val_loss: 2.3634 - val_accuracy: 0.2881\n","Epoch 99/400\n","10/10 [==============================] - 3s 293ms/step - loss: 2.3895 - accuracy: 0.1969 - val_loss: 2.3796 - val_accuracy: 0.2808\n","Epoch 100/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.3110 - accuracy: 0.2125 - val_loss: 2.4137 - val_accuracy: 0.2409\n","Epoch 101/400\n","10/10 [==============================] - 2s 263ms/step - loss: 2.2469 - accuracy: 0.2906 - val_loss: 2.4022 - val_accuracy: 0.2486\n","Epoch 102/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.2380 - accuracy: 0.2719 - val_loss: 2.4147 - val_accuracy: 0.2532\n","Epoch 103/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.3009 - accuracy: 0.1937 - val_loss: 2.4031 - val_accuracy: 0.2549\n","Epoch 104/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2469 - accuracy: 0.2781 - val_loss: 2.4061 - val_accuracy: 0.2414\n","Epoch 105/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.2584 - accuracy: 0.2594 - val_loss: 2.3820 - val_accuracy: 0.2654\n","Epoch 106/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2454 - accuracy: 0.2719 - val_loss: 2.3965 - val_accuracy: 0.2484\n","Epoch 107/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.2938 - accuracy: 0.2469 - val_loss: 2.3932 - val_accuracy: 0.2529\n","Epoch 108/400\n","10/10 [==============================] - 2s 257ms/step - loss: 2.4069 - accuracy: 0.2000 - val_loss: 2.3931 - val_accuracy: 0.2588\n","Epoch 109/400\n","10/10 [==============================] - 2s 264ms/step - loss: 2.2485 - accuracy: 0.2344 - val_loss: 2.4178 - val_accuracy: 0.2506\n","Epoch 110/400\n","10/10 [==============================] - 2s 258ms/step - loss: 2.3318 - accuracy: 0.1813 - val_loss: 2.4395 - val_accuracy: 0.2254\n","Epoch 111/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2550 - accuracy: 0.2875 - val_loss: 2.4395 - val_accuracy: 0.1995\n","Epoch 112/400\n","10/10 [==============================] - 2s 258ms/step - loss: 2.3060 - accuracy: 0.2156 - val_loss: 2.4116 - val_accuracy: 0.2301\n","Epoch 113/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2860 - accuracy: 0.2156 - val_loss: 2.3951 - val_accuracy: 0.2496\n","Epoch 114/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2922 - accuracy: 0.2344 - val_loss: 2.3796 - val_accuracy: 0.2632\n","Epoch 115/400\n","10/10 [==============================] - 2s 260ms/step - loss: 2.2531 - accuracy: 0.2469 - val_loss: 2.3741 - val_accuracy: 0.2751\n","Epoch 116/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.2621 - accuracy: 0.2438 - val_loss: 2.3678 - val_accuracy: 0.2792\n","Epoch 117/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.1932 - accuracy: 0.2531 - val_loss: 2.3767 - val_accuracy: 0.2625\n","Epoch 118/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.2447 - accuracy: 0.2625 - val_loss: 2.3915 - val_accuracy: 0.2540\n","Epoch 119/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.2481 - accuracy: 0.2281 - val_loss: 2.3891 - val_accuracy: 0.2668\n","Epoch 120/400\n","10/10 [==============================] - 2s 260ms/step - loss: 2.2398 - accuracy: 0.2688 - val_loss: 2.4068 - val_accuracy: 0.2672\n","Epoch 121/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1879 - accuracy: 0.2750 - val_loss: 2.4284 - val_accuracy: 0.2524\n","Epoch 122/400\n","10/10 [==============================] - 3s 293ms/step - loss: 2.2675 - accuracy: 0.2844 - val_loss: 2.4236 - val_accuracy: 0.2545\n","Epoch 123/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2652 - accuracy: 0.2719 - val_loss: 2.3902 - val_accuracy: 0.2724\n","Epoch 124/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.2321 - accuracy: 0.2469 - val_loss: 2.4050 - val_accuracy: 0.2652\n","Epoch 125/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.2666 - accuracy: 0.2313 - val_loss: 2.4160 - val_accuracy: 0.2551\n","Epoch 126/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.2805 - accuracy: 0.2844 - val_loss: 2.4017 - val_accuracy: 0.2616\n","Epoch 127/400\n","10/10 [==============================] - 2s 261ms/step - loss: 2.2841 - accuracy: 0.2531 - val_loss: 2.3677 - val_accuracy: 0.2816\n","Epoch 128/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2262 - accuracy: 0.2531 - val_loss: 2.3946 - val_accuracy: 0.2547\n","Epoch 129/400\n","10/10 [==============================] - 2s 259ms/step - loss: 2.2946 - accuracy: 0.2406 - val_loss: 2.3960 - val_accuracy: 0.2599\n","Epoch 130/400\n","10/10 [==============================] - 2s 267ms/step - loss: 2.3026 - accuracy: 0.2156 - val_loss: 2.4099 - val_accuracy: 0.2536\n","Epoch 131/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.2698 - accuracy: 0.2469 - val_loss: 2.4026 - val_accuracy: 0.2610\n","Epoch 132/400\n","10/10 [==============================] - 2s 258ms/step - loss: 2.2235 - accuracy: 0.2438 - val_loss: 2.4124 - val_accuracy: 0.2511\n","Epoch 133/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.2551 - accuracy: 0.2500 - val_loss: 2.4035 - val_accuracy: 0.2638\n","Epoch 134/400\n","10/10 [==============================] - 2s 260ms/step - loss: 2.2754 - accuracy: 0.2625 - val_loss: 2.4430 - val_accuracy: 0.2326\n","Epoch 135/400\n","10/10 [==============================] - 2s 263ms/step - loss: 2.1855 - accuracy: 0.2781 - val_loss: 2.4465 - val_accuracy: 0.2235\n","Epoch 136/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2852 - accuracy: 0.2375 - val_loss: 2.4376 - val_accuracy: 0.2389\n","Epoch 137/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.2473 - accuracy: 0.2500 - val_loss: 2.4374 - val_accuracy: 0.2287\n","Epoch 138/400\n"," 1/10 [==>...........................] - ETA: 0s - loss: 2.3316 - accuracy: 0.2812"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-1f0c3ed9b451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n\u001b[1;32m     21\u001b[0m     loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_small_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_small_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# that didn't help\n","# might need to lighten up on the dimensionality reduction\n","# so I created a model that isn't learning the training set! let's add another layer\n","layer_list = [ #520 parameters in input\n","          layers.Dropout(0.6),\n","          layers.BatchNormalization(),\n","          #layers.Dropout(0.4),\n","          layers.Dense(40,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dropout(0.6),\n","          layers.Dense(400,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=400, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DrF4yDtAQAo2","executionInfo":{"status":"error","timestamp":1652040138363,"user_tz":240,"elapsed":217700,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"3707171f-fe77-41fc-fafc-8d3591de0b12"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","10/10 [==============================] - 4s 290ms/step - loss: 3.1774 - accuracy: 0.0625 - val_loss: 3.1198 - val_accuracy: 0.0790\n","Epoch 2/400\n","10/10 [==============================] - 2s 248ms/step - loss: 2.9016 - accuracy: 0.0906 - val_loss: 2.7817 - val_accuracy: 0.1790\n","Epoch 3/400\n","10/10 [==============================] - 2s 246ms/step - loss: 2.7968 - accuracy: 0.1219 - val_loss: 2.6586 - val_accuracy: 0.2015\n","Epoch 4/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.7957 - accuracy: 0.1187 - val_loss: 2.5915 - val_accuracy: 0.2062\n","Epoch 5/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.7343 - accuracy: 0.1375 - val_loss: 2.5691 - val_accuracy: 0.2094\n","Epoch 6/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.6231 - accuracy: 0.1437 - val_loss: 2.5490 - val_accuracy: 0.2063\n","Epoch 7/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.6170 - accuracy: 0.1625 - val_loss: 2.5445 - val_accuracy: 0.2076\n","Epoch 8/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5494 - accuracy: 0.1594 - val_loss: 2.5533 - val_accuracy: 0.1901\n","Epoch 9/400\n","10/10 [==============================] - 2s 244ms/step - loss: 2.5240 - accuracy: 0.1813 - val_loss: 2.5578 - val_accuracy: 0.1660\n","Epoch 10/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5191 - accuracy: 0.1969 - val_loss: 2.5180 - val_accuracy: 0.2061\n","Epoch 11/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.4593 - accuracy: 0.1969 - val_loss: 2.4804 - val_accuracy: 0.2460\n","Epoch 12/400\n","10/10 [==============================] - 2s 248ms/step - loss: 2.5153 - accuracy: 0.1781 - val_loss: 2.4669 - val_accuracy: 0.2641\n","Epoch 13/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4353 - accuracy: 0.2344 - val_loss: 2.4481 - val_accuracy: 0.2800\n","Epoch 14/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4675 - accuracy: 0.1969 - val_loss: 2.4304 - val_accuracy: 0.2855\n","Epoch 15/400\n","10/10 [==============================] - 2s 250ms/step - loss: 2.4150 - accuracy: 0.2094 - val_loss: 2.4556 - val_accuracy: 0.2421\n","Epoch 16/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4246 - accuracy: 0.2250 - val_loss: 2.4842 - val_accuracy: 0.2200\n","Epoch 17/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3990 - accuracy: 0.2188 - val_loss: 2.4853 - val_accuracy: 0.2172\n","Epoch 18/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2582 - accuracy: 0.2469 - val_loss: 2.4636 - val_accuracy: 0.2425\n","Epoch 19/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3996 - accuracy: 0.2344 - val_loss: 2.4305 - val_accuracy: 0.2803\n","Epoch 20/400\n","10/10 [==============================] - 2s 246ms/step - loss: 2.3556 - accuracy: 0.2375 - val_loss: 2.4245 - val_accuracy: 0.2925\n","Epoch 21/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2835 - accuracy: 0.2969 - val_loss: 2.4246 - val_accuracy: 0.2861\n","Epoch 22/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2416 - accuracy: 0.2688 - val_loss: 2.4399 - val_accuracy: 0.2718\n","Epoch 23/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3725 - accuracy: 0.1937 - val_loss: 2.4664 - val_accuracy: 0.2472\n","Epoch 24/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2976 - accuracy: 0.2344 - val_loss: 2.4687 - val_accuracy: 0.2534\n","Epoch 25/400\n","10/10 [==============================] - 2s 245ms/step - loss: 2.3036 - accuracy: 0.2562 - val_loss: 2.4326 - val_accuracy: 0.2891\n","Epoch 26/400\n","10/10 [==============================] - 2s 252ms/step - loss: 2.2847 - accuracy: 0.2719 - val_loss: 2.4040 - val_accuracy: 0.3045\n","Epoch 27/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.2596 - accuracy: 0.2719 - val_loss: 2.4153 - val_accuracy: 0.2938\n","Epoch 28/400\n","10/10 [==============================] - 2s 250ms/step - loss: 2.2584 - accuracy: 0.2625 - val_loss: 2.4367 - val_accuracy: 0.2763\n","Epoch 29/400\n","10/10 [==============================] - 2s 252ms/step - loss: 2.2723 - accuracy: 0.2625 - val_loss: 2.4432 - val_accuracy: 0.2563\n","Epoch 30/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1585 - accuracy: 0.2844 - val_loss: 2.4259 - val_accuracy: 0.2640\n","Epoch 31/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1908 - accuracy: 0.2844 - val_loss: 2.4188 - val_accuracy: 0.2642\n","Epoch 32/400\n","10/10 [==============================] - 2s 250ms/step - loss: 2.1508 - accuracy: 0.2812 - val_loss: 2.3741 - val_accuracy: 0.2949\n","Epoch 33/400\n","10/10 [==============================] - 2s 247ms/step - loss: 2.2118 - accuracy: 0.2750 - val_loss: 2.3806 - val_accuracy: 0.2954\n","Epoch 34/400\n","10/10 [==============================] - 2s 252ms/step - loss: 2.1739 - accuracy: 0.2875 - val_loss: 2.3614 - val_accuracy: 0.3099\n","Epoch 35/400\n","10/10 [==============================] - 2s 245ms/step - loss: 2.2620 - accuracy: 0.2969 - val_loss: 2.3613 - val_accuracy: 0.3124\n","Epoch 36/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1663 - accuracy: 0.2875 - val_loss: 2.3806 - val_accuracy: 0.2915\n","Epoch 37/400\n","10/10 [==============================] - 2s 249ms/step - loss: 2.0681 - accuracy: 0.3375 - val_loss: 2.3893 - val_accuracy: 0.2731\n","Epoch 38/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1311 - accuracy: 0.3344 - val_loss: 2.3558 - val_accuracy: 0.2926\n","Epoch 39/400\n","10/10 [==============================] - 2s 256ms/step - loss: 2.1362 - accuracy: 0.3281 - val_loss: 2.3679 - val_accuracy: 0.2843\n","Epoch 40/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1844 - accuracy: 0.2969 - val_loss: 2.3514 - val_accuracy: 0.2959\n","Epoch 41/400\n","10/10 [==============================] - 2s 252ms/step - loss: 2.1342 - accuracy: 0.3031 - val_loss: 2.3185 - val_accuracy: 0.3097\n","Epoch 42/400\n","10/10 [==============================] - 3s 289ms/step - loss: 2.0805 - accuracy: 0.3219 - val_loss: 2.2960 - val_accuracy: 0.3163\n","Epoch 43/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0749 - accuracy: 0.3156 - val_loss: 2.3108 - val_accuracy: 0.3124\n","Epoch 44/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1190 - accuracy: 0.2750 - val_loss: 2.3151 - val_accuracy: 0.3001\n","Epoch 45/400\n","10/10 [==============================] - 2s 250ms/step - loss: 2.0619 - accuracy: 0.3031 - val_loss: 2.3206 - val_accuracy: 0.3077\n","Epoch 46/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0893 - accuracy: 0.3344 - val_loss: 2.3298 - val_accuracy: 0.3057\n","Epoch 47/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0922 - accuracy: 0.3219 - val_loss: 2.3477 - val_accuracy: 0.2947\n","Epoch 48/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1464 - accuracy: 0.3219 - val_loss: 2.3543 - val_accuracy: 0.2860\n","Epoch 49/400\n","10/10 [==============================] - 2s 246ms/step - loss: 1.9999 - accuracy: 0.3156 - val_loss: 2.3927 - val_accuracy: 0.2647\n","Epoch 50/400\n","10/10 [==============================] - 2s 247ms/step - loss: 2.0377 - accuracy: 0.3156 - val_loss: 2.3758 - val_accuracy: 0.2774\n","Epoch 51/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0956 - accuracy: 0.3187 - val_loss: 2.3401 - val_accuracy: 0.2956\n","Epoch 52/400\n","10/10 [==============================] - 2s 246ms/step - loss: 2.0999 - accuracy: 0.3500 - val_loss: 2.3119 - val_accuracy: 0.3131\n","Epoch 53/400\n","10/10 [==============================] - 2s 255ms/step - loss: 1.9730 - accuracy: 0.3625 - val_loss: 2.3608 - val_accuracy: 0.2817\n","Epoch 54/400\n","10/10 [==============================] - 2s 254ms/step - loss: 2.0437 - accuracy: 0.3469 - val_loss: 2.3854 - val_accuracy: 0.2709\n","Epoch 55/400\n","10/10 [==============================] - 2s 253ms/step - loss: 2.0422 - accuracy: 0.3625 - val_loss: 2.3910 - val_accuracy: 0.2787\n","Epoch 56/400\n","10/10 [==============================] - 2s 251ms/step - loss: 1.9582 - accuracy: 0.3406 - val_loss: 2.3762 - val_accuracy: 0.2892\n","Epoch 57/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1434 - accuracy: 0.3187 - val_loss: 2.3924 - val_accuracy: 0.2790\n","Epoch 58/400\n","10/10 [==============================] - 2s 246ms/step - loss: 2.1524 - accuracy: 0.3187 - val_loss: 2.3593 - val_accuracy: 0.2935\n","Epoch 59/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0741 - accuracy: 0.3344 - val_loss: 2.3258 - val_accuracy: 0.3057\n","Epoch 60/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9993 - accuracy: 0.3562 - val_loss: 2.3220 - val_accuracy: 0.2992\n","Epoch 61/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0025 - accuracy: 0.3500 - val_loss: 2.3445 - val_accuracy: 0.2856\n","Epoch 62/400\n","10/10 [==============================] - 2s 244ms/step - loss: 2.0634 - accuracy: 0.3594 - val_loss: 2.3524 - val_accuracy: 0.2835\n","Epoch 63/400\n","10/10 [==============================] - 2s 253ms/step - loss: 1.9956 - accuracy: 0.3562 - val_loss: 2.3624 - val_accuracy: 0.2849\n","Epoch 64/400\n","10/10 [==============================] - 2s 244ms/step - loss: 1.9761 - accuracy: 0.3250 - val_loss: 2.3721 - val_accuracy: 0.2815\n","Epoch 65/400\n","10/10 [==============================] - 3s 291ms/step - loss: 1.9422 - accuracy: 0.3969 - val_loss: 2.3909 - val_accuracy: 0.2741\n","Epoch 66/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9856 - accuracy: 0.3594 - val_loss: 2.3601 - val_accuracy: 0.2935\n","Epoch 67/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0160 - accuracy: 0.3469 - val_loss: 2.3488 - val_accuracy: 0.3036\n","Epoch 68/400\n","10/10 [==============================] - 2s 250ms/step - loss: 2.0874 - accuracy: 0.3094 - val_loss: 2.3694 - val_accuracy: 0.2937\n","Epoch 69/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9060 - accuracy: 0.3562 - val_loss: 2.3768 - val_accuracy: 0.2898\n","Epoch 70/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9218 - accuracy: 0.3906 - val_loss: 2.4180 - val_accuracy: 0.2640\n","Epoch 71/400\n","10/10 [==============================] - 3s 289ms/step - loss: 1.9182 - accuracy: 0.3781 - val_loss: 2.3949 - val_accuracy: 0.2741\n","Epoch 72/400\n","10/10 [==============================] - 2s 250ms/step - loss: 1.9065 - accuracy: 0.3875 - val_loss: 2.3962 - val_accuracy: 0.2767\n","Epoch 73/400\n","10/10 [==============================] - 2s 251ms/step - loss: 1.9404 - accuracy: 0.4031 - val_loss: 2.3833 - val_accuracy: 0.2851\n","Epoch 74/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9529 - accuracy: 0.3875 - val_loss: 2.3899 - val_accuracy: 0.2789\n","Epoch 75/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9106 - accuracy: 0.3875 - val_loss: 2.4004 - val_accuracy: 0.2692\n","Epoch 76/400\n","10/10 [==============================] - 2s 250ms/step - loss: 1.9376 - accuracy: 0.3719 - val_loss: 2.3834 - val_accuracy: 0.2828\n","Epoch 77/400\n","10/10 [==============================] - 2s 246ms/step - loss: 1.8754 - accuracy: 0.3656 - val_loss: 2.3816 - val_accuracy: 0.2810\n","Epoch 78/400\n","10/10 [==============================] - 2s 246ms/step - loss: 1.8817 - accuracy: 0.4250 - val_loss: 2.3891 - val_accuracy: 0.2770\n","Epoch 79/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8717 - accuracy: 0.3969 - val_loss: 2.3889 - val_accuracy: 0.2861\n","Epoch 80/400\n","10/10 [==============================] - 2s 249ms/step - loss: 1.8738 - accuracy: 0.3938 - val_loss: 2.3770 - val_accuracy: 0.2899\n","Epoch 81/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9352 - accuracy: 0.3781 - val_loss: 2.3706 - val_accuracy: 0.2955\n","Epoch 82/400\n","10/10 [==============================] - 2s 247ms/step - loss: 1.9550 - accuracy: 0.3531 - val_loss: 2.3689 - val_accuracy: 0.3020\n","Epoch 83/400\n","10/10 [==============================] - 2s 248ms/step - loss: 1.8977 - accuracy: 0.4031 - val_loss: 2.4054 - val_accuracy: 0.2755\n","Epoch 84/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8639 - accuracy: 0.3875 - val_loss: 2.4297 - val_accuracy: 0.2609\n","Epoch 85/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9546 - accuracy: 0.3594 - val_loss: 2.4277 - val_accuracy: 0.2637\n","Epoch 86/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9095 - accuracy: 0.3719 - val_loss: 2.3959 - val_accuracy: 0.2795\n","Epoch 87/400\n","10/10 [==============================] - 2s 251ms/step - loss: 1.9100 - accuracy: 0.3562 - val_loss: 2.4218 - val_accuracy: 0.2695\n","Epoch 88/400\n"," 1/10 [==>...........................] - ETA: 0s - loss: 1.7464 - accuracy: 0.4062"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-df6aed460c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n\u001b[1;32m     20\u001b[0m     loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_small_1hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_small_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# that didn't help\n","# might need to lighten up on the dimensionality reduction\n","# so I created a model that isn't learning the training set! let's add another layer\n","layer_list = [ #520 parameters in input\n","          layers.Dropout(0.6),\n","          layers.BatchNormalization(),\n","          #layers.Dropout(0.4),\n","          layers.Dense(40,kernel_initializer='lecun_normal'), #let's try dimensionality reduction\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(40,kernel_initializer='lecun_normal',kernel_regularizer='l2'), \n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dropout(0.6),\n","          layers.Dense(400,kernel_initializer='lecun_normal'),\n","          layers.BatchNormalization(),\n","          layers.Activation('selu'),\n","          layers.Dense(16,activation='softmax',kernel_initializer='lecun_normal'),\n","          ]\n","model = Sequential(layer_list)\n","model.compile(optimizer=keras.optimizers.Adam(\n","    learning_rate=keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=2000,decay_rate=0.99)),\n","    loss=\"categorical_crossentropy\", metrics=['accuracy'],)\n","history = model.fit(x_train_small, y_train_small_1hot, batch_size=32, epochs=400, validation_data=(x_val_small, y_val_small_1hot))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cjK69D0SRDkj","executionInfo":{"status":"error","timestamp":1652040672698,"user_tz":240,"elapsed":488668,"user":{"displayName":"Finn Clark","userId":"13891723806369472987"}},"outputId":"cccac245-6d61-4a5d-f820-c4762be99784"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","10/10 [==============================] - ETA: 0s - loss: 3.5057 - accuracy: 0.0656     "]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n","Traceback (most recent call last):\n","  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n","KeyboardInterrupt\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 109s 12s/step - loss: 3.5057 - accuracy: 0.0656 - val_loss: 3.6136 - val_accuracy: 0.0544\n","Epoch 2/400\n","10/10 [==============================] - 3s 292ms/step - loss: 3.3441 - accuracy: 0.0844 - val_loss: 3.3364 - val_accuracy: 0.0627\n","Epoch 3/400\n","10/10 [==============================] - 2s 267ms/step - loss: 3.1368 - accuracy: 0.1250 - val_loss: 3.0985 - val_accuracy: 0.1146\n","Epoch 4/400\n","10/10 [==============================] - 2s 264ms/step - loss: 3.1043 - accuracy: 0.1219 - val_loss: 3.0743 - val_accuracy: 0.1268\n","Epoch 5/400\n","10/10 [==============================] - 3s 292ms/step - loss: 3.0811 - accuracy: 0.1219 - val_loss: 3.0187 - val_accuracy: 0.1577\n","Epoch 6/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.9686 - accuracy: 0.1813 - val_loss: 2.9264 - val_accuracy: 0.2061\n","Epoch 7/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.9256 - accuracy: 0.1844 - val_loss: 2.8509 - val_accuracy: 0.2436\n","Epoch 8/400\n","10/10 [==============================] - 2s 271ms/step - loss: 2.9747 - accuracy: 0.1531 - val_loss: 2.8138 - val_accuracy: 0.2725\n","Epoch 9/400\n","10/10 [==============================] - 2s 271ms/step - loss: 2.8494 - accuracy: 0.1844 - val_loss: 2.7782 - val_accuracy: 0.2905\n","Epoch 10/400\n","10/10 [==============================] - 2s 266ms/step - loss: 2.8759 - accuracy: 0.1594 - val_loss: 2.7668 - val_accuracy: 0.2970\n","Epoch 11/400\n","10/10 [==============================] - 2s 271ms/step - loss: 2.8111 - accuracy: 0.1813 - val_loss: 2.7379 - val_accuracy: 0.3112\n","Epoch 12/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.8282 - accuracy: 0.1906 - val_loss: 2.7206 - val_accuracy: 0.3159\n","Epoch 13/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.7587 - accuracy: 0.2313 - val_loss: 2.7010 - val_accuracy: 0.3332\n","Epoch 14/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.7879 - accuracy: 0.2375 - val_loss: 2.7305 - val_accuracy: 0.3073\n","Epoch 15/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.6908 - accuracy: 0.2406 - val_loss: 2.7064 - val_accuracy: 0.3135\n","Epoch 16/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6593 - accuracy: 0.2344 - val_loss: 2.6967 - val_accuracy: 0.3063\n","Epoch 17/400\n","10/10 [==============================] - 2s 265ms/step - loss: 2.7013 - accuracy: 0.2406 - val_loss: 2.6646 - val_accuracy: 0.3013\n","Epoch 18/400\n","10/10 [==============================] - 2s 270ms/step - loss: 2.6342 - accuracy: 0.2625 - val_loss: 2.6557 - val_accuracy: 0.2933\n","Epoch 19/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.6021 - accuracy: 0.2500 - val_loss: 2.6678 - val_accuracy: 0.2771\n","Epoch 20/400\n","10/10 [==============================] - 2s 275ms/step - loss: 2.6232 - accuracy: 0.2875 - val_loss: 2.6447 - val_accuracy: 0.3054\n","Epoch 21/400\n","10/10 [==============================] - 2s 268ms/step - loss: 2.5401 - accuracy: 0.2562 - val_loss: 2.6603 - val_accuracy: 0.2929\n","Epoch 22/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5952 - accuracy: 0.2406 - val_loss: 2.6906 - val_accuracy: 0.2739\n","Epoch 23/400\n","10/10 [==============================] - 2s 267ms/step - loss: 2.5153 - accuracy: 0.2562 - val_loss: 2.6646 - val_accuracy: 0.2813\n","Epoch 24/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4844 - accuracy: 0.2812 - val_loss: 2.6271 - val_accuracy: 0.3018\n","Epoch 25/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.5471 - accuracy: 0.2781 - val_loss: 2.6122 - val_accuracy: 0.3063\n","Epoch 26/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4944 - accuracy: 0.3031 - val_loss: 2.5844 - val_accuracy: 0.3166\n","Epoch 27/400\n","10/10 [==============================] - 2s 271ms/step - loss: 2.4637 - accuracy: 0.2906 - val_loss: 2.5718 - val_accuracy: 0.3272\n","Epoch 28/400\n","10/10 [==============================] - 2s 266ms/step - loss: 2.5398 - accuracy: 0.2344 - val_loss: 2.5910 - val_accuracy: 0.3132\n","Epoch 29/400\n","10/10 [==============================] - 2s 262ms/step - loss: 2.5383 - accuracy: 0.2562 - val_loss: 2.5782 - val_accuracy: 0.3108\n","Epoch 30/400\n","10/10 [==============================] - 2s 268ms/step - loss: 2.4613 - accuracy: 0.3094 - val_loss: 2.5870 - val_accuracy: 0.2935\n","Epoch 31/400\n","10/10 [==============================] - 2s 267ms/step - loss: 2.4157 - accuracy: 0.3219 - val_loss: 2.5589 - val_accuracy: 0.3076\n","Epoch 32/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.4168 - accuracy: 0.2969 - val_loss: 2.5649 - val_accuracy: 0.3034\n","Epoch 33/400\n","10/10 [==============================] - 2s 269ms/step - loss: 2.3964 - accuracy: 0.3156 - val_loss: 2.5728 - val_accuracy: 0.2875\n","Epoch 34/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3186 - accuracy: 0.3187 - val_loss: 2.5817 - val_accuracy: 0.2831\n","Epoch 35/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3728 - accuracy: 0.2937 - val_loss: 2.5844 - val_accuracy: 0.2822\n","Epoch 36/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.3504 - accuracy: 0.3344 - val_loss: 2.6139 - val_accuracy: 0.2743\n","Epoch 37/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.4034 - accuracy: 0.2969 - val_loss: 2.5896 - val_accuracy: 0.2864\n","Epoch 38/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.3199 - accuracy: 0.3094 - val_loss: 2.5662 - val_accuracy: 0.2996\n","Epoch 39/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.3048 - accuracy: 0.3406 - val_loss: 2.5654 - val_accuracy: 0.2932\n","Epoch 40/400\n","10/10 [==============================] - 2s 267ms/step - loss: 2.3415 - accuracy: 0.2875 - val_loss: 2.5432 - val_accuracy: 0.2965\n","Epoch 41/400\n","10/10 [==============================] - 2s 268ms/step - loss: 2.2699 - accuracy: 0.3688 - val_loss: 2.5484 - val_accuracy: 0.2932\n","Epoch 42/400\n","10/10 [==============================] - 2s 268ms/step - loss: 2.2681 - accuracy: 0.3313 - val_loss: 2.5592 - val_accuracy: 0.2873\n","Epoch 43/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2129 - accuracy: 0.3562 - val_loss: 2.5536 - val_accuracy: 0.2854\n","Epoch 44/400\n","10/10 [==============================] - 2s 272ms/step - loss: 2.2601 - accuracy: 0.3000 - val_loss: 2.5346 - val_accuracy: 0.2968\n","Epoch 45/400\n","10/10 [==============================] - 2s 265ms/step - loss: 2.2756 - accuracy: 0.3438 - val_loss: 2.5789 - val_accuracy: 0.2722\n","Epoch 46/400\n","10/10 [==============================] - 3s 278ms/step - loss: 2.2607 - accuracy: 0.3219 - val_loss: 2.5830 - val_accuracy: 0.2673\n","Epoch 47/400\n","10/10 [==============================] - 2s 266ms/step - loss: 2.1786 - accuracy: 0.3656 - val_loss: 2.5614 - val_accuracy: 0.2802\n","Epoch 48/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2201 - accuracy: 0.3344 - val_loss: 2.5319 - val_accuracy: 0.2943\n","Epoch 49/400\n","10/10 [==============================] - 3s 293ms/step - loss: 2.2366 - accuracy: 0.3969 - val_loss: 2.5601 - val_accuracy: 0.2741\n","Epoch 50/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.1796 - accuracy: 0.3469 - val_loss: 2.5864 - val_accuracy: 0.2612\n","Epoch 51/400\n","10/10 [==============================] - 2s 268ms/step - loss: 2.1931 - accuracy: 0.3313 - val_loss: 2.5600 - val_accuracy: 0.2731\n","Epoch 52/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1442 - accuracy: 0.3844 - val_loss: 2.5435 - val_accuracy: 0.2840\n","Epoch 53/400\n","10/10 [==============================] - 2s 265ms/step - loss: 2.1793 - accuracy: 0.3562 - val_loss: 2.5569 - val_accuracy: 0.2733\n","Epoch 54/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.1645 - accuracy: 0.3375 - val_loss: 2.5649 - val_accuracy: 0.2674\n","Epoch 55/400\n","10/10 [==============================] - 2s 268ms/step - loss: 2.1728 - accuracy: 0.3375 - val_loss: 2.5767 - val_accuracy: 0.2601\n","Epoch 56/400\n","10/10 [==============================] - 2s 265ms/step - loss: 2.1400 - accuracy: 0.3531 - val_loss: 2.5477 - val_accuracy: 0.2790\n","Epoch 57/400\n","10/10 [==============================] - 3s 292ms/step - loss: 2.1612 - accuracy: 0.3406 - val_loss: 2.5236 - val_accuracy: 0.2890\n","Epoch 58/400\n","10/10 [==============================] - 2s 272ms/step - loss: 2.1283 - accuracy: 0.3469 - val_loss: 2.5409 - val_accuracy: 0.2815\n","Epoch 59/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1508 - accuracy: 0.3219 - val_loss: 2.5255 - val_accuracy: 0.2838\n","Epoch 60/400\n","10/10 [==============================] - 2s 267ms/step - loss: 2.1156 - accuracy: 0.3844 - val_loss: 2.5360 - val_accuracy: 0.2803\n","Epoch 61/400\n","10/10 [==============================] - 2s 268ms/step - loss: 2.0701 - accuracy: 0.4031 - val_loss: 2.5379 - val_accuracy: 0.2847\n","Epoch 62/400\n","10/10 [==============================] - 2s 268ms/step - loss: 2.0545 - accuracy: 0.3969 - val_loss: 2.5347 - val_accuracy: 0.2871\n","Epoch 63/400\n","10/10 [==============================] - 2s 267ms/step - loss: 2.0723 - accuracy: 0.3594 - val_loss: 2.5097 - val_accuracy: 0.2994\n","Epoch 64/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.1347 - accuracy: 0.3406 - val_loss: 2.5072 - val_accuracy: 0.3005\n","Epoch 65/400\n","10/10 [==============================] - 2s 271ms/step - loss: 2.0559 - accuracy: 0.4094 - val_loss: 2.5147 - val_accuracy: 0.2953\n","Epoch 66/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.2511 - accuracy: 0.3344 - val_loss: 2.5435 - val_accuracy: 0.2824\n","Epoch 67/400\n","10/10 [==============================] - 2s 270ms/step - loss: 2.0603 - accuracy: 0.3719 - val_loss: 2.5822 - val_accuracy: 0.2581\n","Epoch 68/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.0340 - accuracy: 0.3562 - val_loss: 2.5595 - val_accuracy: 0.2657\n","Epoch 69/400\n","10/10 [==============================] - 2s 270ms/step - loss: 2.0242 - accuracy: 0.4031 - val_loss: 2.5057 - val_accuracy: 0.2903\n","Epoch 70/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0362 - accuracy: 0.3688 - val_loss: 2.4862 - val_accuracy: 0.3024\n","Epoch 71/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9612 - accuracy: 0.4187 - val_loss: 2.5199 - val_accuracy: 0.2867\n","Epoch 72/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9705 - accuracy: 0.3875 - val_loss: 2.5703 - val_accuracy: 0.2641\n","Epoch 73/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.0360 - accuracy: 0.3906 - val_loss: 2.5333 - val_accuracy: 0.2804\n","Epoch 74/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0929 - accuracy: 0.3500 - val_loss: 2.4963 - val_accuracy: 0.3004\n","Epoch 75/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0769 - accuracy: 0.3594 - val_loss: 2.5058 - val_accuracy: 0.2978\n","Epoch 76/400\n","10/10 [==============================] - 3s 283ms/step - loss: 2.0112 - accuracy: 0.4125 - val_loss: 2.5145 - val_accuracy: 0.2926\n","Epoch 77/400\n","10/10 [==============================] - 2s 273ms/step - loss: 1.9101 - accuracy: 0.4469 - val_loss: 2.5067 - val_accuracy: 0.2958\n","Epoch 78/400\n","10/10 [==============================] - 2s 266ms/step - loss: 2.0557 - accuracy: 0.3812 - val_loss: 2.5039 - val_accuracy: 0.2970\n","Epoch 79/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9661 - accuracy: 0.4062 - val_loss: 2.5192 - val_accuracy: 0.2912\n","Epoch 80/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0385 - accuracy: 0.4094 - val_loss: 2.5170 - val_accuracy: 0.2850\n","Epoch 81/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.0079 - accuracy: 0.4031 - val_loss: 2.5685 - val_accuracy: 0.2645\n","Epoch 82/400\n","10/10 [==============================] - 2s 272ms/step - loss: 2.0580 - accuracy: 0.3688 - val_loss: 2.5417 - val_accuracy: 0.2755\n","Epoch 83/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9431 - accuracy: 0.4156 - val_loss: 2.5248 - val_accuracy: 0.2825\n","Epoch 84/400\n","10/10 [==============================] - 2s 271ms/step - loss: 1.9330 - accuracy: 0.4094 - val_loss: 2.4949 - val_accuracy: 0.2972\n","Epoch 85/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9162 - accuracy: 0.4125 - val_loss: 2.4726 - val_accuracy: 0.3113\n","Epoch 86/400\n","10/10 [==============================] - 2s 263ms/step - loss: 2.0266 - accuracy: 0.3375 - val_loss: 2.5115 - val_accuracy: 0.2965\n","Epoch 87/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8758 - accuracy: 0.4125 - val_loss: 2.5745 - val_accuracy: 0.2666\n","Epoch 88/400\n","10/10 [==============================] - 2s 274ms/step - loss: 1.9804 - accuracy: 0.4125 - val_loss: 2.5729 - val_accuracy: 0.2738\n","Epoch 89/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9182 - accuracy: 0.4062 - val_loss: 2.5739 - val_accuracy: 0.2729\n","Epoch 90/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9683 - accuracy: 0.4219 - val_loss: 2.5654 - val_accuracy: 0.2742\n","Epoch 91/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8840 - accuracy: 0.4219 - val_loss: 2.5754 - val_accuracy: 0.2724\n","Epoch 92/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8251 - accuracy: 0.4469 - val_loss: 2.5627 - val_accuracy: 0.2715\n","Epoch 93/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9590 - accuracy: 0.4125 - val_loss: 2.5560 - val_accuracy: 0.2728\n","Epoch 94/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0616 - accuracy: 0.3406 - val_loss: 2.5621 - val_accuracy: 0.2695\n","Epoch 95/400\n","10/10 [==============================] - 2s 270ms/step - loss: 1.9041 - accuracy: 0.3969 - val_loss: 2.5794 - val_accuracy: 0.2655\n","Epoch 96/400\n","10/10 [==============================] - 2s 274ms/step - loss: 1.9440 - accuracy: 0.4000 - val_loss: 2.6152 - val_accuracy: 0.2578\n","Epoch 97/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8790 - accuracy: 0.4437 - val_loss: 2.6003 - val_accuracy: 0.2623\n","Epoch 98/400\n","10/10 [==============================] - 3s 291ms/step - loss: 2.0207 - accuracy: 0.3781 - val_loss: 2.5871 - val_accuracy: 0.2671\n","Epoch 99/400\n","10/10 [==============================] - 2s 263ms/step - loss: 1.9174 - accuracy: 0.4375 - val_loss: 2.5800 - val_accuracy: 0.2738\n","Epoch 100/400\n","10/10 [==============================] - 3s 290ms/step - loss: 2.0537 - accuracy: 0.3750 - val_loss: 2.6515 - val_accuracy: 0.2459\n","Epoch 101/400\n","10/10 [==============================] - 2s 270ms/step - loss: 1.9346 - accuracy: 0.4187 - val_loss: 2.6247 - val_accuracy: 0.2483\n","Epoch 102/400\n","10/10 [==============================] - 2s 264ms/step - loss: 1.8711 - accuracy: 0.4219 - val_loss: 2.6084 - val_accuracy: 0.2514\n","Epoch 103/400\n","10/10 [==============================] - 2s 267ms/step - loss: 1.9009 - accuracy: 0.3969 - val_loss: 2.5729 - val_accuracy: 0.2652\n","Epoch 104/400\n","10/10 [==============================] - 2s 267ms/step - loss: 1.8595 - accuracy: 0.4406 - val_loss: 2.5735 - val_accuracy: 0.2646\n","Epoch 105/400\n","10/10 [==============================] - 2s 267ms/step - loss: 1.9511 - accuracy: 0.4281 - val_loss: 2.5687 - val_accuracy: 0.2634\n","Epoch 106/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8949 - accuracy: 0.4187 - val_loss: 2.5846 - val_accuracy: 0.2550\n","Epoch 107/400\n","10/10 [==============================] - 3s 291ms/step - loss: 1.8581 - accuracy: 0.4531 - val_loss: 2.5839 - val_accuracy: 0.2612\n","Epoch 108/400\n","10/10 [==============================] - 3s 291ms/step - loss: 1.8954 - accuracy: 0.4031 - val_loss: 2.5989 - val_accuracy: 0.2601\n","Epoch 109/400\n","10/10 [==============================] - 2s 267ms/step - loss: 1.8519 - accuracy: 0.3969 - val_loss: 2.5941 - val_accuracy: 0.2611\n","Epoch 110/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9102 - accuracy: 0.4125 - val_loss: 2.5966 - val_accuracy: 0.2578\n","Epoch 111/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.9550 - accuracy: 0.3781 - val_loss: 2.6371 - val_accuracy: 0.2459\n","Epoch 112/400\n","10/10 [==============================] - 2s 267ms/step - loss: 1.9229 - accuracy: 0.3875 - val_loss: 2.6102 - val_accuracy: 0.2572\n","Epoch 113/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8430 - accuracy: 0.4437 - val_loss: 2.5928 - val_accuracy: 0.2580\n","Epoch 114/400\n","10/10 [==============================] - 3s 292ms/step - loss: 1.8889 - accuracy: 0.4094 - val_loss: 2.5896 - val_accuracy: 0.2549\n","Epoch 115/400\n","10/10 [==============================] - 2s 266ms/step - loss: 1.8585 - accuracy: 0.4500 - val_loss: 2.5579 - val_accuracy: 0.2760\n","Epoch 116/400\n","10/10 [==============================] - 3s 292ms/step - loss: 1.9412 - accuracy: 0.4125 - val_loss: 2.5816 - val_accuracy: 0.2735\n","Epoch 117/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8416 - accuracy: 0.4281 - val_loss: 2.5869 - val_accuracy: 0.2663\n","Epoch 118/400\n","10/10 [==============================] - 2s 265ms/step - loss: 1.8653 - accuracy: 0.4313 - val_loss: 2.5931 - val_accuracy: 0.2584\n","Epoch 119/400\n","10/10 [==============================] - 3s 291ms/step - loss: 1.8097 - accuracy: 0.4500 - val_loss: 2.5594 - val_accuracy: 0.2731\n","Epoch 120/400\n","10/10 [==============================] - 3s 292ms/step - loss: 1.8370 - accuracy: 0.4281 - val_loss: 2.5461 - val_accuracy: 0.2845\n","Epoch 121/400\n","10/10 [==============================] - 2s 266ms/step - loss: 1.8632 - accuracy: 0.4000 - val_loss: 2.5481 - val_accuracy: 0.2814\n","Epoch 122/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8786 - accuracy: 0.4469 - val_loss: 2.5714 - val_accuracy: 0.2718\n","Epoch 123/400\n","10/10 [==============================] - 3s 291ms/step - loss: 1.9160 - accuracy: 0.3906 - val_loss: 2.5765 - val_accuracy: 0.2670\n","Epoch 124/400\n","10/10 [==============================] - 2s 266ms/step - loss: 1.8495 - accuracy: 0.4031 - val_loss: 2.5673 - val_accuracy: 0.2699\n","Epoch 125/400\n","10/10 [==============================] - 2s 266ms/step - loss: 1.8552 - accuracy: 0.4187 - val_loss: 2.6138 - val_accuracy: 0.2576\n","Epoch 126/400\n","10/10 [==============================] - 2s 269ms/step - loss: 1.8279 - accuracy: 0.4344 - val_loss: 2.6309 - val_accuracy: 0.2556\n","Epoch 127/400\n","10/10 [==============================] - 2s 263ms/step - loss: 1.8607 - accuracy: 0.4219 - val_loss: 2.6111 - val_accuracy: 0.2606\n","Epoch 128/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.7337 - accuracy: 0.4812 - val_loss: 2.5701 - val_accuracy: 0.2697\n","Epoch 129/400\n","10/10 [==============================] - 2s 268ms/step - loss: 1.7823 - accuracy: 0.4594 - val_loss: 2.5683 - val_accuracy: 0.2703\n","Epoch 130/400\n","10/10 [==============================] - 2s 266ms/step - loss: 1.8561 - accuracy: 0.3875 - val_loss: 2.5561 - val_accuracy: 0.2785\n","Epoch 131/400\n","10/10 [==============================] - 2s 268ms/step - loss: 1.7957 - accuracy: 0.4219 - val_loss: 2.5955 - val_accuracy: 0.2653\n","Epoch 132/400\n","10/10 [==============================] - 2s 266ms/step - loss: 1.8284 - accuracy: 0.4437 - val_loss: 2.6072 - val_accuracy: 0.2588\n","Epoch 133/400\n","10/10 [==============================] - 2s 265ms/step - loss: 1.7762 - accuracy: 0.4219 - val_loss: 2.6233 - val_accuracy: 0.2554\n","Epoch 134/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.8870 - accuracy: 0.4062 - val_loss: 2.6119 - val_accuracy: 0.2597\n","Epoch 135/400\n","10/10 [==============================] - 3s 292ms/step - loss: 1.8693 - accuracy: 0.4375 - val_loss: 2.5974 - val_accuracy: 0.2662\n","Epoch 136/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.7380 - accuracy: 0.4719 - val_loss: 2.6040 - val_accuracy: 0.2626\n","Epoch 137/400\n","10/10 [==============================] - 3s 291ms/step - loss: 1.8034 - accuracy: 0.4594 - val_loss: 2.6169 - val_accuracy: 0.2537\n","Epoch 138/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.7582 - accuracy: 0.4688 - val_loss: 2.6184 - val_accuracy: 0.2548\n","Epoch 139/400\n","10/10 [==============================] - 3s 293ms/step - loss: 1.8875 - accuracy: 0.3969 - val_loss: 2.6234 - val_accuracy: 0.2603\n","Epoch 140/400\n","10/10 [==============================] - 3s 291ms/step - loss: 1.7888 - accuracy: 0.4500 - val_loss: 2.5590 - val_accuracy: 0.2839\n","Epoch 141/400\n","10/10 [==============================] - 3s 291ms/step - loss: 1.8835 - accuracy: 0.4000 - val_loss: 2.5750 - val_accuracy: 0.2730\n","Epoch 142/400\n","10/10 [==============================] - 2s 269ms/step - loss: 1.7460 - accuracy: 0.4844 - val_loss: 2.5860 - val_accuracy: 0.2677\n","Epoch 143/400\n","10/10 [==============================] - 2s 265ms/step - loss: 1.7398 - accuracy: 0.4906 - val_loss: 2.6119 - val_accuracy: 0.2582\n","Epoch 144/400\n","10/10 [==============================] - 2s 269ms/step - loss: 1.8394 - accuracy: 0.4656 - val_loss: 2.5879 - val_accuracy: 0.2698\n","Epoch 145/400\n","10/10 [==============================] - 2s 270ms/step - loss: 1.6748 - accuracy: 0.4781 - val_loss: 2.6145 - val_accuracy: 0.2591\n","Epoch 146/400\n","10/10 [==============================] - 2s 264ms/step - loss: 1.8201 - accuracy: 0.4219 - val_loss: 2.6754 - val_accuracy: 0.2394\n","Epoch 147/400\n","10/10 [==============================] - 3s 290ms/step - loss: 1.7421 - accuracy: 0.4531 - val_loss: 2.6913 - val_accuracy: 0.2338\n","Epoch 148/400\n"," 1/10 [==>...........................] - ETA: 0s - loss: 1.5949 - accuracy: 0.5625"]},{"output_type":"stream","name":"stderr","text":["\n","KeyboardInterrupt\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"rNAVSj8sU4vt"},"execution_count":null,"outputs":[]}]}